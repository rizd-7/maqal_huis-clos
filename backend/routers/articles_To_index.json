{
  "data": [
    "{\n  \"DocumentTitle\": \"Framing the News: From Human Perception to Large Language Model Inferences\",\n  \"Auteurs\": \"David Alonso del Barrio, Daniel Gatica-Perez, \",\n  \"Institutions\": \"Idiap Research Institute and EPFL, Idiap Research Institute, \",\n  \"Abstract\": \"\\n        \",\n  \"Sections\": [\n    {\n      \"title\": \"CCS CONCEPTS\",\n      \"paragraphs\": [\n        \"\\u2022 Computing methodologies \\u2192 Information extraction; \\u2022\\nHuman-centered computing \\u2192 Text input.\\nCovid-19 no-vax, news framing, GPT-3, prompt-engineering,\\ntransformers, large language models\\nPermission to make digital or hard copies of all or part of this work for personal or\\nclassroom use is granted without fee provided that copies are not made or distributed\\nfor profit or commercial advantage and that copies bear this notice and the full citation\\non the first page. Copyrights for components of this work owned by others than the\\nauthor(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or\\nrepublish, to post on servers or to redistribute to lists, requires prior specific permission\\nand/or a fee. Request permissions from permissions@acm.org.\",\n        \"ICMR \\u201923, June 12\\u201315, 2023, Thessaloniki, Greece\\n\\u00a9 2023 Copyright held by the owner/author(s). Publication rights licensed to ACM.\\nACM ISBN 979-8-4007-0178-8/23/06. . . $15.00\\nhttps://doi.org/10.1145/3591106.3592278\"\n      ]\n    },\n    {\n      \"title\": \"INTRODUCTION\",\n      \"paragraphs\": [\n        \"\\n        In recent years, there has been a proliferation in the use of concepts\\nsuch as data journalism, computational journalism, and\\ncomputerassisted reporting \\n        \",\n        \"Frame analysis is a concept from journalism, which consists of\\nstudying the way in which news stories are presented on an issue,\\nand what aspects are emphasized: Is a merely informative vision\\ngiven in an article? Or is it intended to leave a moral lesson? Is\\na news article being presented from an economic point of view?\\nOr from a more human, emotional angle? The examples above\\ncorrespond to diferent frames with which an article can be written.\",\n        \"\\n        The concept of news framing has been studied in computing as\\na step beyond topic modeling and sentiment analysis, and for this\\npurpose, in recent years, pre-trained language models have been\\nused for fine-tuning the classification process of these frames \\n        \",\n        \"Our work aims to address this research gap by posing the\\nfollowing research questions:\",\n        \"RQ1: What are the main frames in the news headlines about\\nthe anti-vaccine movement, as reported in newspapers across 5\\nEuropean countries?\",\n        \"RQ2: Can prompt engineering be used for classification of\\nheadlines according to frames?\",\n        \"By addressing the above research questions, our work makes the\\nfollowing contributions:\",\n        \"Contribution 1. We implemented a process to do human\\nannotation of the main frame of 1786 headlines of articles about the\\nCovid-19 no-vax movement, as reported in 19 newspapers from 5\\nEuropean countries (France, Italy, Spain, Switzerland and United\\nKingdom.) At the headline level, we found that the predominant\\nframe was human interest, where this frame corresponds to a\\npersonification of an event, either through a statement by a person,\\nor the explanation of a specific event that happened to a person.\\nFurthermore, we found a large number of headlines annotated as\\ncontaining no frame, as they simply present information without\\nentering into evaluations. We also found that for all the countries\\ninvolved, the distribution of frame types was very similar, i.e.,\\nhuman interest and no frame are the two predominant frames. Finally,\\nthe generated annotations allowed to subsequently study the\\nperformance of a large language model.\",\n        \"Contribution 2. We studied the performance of GPT-3.5 on\\nthe task of frame classification of headlines. In addition to using\\nthe fine-tuning approach from previous literature, we propose an\\nalternative approach for frame classification that requires no labeled\\ndata for training, namely prompt-engineering using GPT-3.5. The\\nresults show that fine-tuning with GPT-3.5 produces 72% accuracy\\n(slightly higher than other smaller models), and that the\\npromptengineering approach results in lower performance (49% accuracy.)\\nOur analysis also shows that the subjectivity of the human labeling\\ntask has an efect on the obtained accufracy.\",\n        \"The paper is organized as follows. In Section 2, we discuss related\\nwork. In Section 3, we describe the news dataset. In Section 4, we\\ndescribe the methodology for both human labeling and machine\\nclassification of news frames. We present and discuss results for\\nRQ1 and RQ2 in Sections 5 and 6, respectively. Finally, we provide\\nconclusions in Section 7.\\n2\"\n      ]\n    },\n    {\n      \"title\": \"RELATED WORK\",\n      \"paragraphs\": [\n        \"\\n        Framing has been a concept widely studied in journalism, with a\\ndefinition that is rooted in the study of this domain \\n        \",\n        \"\\n        For frame recognition, there are two main approaches: the\\ninductive approach \\n        \",\n        \"\\n        We now compare the two approaches on a common topic, such\\nas Covid-19. Ebrahim et al. \\n        \",\n        \"We decided to follow the deductive approach because a\\npredeifned list of frames allows to compare among topics, countries,\\nprevious literature, and also because they represent a fixed list of\\nlabels for machine classification models. Furthermore, the\\ninductive approach tends to be more specific to a topic, and from the\\ncomputing viewpoint, past work has tried to justify topic modeling\\nas a technique to extract frames from articles.\",\n        \"\\n        Yl\\u00e4-Antitila et al. \\n        \",\n        \"\\n        From Entman\\u2019s definition of frame \\n        \",\n        \"\\n        Isoaho et al.\\n        \",\n        \"\\n        We also consider that the larger the number of possible frame\\ntypes, the more likely it is to end up doing topic modeling instead of\\nframe analysis. Using a deductive approach, Dallas et al. \\n        \",\n        \"\\n        A final decision in our work was the type of text to analyze,\\nwhether headlines or whole article. For this decision, the chosen\\nclassification method was also going to be important. For example,\\nKhanehzar et al. \\n        \",\n        \"\\n        Continuing with the question of the methods used for\\nclassiifcation, much work has been developed in prompt engineering,\\nespecially since the release of GPT-3. Liu et al.\\n        \",\n        \"\\n        As mentioned before, the emergence of giant models like GPT-3,\\nBLOOM, and ChatGPT are a very active research topic. To the best\\nof our knowledge, on one hand our work extends the computational\\nanalysis of news related to the covid-19 no-vax movement, which\\nillustrates the influence of the press on the ways societies think\\nabout relevant issues \\n        \"\n      ]\n    },\n    {\n      \"title\": \"3 DATA: EUROPEAN COVID-19 NEWS\",\n      \"paragraphs\": []\n    },\n    {\n      \"title\": \"DATASET\",\n      \"paragraphs\": [\n        \"\\n        We used part of the European Covid-19 News dataset collected in\\nour recent work \\n        \",\n        \"In the first phase, annotators had to read the codebook and get\\nfamiliar with the task. In the second phase, they were asked to\\nidentify the main frame in the same subset of 50 headlines. At the\\nend of the second phase, the intercoder reliability (ICR) was 0.58\\nbetween the 2 annotators. We analyzed those cases where there\\nwere discrepancies, and observed that in some cases, there was not a\\nunique main frame, because both annotators had valid arguments to\\nselect one of the frames. In other cases, the discrepancies were due\\nto slight misunderstanding of the definitions. In the third phase, the\\nannotators coded again 50 headlines, and the ICR increased to was\\n0.66. We realized that the possibility of having two frames remained.\\nThey discussed the cases in which they had disagreed, and if the\\nother person\\u2019s arguments were considered valid, it could be said that\\nthere were two frames. After this three-phase training procedure,\\nannotators were ready to annotate the dataset independently. We\\ndivided the dataset into two equal parts, and each person annotated\\n893 headlines.\\n4.2\"\n      ]\n    },\n    {\n      \"title\": \"Fine-tuning GPT-3.5 and BERT-based models\",\n      \"paragraphs\": [\n        \"With the annotated dataset, we investigated two NLP approaches:\\nthe first one involves fine-tuning a pre-trained model; the second\\none is prompt engineering. Pre-trained language models have been\\ntrained with large text strings based on two unsupervised tasks,\\nnext sentence prediction and masked language model. Figure 1\\nsummarizes these techniques.\",\n        \"\\n        In the first approach, a model with a fixed architecture is\\npretrained as a language model (LM), predicting the likelihood of the\\nobserved textual data. This can be done due to the availability of\\nlarge, raw text data needed to train LMs. This learning process can\\nproduce general purpose features of the modeled language. The\\nlearning process produces robust, general-purpose features of the\\nlanguage being modeled. The above pre-trained LM is then adapted\\nto diferent downstream tasks, by introducing additional parameters\\nand adjusting them using task-specific objective functions. In this\\napproach, the focus was primarily on goal engineering, designing\\nthe training targets used in both the pre-training and the fine-tuning\\nstages \\n        \",\n        \"We present an example to illustrate the idea. Imagine that the\\ntask is sentiment analysis, and we have a dataset with sentences\\nand their associated sentiment, and a pre-trained model, which is a\\nsaved neural network trained with a much larger dataset. For that\\npre-trained model to address the target task, we unfreeze a few of\\nthe top layers of the saved model base and jointly train both the\\nnewly-added classifier layers and the last layers of the base model.\\nThis allows to \\\"fine-tune\\\" the higher-order feature representations\\nin the base model to make them more relevant for the sentiment\\nanalysis task. In this way, instead of having to obtain a very large\\ndataset with target labels to train a model, we can reuse the\\npretrained model and use a much smaller train dataset. We use a part\\nof our dataset as examples for the model to learn the task, while\\nthe other part of the dataset is used to evaluate model performance.\",\n        \"Previous works related to frame classification in the computing\\nliterature have used fine-tuning, BERT-based models. In our work,\\nwe have done the same as a baseline, but we aimed to go one step\\nfurther and also produce results using fine-tuning of GPT-3.5.\\n4.3\"\n      ]\n    },\n    {\n      \"title\": \"Prompt-engineering with GPT-3.5\",\n      \"paragraphs\": [\n        \"\\n        Model fine-tuning has been widely used, but with the emergence\\nof generative models such as GPT-3, another way to approach\\nclassification tasks has appeared. The idea is to use the pre-trained\\nmodel directly and convert the task to be performed into a format\\nas close as possible to the tasks for which it has been pre-trained.\\nThat is, if the model has been pre-trained from next word prediction\\nas in the case of GPT-3, classification can be done by defining a\\nprompt, where the input to the model is an incomplete sentence,\\nand the model must complete it with a word or several words, just\\nas it has been trained. This avoids having to use part of the already\\nlabeled dataset to teach the task to be performed to the model, and\\na previous labeling is not needed \\n        \",\n        \"\\n        In this approach, instead of adapting pre-trained LMs to\\ndownstream tasks via objective engineering, downstream tasks are\\nreformulated to look more like those solved during the original LM\\ntraining with the help of a textual prompt. For example, when\\nrecognizing the emotion of a social media post, \\u201cI missed the bus today.\\u201d,\\nwe may continue with a prompt \\u201cI felt so _\\u201d, and ask the LM to\\nifll the blank with an emotion-bearing word. Or if we choose the\\nprompt \\u201cEnglish: I missed the bus today. French: _\\u201d), an LM may\\nbe able to fill in the blank with a French translation. In this way,\\nby selecting the appropriate prompts, we can influence the model\\nbehavior so that the pre-trained LM itself can be used to predict the\\ndesired output, even without any additional task-specific training\\n\\n        \",\n        \"\\n        We use this emerging NLP approach to classify frames at headline\\nlevel. We are not aware of previous uses of this strategy to classify\\nframes as we propose here. The idea is the following. Prompt\\nengineering consists of giving a prompt to the model, and understands\\nthat prompt as an incomplete sentence. To do prompt\\nengineering with our dataset, we needed to define an appropriate prompt\\nthat would produce the headline frames as output. We defined\\nseveral experiments with the Playground of GPT-3, in order to find\\nthe best prompt for our task. In our initial experiments, we\\nfollowed existing approaches in prompt engineering to do sentiment\\nanalysis, where the individual answer was an adjective, and this\\nadjective was matched with a sentiment. In a similar fashion, we\\ndecided to build a thesaurus of adjectives that define each of the\\nframes. For instance, the human interest frame could be\\n\\u2019interesting\\u2019, \\u2019emotional\\u2019, \\u2019personal\\u2019, \\u2019human\\u2019. The conflict frame could be:\\n\\u2019conflictive\\u2019, \\u2019bellicose\\u2019, \\u2019troublesome\\u2019, \\u2019rowdy\\u2019, \\u2019quarrelsome\\u2019,\\n\\u2019troublemaker\\u2019, \\u2019agitator\\u2019, etc. After the list of adjectives was defined,\\nwe needed to define the prompt in order to get, as an answer, one\\nof the adjectives in our thesaurus to match them with the frame.\\nWe used the GPT-3 playground using the headline as input and\\nasking for the frame as output, but the strategy did not work. In\\nour final experiment, instead of giving the headline as input, we\\ngave the definitions of each type of frame plus the headline, and we\\nasked the model to choose between the diferent types of frames\\nas output. In this way, the output of the model was directly one of\\nthe frames, and we avoided the step of matching adjectives with\\nframes. An example is shown in Figure 2.\\nFor the GPT-3 configuration 1, there are 3 main concepts:\\n\\u2022 TEMPERATURE \\n        \",\n        \"After testing with the GPT-3 playground and varying diferent\\nhyper-parameters to assess performance, we set the temperature to\\n0, since the higher the temperature the more random the response.\\nFurthermore, the Top-p parameter was set to 1, as it would likely\\nget a set of the most likely words for the model to choose from. The\\nmaximum number of tokens was set to 2; in this way, the model\\nis asked to choose between one of the responses. As a model, we\\nused the one with the best performance at the time of experimental\\ndesign, which was TEXT-DAVINCI-003, recognized as GPT 3.5.\\n5\"\n      ]\n    },\n    {\n      \"title\": \"RESULTS: HUMAN LABELING OF FRAMES\",\n      \"paragraphs\": []\n    },\n    {\n      \"title\": \"IN NO-VAX NEWS HEADLINES (RQ1)\",\n      \"paragraphs\": [\n        \"In this section, we present and discuss the results of the analysis\\nrelated to our first RQ.\",\n        \"Figure 3 shows the distribution of frames per country at headline\\nlevel, with human interest and no-frame being the predominant\\n1https://beta.openai.com/docs/introduction\\nones. Attribution of responsibility is the third one except in\\nSwitzerland, where the corresponding frame is conflict. Finally, morality\\nand economic are the least represented in the dataset for every\\ncountry.\",\n        \"The monthly distribution of frames aggregated for all countries\\nis shown in Fig. 4. We can see two big peaks, the first one in January\\n2021 and the second one in August 2021. In all countries, the\\nvaccination process started at the end of December 2020, so it makes\\nsense that the no-vax movement started to be more predominant in\\nthe news in January 2021. Human interest is the most predominant\\nframe. Manual inspection shows that this is because the headlines\\nare about personal cases of people who are pro- or anti- vaccine.\\nAttribution of responsibility is also present. Manual inspection\\nindicates that local politicians and health authorities had to make\\ndecisions about who could be vaccinated at the beginning of the\\nprocess. The second peak at the end of summer 2021 coincided\\nwith the health pass (also called Covid passport in some countries),\\nand we can observe a peak in the curve corresponding to the\\nconlfict frame, reflecting the demonstrations against the measure of\\nmandatory health passes taken by country governments.\",\n        \"\\n        In Figure 5, we compare the sentiment per frame and per country,\\nto understand if there were any major diferences. The sentiment\\nanalysis labels were obtained using BERT-sent from the Hugging\\nFace package \\n        \",\n        \"Switzerland, and the United Kingdom,\\n\\u2022 No frame: 20-30% of negative content.\",\n        \"Regarding the results of the annotation process, the fact that the\\ndistribution of the 6 frame types is relatively similar between\\ncountries suggests that the anti-vaccine movement issue was treated\\nin a similar way in these countries. The fact that human interest\\nis the most dominant frame indicates that this issue was treated\\nfrom a more human and emotional approach, with headlines about\\npersonal experiences, celebrities giving their opinion about\\nvaccination, and politicians defending vaccine policies. Moreover, the\\nreason for many headlines being classified as no-frame is partly\\ndue to how data was selected. We chose articles that contained\\nwords related to no-vax, either in the headline or in the article. This\\nresulted in many headlines not containing anything specific related\\nto no-vax, while the no-vax content was actually included in the\\nmain text of the corresponding articles.\",\n        \"It is worth mentioning that prior to obtaining the results, we had\\nexpected that attribution of responsibility would be among the most\\nprominent frames, since governments took many measures such as\\nmandatory health pass requirements to access certain sites; we had\\nalso expected that the conflict frame would be prominent, since\\nthere were many demonstrations in Europe. In reality, however,\\nthese frames categories were not reflected as frequently at the\\nheadline level.\",\n        \"Regarding the analysis at the temporal level, it is clear that certain\\nevents were captured by the press, such as the start of vaccination\\nor the mandatory vaccination passport.\",\n        \"\\n        Finally, the sentiment analysis of the diferent frames shows that\\nthe predominant tone in all of them is neutral or negative, with very\\nsimilar trends between countries. This association between\\nsentiment analysis and frames has been discussed in previous literature\\n\\n        \"\n      ]\n    },\n    {\n      \"title\": \"RESULTS: GPT-3.5 FOR FRAME\",\n      \"paragraphs\": []\n    },\n    {\n      \"title\": \"CLASSIFICATION OF HEADLINES (RQ2)\",\n      \"paragraphs\": [\n        \"Here, we present and discuss the results related to our second RQ.\\n6.1\"\n      ]\n    },\n    {\n      \"title\": \"Fine-tuning GPT-3.5\",\n      \"paragraphs\": [\n        \"Table 4 shows the results of the 6-class classification task using\\n5-cross validation. Three models were used: GPT-3.5 and two\\nBERTbased models. We observe that, on average, GPT-3.5 performs better\\nthan the BERT-based models. This is somehow expected as\\nGPT3.5 is a much larger model. Overall, in the case of fine-tuning, the\\nbest performance for the six-class frame classification task is 72%\\naccuracy, which is promising, with an improvement over previous\\nmodels based on BERT. Yet, it should be noted that the performance\\ndiferences are modest (2% improvement between GPT-3.5 and\\nRoBERTa).\",\n        \"On the other hand, BERT is open-source, while GPT-3 has an\\neconomic cost as the use of the model is not free, which monetarily\\nlimits the number of experiments that can be performed with it,\\nas well as the diferent configurations one can explore to improve\\nperformance. This is important because much of the improvement\\nin performance requires empirical explorations of model parameters\\nMore specifically, the cost of an experiment for each of the folds has\\na cost of 4 dollars (at the time of writing this paper.) This represents\\na limitation in practice.\",\n        \"\\n        Furthermore, GPT-3 has a significant carbon footprint. Similarly,\\nfor prompt engineering (discussed in the next subsection), choosing\\nthe right prompt (i.e., the words that best define the task so that the\\nmodel is able to perform adequately) is also based on trial and error.\\nThis also has an impact on carbon footprint. In connection with\\nthis topic, Strubell et al.\\n        \"\n      ]\n    },\n    {\n      \"title\": \"Prompt-engineering with GPT-3.5\",\n      \"paragraphs\": [\n        \"For each headline, we got the frame that the model considered the\\nmost likely, and we compared these GPT-3.5 inferences with the\\nframes labeled by the annotators. The agreement between model\\nand annotator was of 49%. Analyzing the results, and specifically\\nlooking at the cases where the annotator and GPT-3.5 disagreed,\\nwe discovered that according to the frame definitions, the model\\nin some cases proposed a frame that indeed made sense. This\\nobservation, together with our previous experience in the annotation\\nprocess, where headlines could have more than one valid frame,\\nled us to design a second post-hoc experiment. We took all the\\nheadlines where each of the two annotators had disagreed with\\nGPT-3.5, and we asked the annotators to state whether they would\\nagree (or not) with each GPT-inferred label for a given headline.\\nIt is important to emphasize that the annotators did not know the\\norigin of that label, i.e., they did not know if it was the label they\\nhad originally assigned, or if it was a random one. In this way, we\\ncould quantify how GPT-3.5 worked according to valid arguments\\nprovided by the annotators. In this post-hoc experiment, the model\\nagreed in 76% of cases with the annotators.\",\n        \"\\n        Looking at the results of the classification models, the 49%\\naccuracy of the prompt-engineering approach can be considered low,\\nyet we consider that it is a valid avenue for further investigation,\\nas in the second post-hoc analysis, we found that the model agrees\\nwith human annotators in 76% of the cases. Clearly, framing\\ninvolves aspects of subjectivity \\n        \",\n        \"\\n        News reading is never fully objective, and the annotators\\nengaged in the frame classification task, influenced by their personal\\nstate of mind, experience, and culture, may perceive information\\ndiferently. Monarch afirms that \\\"for simple tasks, like binary labels\\non objective tasks, the statistics are fairly straightforward to decide\\nwhich is the \\u2018correct\\u2019 label when diferent annotators disagree. But\\nfor subjective tasks, or even objective tasks with continuous data,\\nthere are no simple heuristics for deciding what the correct label\\nshould be\\\" \\n        \",\n        \"\\n        Subjectivity is involved in both the generation and perception\\nof information: the assumption that there is only one frame is\\ncomplicated by the point of view of the reader. In the case of news, the\\ninformation sender (the journalist) has an intention, but the receiver\\n(the reader) plays a role and is influenced by it. In psychology, this\\nis known as the lens model of interpersonal communication, where\\nthe sender has certain objectives, but the receiver can interpret\\nor re-interpret what the sender wants to say, with more or less\\naccuracy \\n        \",\n        \"Following this discussion on subjectivity, the question arose as to\\nwhat would happen if, instead of headlines, we used the complete\\narticle as a source of analysis. We wondered if longer text could\\nmake the frame labeling task clearer than when using headlines.\\nYet another possible hypothesis is that having to read longer texts\\ncould lead to the same subject being presented from diferent angles.\\nPlease recall that in the existing literature discussed in Section 2,\\nboth headlines and full articles have been used from frame analysis\\n(see Table 1.) This remains as an issue for future work.\\n7\"\n      ]\n    },\n    {\n      \"title\": \"CONCLUSIONS\",\n      \"paragraphs\": [\n        \"In this paper, we first presented an analysis of human-generated\\nnews frames on the covid-19 no-vax movement in Europe, and\\nthen studied diferent approaches using large language models for\\nautomatic inference of frames. We conclude by answering the two\\nresearch questions we posed:\",\n        \"RQ1: What are the main frames in the news headlines about the\\ncovid-19 anti-vaccine movement in 5 European countries? After\\nannotating the headlines, we found that of the 1786 headlines,\\nthe predominant frame is human interest (45.3% of cases), which\\npresents a news item with an emotional angle, putting a face to a\\nproblem or situation. We also found that a substantial proportion\\nof headlines were annotated as not presenting any frame (40.2% of\\ncases). Finally, the other frame types are found more infrequently.\",\n        \"RQ2: Can prompt engineering be used for classification of\\nheadlines according to frames? We first used fine-tuning of a number of\\nlanguage models, and found that GPT-3.5 produced classicfiation\\naccuracy of 72% on a six-frame classification task. This represented a\\nmodest 2% improvement over BERT-based models, at a significantly\\nlarger environmental cost. We then presented a new way of\\nclassifying frames using prompts. At the headline level, inferences made\\nwith GPT-3.5 reached 49% of agreement with human-generated\\nframe labels. In many cases, the GPT-3.5 model inferred frame\\ntypes that were considered as valid choices by human annotators,\\nand in an post-doc experiment, the human-machine agreement\\nreached 76%. These results have opened several new directions for\\nfuture work.\"\n      ]\n    },\n    {\n      \"title\": \"ACKNOWLEDGMENTS\",\n      \"paragraphs\": [\n        \"This work was supported by the AI4Media project, funded by the\\nEuropean Commission (Grant 951911) under the H2020 Programme\\nICT-48-2020. We also thank the newspapers for sharing their online\\narticles. Finally, we thank our colleagues Haeeun Kim and Emma\\nBouton-Bessac for their support with annotations, and Victor Bros\\nand Oleksii Polegkyi for discussions.\"\n      ]\n    }\n  ]\n}",
    "{\n  \"DocumentTitle\": \"Framing the News: From Human Perception to Large Language Model Inferences\",\n  \"Auteurs\": \"David Alonso del Barrio, Daniel Gatica-Perez, \",\n  \"Institutions\": \"Idiap Research Institute and EPFL, Idiap Research Institute, \",\n  \"Abstract\": \"\\n        \",\n  \"Sections\": [\n    {\n      \"title\": \"CCS CONCEPTS\",\n      \"paragraphs\": [\n        \"\\u2022 Computing methodologies \\u2192 Information extraction; \\u2022\\nHuman-centered computing \\u2192 Text input.\\nCovid-19 no-vax, news framing, GPT-3, prompt-engineering,\\ntransformers, large language models\\nPermission to make digital or hard copies of all or part of this work for personal or\\nclassroom use is granted without fee provided that copies are not made or distributed\\nfor profit or commercial advantage and that copies bear this notice and the full citation\\non the first page. Copyrights for components of this work owned by others than the\\nauthor(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or\\nrepublish, to post on servers or to redistribute to lists, requires prior specific permission\\nand/or a fee. Request permissions from permissions@acm.org.\",\n        \"ICMR \\u201923, June 12\\u201315, 2023, Thessaloniki, Greece\\n\\u00a9 2023 Copyright held by the owner/author(s). Publication rights licensed to ACM.\\nACM ISBN 979-8-4007-0178-8/23/06. . . $15.00\\nhttps://doi.org/10.1145/3591106.3592278\"\n      ]\n    },\n    {\n      \"title\": \"INTRODUCTION\",\n      \"paragraphs\": [\n        \"\\n        In recent years, there has been a proliferation in the use of concepts\\nsuch as data journalism, computational journalism, and\\ncomputerassisted reporting \\n        \",\n        \"Frame analysis is a concept from journalism, which consists of\\nstudying the way in which news stories are presented on an issue,\\nand what aspects are emphasized: Is a merely informative vision\\ngiven in an article? Or is it intended to leave a moral lesson? Is\\na news article being presented from an economic point of view?\\nOr from a more human, emotional angle? The examples above\\ncorrespond to diferent frames with which an article can be written.\",\n        \"\\n        The concept of news framing has been studied in computing as\\na step beyond topic modeling and sentiment analysis, and for this\\npurpose, in recent years, pre-trained language models have been\\nused for fine-tuning the classification process of these frames \\n        \",\n        \"Our work aims to address this research gap by posing the\\nfollowing research questions:\",\n        \"RQ1: What are the main frames in the news headlines about\\nthe anti-vaccine movement, as reported in newspapers across 5\\nEuropean countries?\",\n        \"RQ2: Can prompt engineering be used for classification of\\nheadlines according to frames?\",\n        \"By addressing the above research questions, our work makes the\\nfollowing contributions:\",\n        \"Contribution 1. We implemented a process to do human\\nannotation of the main frame of 1786 headlines of articles about the\\nCovid-19 no-vax movement, as reported in 19 newspapers from 5\\nEuropean countries (France, Italy, Spain, Switzerland and United\\nKingdom.) At the headline level, we found that the predominant\\nframe was human interest, where this frame corresponds to a\\npersonification of an event, either through a statement by a person,\\nor the explanation of a specific event that happened to a person.\\nFurthermore, we found a large number of headlines annotated as\\ncontaining no frame, as they simply present information without\\nentering into evaluations. We also found that for all the countries\\ninvolved, the distribution of frame types was very similar, i.e.,\\nhuman interest and no frame are the two predominant frames. Finally,\\nthe generated annotations allowed to subsequently study the\\nperformance of a large language model.\",\n        \"Contribution 2. We studied the performance of GPT-3.5 on\\nthe task of frame classification of headlines. In addition to using\\nthe fine-tuning approach from previous literature, we propose an\\nalternative approach for frame classification that requires no labeled\\ndata for training, namely prompt-engineering using GPT-3.5. The\\nresults show that fine-tuning with GPT-3.5 produces 72% accuracy\\n(slightly higher than other smaller models), and that the\\npromptengineering approach results in lower performance (49% accuracy.)\\nOur analysis also shows that the subjectivity of the human labeling\\ntask has an efect on the obtained accufracy.\",\n        \"The paper is organized as follows. In Section 2, we discuss related\\nwork. In Section 3, we describe the news dataset. In Section 4, we\\ndescribe the methodology for both human labeling and machine\\nclassification of news frames. We present and discuss results for\\nRQ1 and RQ2 in Sections 5 and 6, respectively. Finally, we provide\\nconclusions in Section 7.\\n2\"\n      ]\n    },\n    {\n      \"title\": \"RELATED WORK\",\n      \"paragraphs\": [\n        \"\\n        Framing has been a concept widely studied in journalism, with a\\ndefinition that is rooted in the study of this domain \\n        \",\n        \"\\n        For frame recognition, there are two main approaches: the\\ninductive approach \\n        \",\n        \"\\n        We now compare the two approaches on a common topic, such\\nas Covid-19. Ebrahim et al. \\n        \",\n        \"We decided to follow the deductive approach because a\\npredeifned list of frames allows to compare among topics, countries,\\nprevious literature, and also because they represent a fixed list of\\nlabels for machine classification models. Furthermore, the\\ninductive approach tends to be more specific to a topic, and from the\\ncomputing viewpoint, past work has tried to justify topic modeling\\nas a technique to extract frames from articles.\",\n        \"\\n        Yl\\u00e4-Antitila et al. \\n        \",\n        \"\\n        From Entman\\u2019s definition of frame \\n        \",\n        \"\\n        Isoaho et al.\\n        \",\n        \"\\n        We also consider that the larger the number of possible frame\\ntypes, the more likely it is to end up doing topic modeling instead of\\nframe analysis. Using a deductive approach, Dallas et al. \\n        \",\n        \"\\n        A final decision in our work was the type of text to analyze,\\nwhether headlines or whole article. For this decision, the chosen\\nclassification method was also going to be important. For example,\\nKhanehzar et al. \\n        \",\n        \"\\n        Continuing with the question of the methods used for\\nclassiifcation, much work has been developed in prompt engineering,\\nespecially since the release of GPT-3. Liu et al.\\n        \",\n        \"\\n        As mentioned before, the emergence of giant models like GPT-3,\\nBLOOM, and ChatGPT are a very active research topic. To the best\\nof our knowledge, on one hand our work extends the computational\\nanalysis of news related to the covid-19 no-vax movement, which\\nillustrates the influence of the press on the ways societies think\\nabout relevant issues \\n        \"\n      ]\n    },\n    {\n      \"title\": \"3 DATA: EUROPEAN COVID-19 NEWS\",\n      \"paragraphs\": []\n    },\n    {\n      \"title\": \"DATASET\",\n      \"paragraphs\": [\n        \"\\n        We used part of the European Covid-19 News dataset collected in\\nour recent work \\n        \",\n        \"In the first phase, annotators had to read the codebook and get\\nfamiliar with the task. In the second phase, they were asked to\\nidentify the main frame in the same subset of 50 headlines. At the\\nend of the second phase, the intercoder reliability (ICR) was 0.58\\nbetween the 2 annotators. We analyzed those cases where there\\nwere discrepancies, and observed that in some cases, there was not a\\nunique main frame, because both annotators had valid arguments to\\nselect one of the frames. In other cases, the discrepancies were due\\nto slight misunderstanding of the definitions. In the third phase, the\\nannotators coded again 50 headlines, and the ICR increased to was\\n0.66. We realized that the possibility of having two frames remained.\\nThey discussed the cases in which they had disagreed, and if the\\nother person\\u2019s arguments were considered valid, it could be said that\\nthere were two frames. After this three-phase training procedure,\\nannotators were ready to annotate the dataset independently. We\\ndivided the dataset into two equal parts, and each person annotated\\n893 headlines.\\n4.2\"\n      ]\n    },\n    {\n      \"title\": \"Fine-tuning GPT-3.5 and BERT-based models\",\n      \"paragraphs\": [\n        \"With the annotated dataset, we investigated two NLP approaches:\\nthe first one involves fine-tuning a pre-trained model; the second\\none is prompt engineering. Pre-trained language models have been\\ntrained with large text strings based on two unsupervised tasks,\\nnext sentence prediction and masked language model. Figure 1\\nsummarizes these techniques.\",\n        \"\\n        In the first approach, a model with a fixed architecture is\\npretrained as a language model (LM), predicting the likelihood of the\\nobserved textual data. This can be done due to the availability of\\nlarge, raw text data needed to train LMs. This learning process can\\nproduce general purpose features of the modeled language. The\\nlearning process produces robust, general-purpose features of the\\nlanguage being modeled. The above pre-trained LM is then adapted\\nto diferent downstream tasks, by introducing additional parameters\\nand adjusting them using task-specific objective functions. In this\\napproach, the focus was primarily on goal engineering, designing\\nthe training targets used in both the pre-training and the fine-tuning\\nstages \\n        \",\n        \"We present an example to illustrate the idea. Imagine that the\\ntask is sentiment analysis, and we have a dataset with sentences\\nand their associated sentiment, and a pre-trained model, which is a\\nsaved neural network trained with a much larger dataset. For that\\npre-trained model to address the target task, we unfreeze a few of\\nthe top layers of the saved model base and jointly train both the\\nnewly-added classifier layers and the last layers of the base model.\\nThis allows to \\\"fine-tune\\\" the higher-order feature representations\\nin the base model to make them more relevant for the sentiment\\nanalysis task. In this way, instead of having to obtain a very large\\ndataset with target labels to train a model, we can reuse the\\npretrained model and use a much smaller train dataset. We use a part\\nof our dataset as examples for the model to learn the task, while\\nthe other part of the dataset is used to evaluate model performance.\",\n        \"Previous works related to frame classification in the computing\\nliterature have used fine-tuning, BERT-based models. In our work,\\nwe have done the same as a baseline, but we aimed to go one step\\nfurther and also produce results using fine-tuning of GPT-3.5.\\n4.3\"\n      ]\n    },\n    {\n      \"title\": \"Prompt-engineering with GPT-3.5\",\n      \"paragraphs\": [\n        \"\\n        Model fine-tuning has been widely used, but with the emergence\\nof generative models such as GPT-3, another way to approach\\nclassification tasks has appeared. The idea is to use the pre-trained\\nmodel directly and convert the task to be performed into a format\\nas close as possible to the tasks for which it has been pre-trained.\\nThat is, if the model has been pre-trained from next word prediction\\nas in the case of GPT-3, classification can be done by defining a\\nprompt, where the input to the model is an incomplete sentence,\\nand the model must complete it with a word or several words, just\\nas it has been trained. This avoids having to use part of the already\\nlabeled dataset to teach the task to be performed to the model, and\\na previous labeling is not needed \\n        \",\n        \"\\n        In this approach, instead of adapting pre-trained LMs to\\ndownstream tasks via objective engineering, downstream tasks are\\nreformulated to look more like those solved during the original LM\\ntraining with the help of a textual prompt. For example, when\\nrecognizing the emotion of a social media post, \\u201cI missed the bus today.\\u201d,\\nwe may continue with a prompt \\u201cI felt so _\\u201d, and ask the LM to\\nifll the blank with an emotion-bearing word. Or if we choose the\\nprompt \\u201cEnglish: I missed the bus today. French: _\\u201d), an LM may\\nbe able to fill in the blank with a French translation. In this way,\\nby selecting the appropriate prompts, we can influence the model\\nbehavior so that the pre-trained LM itself can be used to predict the\\ndesired output, even without any additional task-specific training\\n\\n        \",\n        \"\\n        We use this emerging NLP approach to classify frames at headline\\nlevel. We are not aware of previous uses of this strategy to classify\\nframes as we propose here. The idea is the following. Prompt\\nengineering consists of giving a prompt to the model, and understands\\nthat prompt as an incomplete sentence. To do prompt\\nengineering with our dataset, we needed to define an appropriate prompt\\nthat would produce the headline frames as output. We defined\\nseveral experiments with the Playground of GPT-3, in order to find\\nthe best prompt for our task. In our initial experiments, we\\nfollowed existing approaches in prompt engineering to do sentiment\\nanalysis, where the individual answer was an adjective, and this\\nadjective was matched with a sentiment. In a similar fashion, we\\ndecided to build a thesaurus of adjectives that define each of the\\nframes. For instance, the human interest frame could be\\n\\u2019interesting\\u2019, \\u2019emotional\\u2019, \\u2019personal\\u2019, \\u2019human\\u2019. The conflict frame could be:\\n\\u2019conflictive\\u2019, \\u2019bellicose\\u2019, \\u2019troublesome\\u2019, \\u2019rowdy\\u2019, \\u2019quarrelsome\\u2019,\\n\\u2019troublemaker\\u2019, \\u2019agitator\\u2019, etc. After the list of adjectives was defined,\\nwe needed to define the prompt in order to get, as an answer, one\\nof the adjectives in our thesaurus to match them with the frame.\\nWe used the GPT-3 playground using the headline as input and\\nasking for the frame as output, but the strategy did not work. In\\nour final experiment, instead of giving the headline as input, we\\ngave the definitions of each type of frame plus the headline, and we\\nasked the model to choose between the diferent types of frames\\nas output. In this way, the output of the model was directly one of\\nthe frames, and we avoided the step of matching adjectives with\\nframes. An example is shown in Figure 2.\\nFor the GPT-3 configuration 1, there are 3 main concepts:\\n\\u2022 TEMPERATURE \\n        \",\n        \"After testing with the GPT-3 playground and varying diferent\\nhyper-parameters to assess performance, we set the temperature to\\n0, since the higher the temperature the more random the response.\\nFurthermore, the Top-p parameter was set to 1, as it would likely\\nget a set of the most likely words for the model to choose from. The\\nmaximum number of tokens was set to 2; in this way, the model\\nis asked to choose between one of the responses. As a model, we\\nused the one with the best performance at the time of experimental\\ndesign, which was TEXT-DAVINCI-003, recognized as GPT 3.5.\\n5\"\n      ]\n    },\n    {\n      \"title\": \"RESULTS: HUMAN LABELING OF FRAMES\",\n      \"paragraphs\": []\n    },\n    {\n      \"title\": \"IN NO-VAX NEWS HEADLINES (RQ1)\",\n      \"paragraphs\": [\n        \"In this section, we present and discuss the results of the analysis\\nrelated to our first RQ.\",\n        \"Figure 3 shows the distribution of frames per country at headline\\nlevel, with human interest and no-frame being the predominant\\n1https://beta.openai.com/docs/introduction\\nones. Attribution of responsibility is the third one except in\\nSwitzerland, where the corresponding frame is conflict. Finally, morality\\nand economic are the least represented in the dataset for every\\ncountry.\",\n        \"The monthly distribution of frames aggregated for all countries\\nis shown in Fig. 4. We can see two big peaks, the first one in January\\n2021 and the second one in August 2021. In all countries, the\\nvaccination process started at the end of December 2020, so it makes\\nsense that the no-vax movement started to be more predominant in\\nthe news in January 2021. Human interest is the most predominant\\nframe. Manual inspection shows that this is because the headlines\\nare about personal cases of people who are pro- or anti- vaccine.\\nAttribution of responsibility is also present. Manual inspection\\nindicates that local politicians and health authorities had to make\\ndecisions about who could be vaccinated at the beginning of the\\nprocess. The second peak at the end of summer 2021 coincided\\nwith the health pass (also called Covid passport in some countries),\\nand we can observe a peak in the curve corresponding to the\\nconlfict frame, reflecting the demonstrations against the measure of\\nmandatory health passes taken by country governments.\",\n        \"\\n        In Figure 5, we compare the sentiment per frame and per country,\\nto understand if there were any major diferences. The sentiment\\nanalysis labels were obtained using BERT-sent from the Hugging\\nFace package \\n        \",\n        \"Switzerland, and the United Kingdom,\\n\\u2022 No frame: 20-30% of negative content.\",\n        \"Regarding the results of the annotation process, the fact that the\\ndistribution of the 6 frame types is relatively similar between\\ncountries suggests that the anti-vaccine movement issue was treated\\nin a similar way in these countries. The fact that human interest\\nis the most dominant frame indicates that this issue was treated\\nfrom a more human and emotional approach, with headlines about\\npersonal experiences, celebrities giving their opinion about\\nvaccination, and politicians defending vaccine policies. Moreover, the\\nreason for many headlines being classified as no-frame is partly\\ndue to how data was selected. We chose articles that contained\\nwords related to no-vax, either in the headline or in the article. This\\nresulted in many headlines not containing anything specific related\\nto no-vax, while the no-vax content was actually included in the\\nmain text of the corresponding articles.\",\n        \"It is worth mentioning that prior to obtaining the results, we had\\nexpected that attribution of responsibility would be among the most\\nprominent frames, since governments took many measures such as\\nmandatory health pass requirements to access certain sites; we had\\nalso expected that the conflict frame would be prominent, since\\nthere were many demonstrations in Europe. In reality, however,\\nthese frames categories were not reflected as frequently at the\\nheadline level.\",\n        \"Regarding the analysis at the temporal level, it is clear that certain\\nevents were captured by the press, such as the start of vaccination\\nor the mandatory vaccination passport.\",\n        \"\\n        Finally, the sentiment analysis of the diferent frames shows that\\nthe predominant tone in all of them is neutral or negative, with very\\nsimilar trends between countries. This association between\\nsentiment analysis and frames has been discussed in previous literature\\n\\n        \"\n      ]\n    },\n    {\n      \"title\": \"RESULTS: GPT-3.5 FOR FRAME\",\n      \"paragraphs\": []\n    },\n    {\n      \"title\": \"CLASSIFICATION OF HEADLINES (RQ2)\",\n      \"paragraphs\": [\n        \"Here, we present and discuss the results related to our second RQ.\\n6.1\"\n      ]\n    },\n    {\n      \"title\": \"Fine-tuning GPT-3.5\",\n      \"paragraphs\": [\n        \"Table 4 shows the results of the 6-class classification task using\\n5-cross validation. Three models were used: GPT-3.5 and two\\nBERTbased models. We observe that, on average, GPT-3.5 performs better\\nthan the BERT-based models. This is somehow expected as\\nGPT3.5 is a much larger model. Overall, in the case of fine-tuning, the\\nbest performance for the six-class frame classification task is 72%\\naccuracy, which is promising, with an improvement over previous\\nmodels based on BERT. Yet, it should be noted that the performance\\ndiferences are modest (2% improvement between GPT-3.5 and\\nRoBERTa).\",\n        \"On the other hand, BERT is open-source, while GPT-3 has an\\neconomic cost as the use of the model is not free, which monetarily\\nlimits the number of experiments that can be performed with it,\\nas well as the diferent configurations one can explore to improve\\nperformance. This is important because much of the improvement\\nin performance requires empirical explorations of model parameters\\nMore specifically, the cost of an experiment for each of the folds has\\na cost of 4 dollars (at the time of writing this paper.) This represents\\na limitation in practice.\",\n        \"\\n        Furthermore, GPT-3 has a significant carbon footprint. Similarly,\\nfor prompt engineering (discussed in the next subsection), choosing\\nthe right prompt (i.e., the words that best define the task so that the\\nmodel is able to perform adequately) is also based on trial and error.\\nThis also has an impact on carbon footprint. In connection with\\nthis topic, Strubell et al.\\n        \"\n      ]\n    },\n    {\n      \"title\": \"Prompt-engineering with GPT-3.5\",\n      \"paragraphs\": [\n        \"For each headline, we got the frame that the model considered the\\nmost likely, and we compared these GPT-3.5 inferences with the\\nframes labeled by the annotators. The agreement between model\\nand annotator was of 49%. Analyzing the results, and specifically\\nlooking at the cases where the annotator and GPT-3.5 disagreed,\\nwe discovered that according to the frame definitions, the model\\nin some cases proposed a frame that indeed made sense. This\\nobservation, together with our previous experience in the annotation\\nprocess, where headlines could have more than one valid frame,\\nled us to design a second post-hoc experiment. We took all the\\nheadlines where each of the two annotators had disagreed with\\nGPT-3.5, and we asked the annotators to state whether they would\\nagree (or not) with each GPT-inferred label for a given headline.\\nIt is important to emphasize that the annotators did not know the\\norigin of that label, i.e., they did not know if it was the label they\\nhad originally assigned, or if it was a random one. In this way, we\\ncould quantify how GPT-3.5 worked according to valid arguments\\nprovided by the annotators. In this post-hoc experiment, the model\\nagreed in 76% of cases with the annotators.\",\n        \"\\n        Looking at the results of the classification models, the 49%\\naccuracy of the prompt-engineering approach can be considered low,\\nyet we consider that it is a valid avenue for further investigation,\\nas in the second post-hoc analysis, we found that the model agrees\\nwith human annotators in 76% of the cases. Clearly, framing\\ninvolves aspects of subjectivity \\n        \",\n        \"\\n        News reading is never fully objective, and the annotators\\nengaged in the frame classification task, influenced by their personal\\nstate of mind, experience, and culture, may perceive information\\ndiferently. Monarch afirms that \\\"for simple tasks, like binary labels\\non objective tasks, the statistics are fairly straightforward to decide\\nwhich is the \\u2018correct\\u2019 label when diferent annotators disagree. But\\nfor subjective tasks, or even objective tasks with continuous data,\\nthere are no simple heuristics for deciding what the correct label\\nshould be\\\" \\n        \",\n        \"\\n        Subjectivity is involved in both the generation and perception\\nof information: the assumption that there is only one frame is\\ncomplicated by the point of view of the reader. In the case of news, the\\ninformation sender (the journalist) has an intention, but the receiver\\n(the reader) plays a role and is influenced by it. In psychology, this\\nis known as the lens model of interpersonal communication, where\\nthe sender has certain objectives, but the receiver can interpret\\nor re-interpret what the sender wants to say, with more or less\\naccuracy \\n        \",\n        \"Following this discussion on subjectivity, the question arose as to\\nwhat would happen if, instead of headlines, we used the complete\\narticle as a source of analysis. We wondered if longer text could\\nmake the frame labeling task clearer than when using headlines.\\nYet another possible hypothesis is that having to read longer texts\\ncould lead to the same subject being presented from diferent angles.\\nPlease recall that in the existing literature discussed in Section 2,\\nboth headlines and full articles have been used from frame analysis\\n(see Table 1.) This remains as an issue for future work.\\n7\"\n      ]\n    },\n    {\n      \"title\": \"CONCLUSIONS\",\n      \"paragraphs\": [\n        \"In this paper, we first presented an analysis of human-generated\\nnews frames on the covid-19 no-vax movement in Europe, and\\nthen studied diferent approaches using large language models for\\nautomatic inference of frames. We conclude by answering the two\\nresearch questions we posed:\",\n        \"RQ1: What are the main frames in the news headlines about the\\ncovid-19 anti-vaccine movement in 5 European countries? After\\nannotating the headlines, we found that of the 1786 headlines,\\nthe predominant frame is human interest (45.3% of cases), which\\npresents a news item with an emotional angle, putting a face to a\\nproblem or situation. We also found that a substantial proportion\\nof headlines were annotated as not presenting any frame (40.2% of\\ncases). Finally, the other frame types are found more infrequently.\",\n        \"RQ2: Can prompt engineering be used for classification of\\nheadlines according to frames? We first used fine-tuning of a number of\\nlanguage models, and found that GPT-3.5 produced classicfiation\\naccuracy of 72% on a six-frame classification task. This represented a\\nmodest 2% improvement over BERT-based models, at a significantly\\nlarger environmental cost. We then presented a new way of\\nclassifying frames using prompts. At the headline level, inferences made\\nwith GPT-3.5 reached 49% of agreement with human-generated\\nframe labels. In many cases, the GPT-3.5 model inferred frame\\ntypes that were considered as valid choices by human annotators,\\nand in an post-doc experiment, the human-machine agreement\\nreached 76%. These results have opened several new directions for\\nfuture work.\"\n      ]\n    },\n    {\n      \"title\": \"ACKNOWLEDGMENTS\",\n      \"paragraphs\": [\n        \"This work was supported by the AI4Media project, funded by the\\nEuropean Commission (Grant 951911) under the H2020 Programme\\nICT-48-2020. We also thank the newspapers for sharing their online\\narticles. Finally, we thank our colleagues Haeeun Kim and Emma\\nBouton-Bessac for their support with annotations, and Victor Bros\\nand Oleksii Polegkyi for discussions.\"\n      ]\n    }\n  ]\n}"
  ]
}