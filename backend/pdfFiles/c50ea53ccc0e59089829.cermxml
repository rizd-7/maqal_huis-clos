<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.0 20120330//EN" "JATS-archivearticle1.dtd">
<article xmlns:xlink="http://www.w3.org/1999/xlink">
  <front>
    <journal-meta>
      <journal-title-group>
        <journal-title>June</journal-title>
      </journal-title-group>
    </journal-meta>
    <article-meta>
      <title-group>
        <article-title>Framing the News: From Human Perception to Large Language Model Inferences</article-title>
      </title-group>
      <contrib-group>
        <contrib contrib-type="author">
          <string-name>David Alonso del Barrio</string-name>
          <email>ddbarrio@idiap.ch</email>
          <xref ref-type="aff" rid="aff1">1</xref>
        </contrib>
        <contrib contrib-type="author">
          <string-name>Daniel Gatica-Perez</string-name>
          <email>gatica@idiap.ch</email>
          <xref ref-type="aff" rid="aff0">0</xref>
        </contrib>
        <aff id="aff0">
          <label>0</label>
          <institution>Idiap Research Institute and EPFL</institution>
          ,
          <country country="CH">Switzerland</country>
        </aff>
        <aff id="aff1">
          <label>1</label>
          <institution>Idiap Research Institute</institution>
          ,
          <country country="CH">Switzerland</country>
        </aff>
      </contrib-group>
      <pub-date>
        <year>2023</year>
      </pub-date>
      <volume>1</volume>
      <fpage>2</fpage>
      <lpage>15</lpage>
      <abstract>
        <p />
      </abstract>
    </article-meta>
  </front>
  <body>
    <fig>
      <graphic xlink:href="pdfFiles\c50ea53ccc0e59089829.images\img_1_1.png" />
    </fig>
    <fig>
      <graphic xlink:href="pdfFiles\c50ea53ccc0e59089829.images\img_4_1.png" />
    </fig>
    <fig>
      <graphic xlink:href="pdfFiles\c50ea53ccc0e59089829.images\img_5_1.png" />
    </fig>
    <fig>
      <graphic xlink:href="pdfFiles\c50ea53ccc0e59089829.images\img_6_1.png" />
    </fig>
    <fig>
      <graphic xlink:href="pdfFiles\c50ea53ccc0e59089829.images\img_6_2.png" />
    </fig>
    <fig>
      <graphic xlink:href="pdfFiles\c50ea53ccc0e59089829.images\img_6_3.png" />
    </fig>
    <sec id="sec-1">
      <title>CCS CONCEPTS</title>
      <p>• Computing methodologies → Information extraction; •
Human-centered computing → Text input.
Covid-19 no-vax, news framing, GPT-3, prompt-engineering,
transformers, large language models
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for components of this work owned by others than the
author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or
republish, to post on servers or to redistribute to lists, requires prior specific permission
and/or a fee. Request permissions from permissions@acm.org.</p>
      <p>ICMR ’23, June 12–15, 2023, Thessaloniki, Greece
© 2023 Copyright held by the owner/author(s). Publication rights licensed to ACM.
ACM ISBN 979-8-4007-0178-8/23/06. . . $15.00
https://doi.org/10.1145/3591106.3592278</p>
    </sec>
    <sec id="sec-2">
      <title>INTRODUCTION</title>
      <p>
        In recent years, there has been a proliferation in the use of concepts
such as data journalism, computational journalism, and
computerassisted reporting [
        <xref ref-type="bibr" rid="ref15">15</xref>
        ] [
        <xref ref-type="bibr" rid="ref29">29</xref>
        ], which all share the vision of bridging
journalism and technology. The progress made in NLP has been
gradually integrated into the journalistic field [
        <xref ref-type="bibr" rid="ref5">5</xref>
        ][
        <xref ref-type="bibr" rid="ref8">8</xref>
        ][
        <xref ref-type="bibr" rid="ref54">54</xref>
        ]. More
specifically, machine learning models based on transformers have
been integrated in the media sector in diferent tasks [
        <xref ref-type="bibr" rid="ref41">41</xref>
        ] such as
the creation of headlines with generative languages models [
        <xref ref-type="bibr" rid="ref17">17</xref>
        ],
summarization of news articles [
        <xref ref-type="bibr" rid="ref28">28</xref>
        ][
        <xref ref-type="bibr" rid="ref27">27</xref>
        ], false news detection [
        <xref ref-type="bibr" rid="ref49">49</xref>
        ],
and topic modeling and sentiment analysis [
        <xref ref-type="bibr" rid="ref25">25</xref>
        ]. The development of
large language models such as GPT-3 [
        <xref ref-type="bibr" rid="ref9">9</xref>
        ], BLOOM [
        <xref ref-type="bibr" rid="ref51">51</xref>
        ] or ChatGPT
show a clear trend towards human-machine interaction becoming
easier and more intuitive, opening up a wide range of research
possibilities. At the same time, the use of these models is also
associated with a lack of transparency regarding how these models
work, but eforts are being made to bring some transparency to
these models, and to analyze use cases where they can be useful and
where they cannot [
        <xref ref-type="bibr" rid="ref35">35</xref>
        ]. Based on the premises that these models
open up a wide range of research directions [
        <xref ref-type="bibr" rid="ref7">7</xref>
        ], and that at the same
time (and needless to say) they are not the solution to all problems,
we are interested in identifying use cases and tasks where they
can be potentially useful, while acknowledging and systematically
documenting their limitations [
        <xref ref-type="bibr" rid="ref56">56</xref>
        ]. More specifically, the aim of
this work is to analyze the performance of GPT-3.5 for a specific
use case, namely the analysis of frames in news, from an empirical
point of view, with the objective of shedding light on a potential
use of generative models in journalistic tasks.
      </p>
      <p>Frame analysis is a concept from journalism, which consists of
studying the way in which news stories are presented on an issue,
and what aspects are emphasized: Is a merely informative vision
given in an article? Or is it intended to leave a moral lesson? Is
a news article being presented from an economic point of view?
Or from a more human, emotional angle? The examples above
correspond to diferent frames with which an article can be written.</p>
      <p>
        The concept of news framing has been studied in computing as
a step beyond topic modeling and sentiment analysis, and for this
purpose, in recent years, pre-trained language models have been
used for fine-tuning the classification process of these frames [
        <xref ref-type="bibr" rid="ref60">60</xref>
        ]
[
        <xref ref-type="bibr" rid="ref10">10</xref>
        ], but the emergence of generative models opens the possibility
of doing prompt-engineering of these classification tasks, instead
of the fine-tuning approach investigated so far.
      </p>
      <p>Our work aims to address this research gap by posing the
following research questions:</p>
      <p>RQ1: What are the main frames in the news headlines about
the anti-vaccine movement, as reported in newspapers across 5
European countries?</p>
      <p>RQ2: Can prompt engineering be used for classification of
headlines according to frames?</p>
      <p>By addressing the above research questions, our work makes the
following contributions:</p>
      <p>Contribution 1. We implemented a process to do human
annotation of the main frame of 1786 headlines of articles about the
Covid-19 no-vax movement, as reported in 19 newspapers from 5
European countries (France, Italy, Spain, Switzerland and United
Kingdom.) At the headline level, we found that the predominant
frame was human interest, where this frame corresponds to a
personification of an event, either through a statement by a person,
or the explanation of a specific event that happened to a person.
Furthermore, we found a large number of headlines annotated as
containing no frame, as they simply present information without
entering into evaluations. We also found that for all the countries
involved, the distribution of frame types was very similar, i.e.,
human interest and no frame are the two predominant frames. Finally,
the generated annotations allowed to subsequently study the
performance of a large language model.</p>
      <p>Contribution 2. We studied the performance of GPT-3.5 on
the task of frame classification of headlines. In addition to using
the fine-tuning approach from previous literature, we propose an
alternative approach for frame classification that requires no labeled
data for training, namely prompt-engineering using GPT-3.5. The
results show that fine-tuning with GPT-3.5 produces 72% accuracy
(slightly higher than other smaller models), and that the
promptengineering approach results in lower performance (49% accuracy.)
Our analysis also shows that the subjectivity of the human labeling
task has an efect on the obtained accufracy.</p>
      <p>The paper is organized as follows. In Section 2, we discuss related
work. In Section 3, we describe the news dataset. In Section 4, we
describe the methodology for both human labeling and machine
classification of news frames. We present and discuss results for
RQ1 and RQ2 in Sections 5 and 6, respectively. Finally, we provide
conclusions in Section 7.
2</p>
    </sec>
    <sec id="sec-3">
      <title>RELATED WORK</title>
      <p>
        Framing has been a concept widely studied in journalism, with a
definition that is rooted in the study of this domain [
        <xref ref-type="bibr" rid="ref23">23</xref>
        ]: “To frame
is to select some aspects of a perceived reality and make them more
salient in a communicating text, in such a way as to promote a
particular problem definition, causal interpretation, moral evaluation,
and/or treatment recommendation for the item described.”
      </p>
      <p>
        For frame recognition, there are two main approaches: the
inductive approach [
        <xref ref-type="bibr" rid="ref16">16</xref>
        ], where one can extract the frames after reading
the article, and the deductive approach [
        <xref ref-type="bibr" rid="ref38">38</xref>
        ], where a predefined
list of frames exists and the goal is to interpret if any of them
appears in the article. In the deductive case, there are generic frames
and subject-specific frames, and the way to detect them typically
involves reading and identifying one frame at a time, or through
answers to yes/no questions that represent the frames. Semetko et
al. [
        <xref ref-type="bibr" rid="ref52">52</xref>
        ] used 5 types of generic frames (attribution of responsibility,
human interest, conflict, morality, and economic consequences)
based on previous literature, and they defined a list of 20 yes/no
questions to detect frames in articles. For instance, the questions
about morality are the following: "Does the story contain any moral
message? Does the story make reference to morality, God, and other
religious tenets? Does the story ofer specific social prescriptions
about how to behave?", and so on for each of the frame types. This
categorization of frames has been used in various topics such as
climate change [
        <xref ref-type="bibr" rid="ref18">18</xref>
        ] [
        <xref ref-type="bibr" rid="ref19">19</xref>
        ], vaccine hesitance [
        <xref ref-type="bibr" rid="ref13">13</xref>
        ], or immigration
[
        <xref ref-type="bibr" rid="ref34">34</xref>
        ].
      </p>
      <p>
        We now compare the two approaches on a common topic, such
as Covid-19. Ebrahim et al. [
        <xref ref-type="bibr" rid="ref21">21</xref>
        ] followed an inductive approach
in which the frames were not predefined but emerged from the
text (e.g., deadly spread, stay home, what if, the cost of Covid-19)
using headlines as the unit of analysis. In contrast, the deductive
approach has studied very diferent labels. El-Behary et al. [
        <xref ref-type="bibr" rid="ref22">22</xref>
        ]
followed the method of yes/no questions, but in addition to the
5 generic frames presented before, they also used blame frame
and fear frame. Adiprasetio et al. [
        <xref ref-type="bibr" rid="ref1">1</xref>
        ] and Rodelo [
        <xref ref-type="bibr" rid="ref50">50</xref>
        ] used the 5
generic frames with yes/no questions, while Catalán-Matamoros et
al. [
        <xref ref-type="bibr" rid="ref14">14</xref>
        ] used the 5 frames and read the headline and subheadline
to decide the main frame. Table 1 summarizes some of the the
existing approaches. This previous work showed how frame labels
can be diferent, and also that frame analysis has been done at both
headline and article levels. These two approaches (inductive and
deductive) that originated in journalism have since been replicated
in the computing literature.
      </p>
      <p>We decided to follow the deductive approach because a
predeifned list of frames allows to compare among topics, countries,
previous literature, and also because they represent a fixed list of
labels for machine classification models. Furthermore, the
inductive approach tends to be more specific to a topic, and from the
computing viewpoint, past work has tried to justify topic modeling
as a technique to extract frames from articles.</p>
      <p>
        Ylä-Antitila et al. [
        <xref ref-type="bibr" rid="ref60">60</xref>
        ] proposed topic modeling as a frame
extraction technique. They argued that topics can be interpreted as
frames if three requirements are met: frames are operationalized as
connections between concepts; subject-specific data is selected; and
topics are adequately validated as frames, for which they suggested
a practical procedure. This approach was based on the choice of a
specific topic (e.g., climate change) and the use of Latent Dirichlet
Allocation (LDA) as a technique to extract a number of subtopics.
In a second phase, a qualitative study of the top 10 words of each
subtopic was performed, and the diferent subtopics were
eliminated or grouped, reducing the number and establishing a tentative
description. In a third phase, the top 10 articles belonging to that
frame/topic were taken, and if the description of the topic fitted
at least 8 of the 10 articles, that topic/frame remained. The frames
found in this article were: green growth, emission cuts, negotiations
and treaties, environmental risk, cost of carbon emissions, Chinese
emissions, economics of energy production, climate change,
environmental activism, North-South burden sharing, state leaders
negotiating, and citizen participation.
      </p>
      <p>
        From Entman’s definition of frame [
        <xref ref-type="bibr" rid="ref23">23</xref>
        ], it seems that the
deductive approach is more refined than the inductive approach (which
seems to resemble the detection of sub-themes.) For example, with
regard to climate change, there are stories on how people have been
afected by climate change from an emotional point of view, thus
personalizing the problem. In this case, we could categorize the
corresponding frame as human interest, as the writer of the article
is selecting "some aspects of a perceived reality and make them
more salient". The language subtleties with which news articles are
presented cannot be captured with basic topic modeling.
      </p>
      <p>
        Isoaho et al.[
        <xref ref-type="bibr" rid="ref30">30</xref>
        ] held the position that while the benefits of
scale and scope in topic modeling were clear, there were also a
number of problems, namely that topic outputs do not correspond
to the methodological definition of frames, and thus topic modeling
remained an incomplete method for frame analysis. Topic modeling,
in the practice of journalistic research, is a useful technique to deal
with the large datasets that are available, yet is often not enough to
do more thorough analyses [
        <xref ref-type="bibr" rid="ref31">31</xref>
        ]. In our work, we clearly notice that
frame analysis is not topic modeling. For example, two documents
could be about the same topic, say Covid-19 vaccination, but one
article could emphasize the number of deaths after vaccination,
while the other emphasized the role of the vaccine as a solution to
the epidemic.
      </p>
      <p>
        We also consider that the larger the number of possible frame
types, the more likely it is to end up doing topic modeling instead of
frame analysis. Using a deductive approach, Dallas et al. [
        <xref ref-type="bibr" rid="ref12">12</xref>
        ] created
a dataset with articles about polemic topics such as immigration,
same sex marriage, or smoking, and they defined 15 types of frames:
"economic, capacity and resources, morality, fairness and equality,
legality, constitutionality and jurisprudence, policy prescription and
evaluation, crime and punishment, security and defense, health and
safety, quality of life, cultural identity, political, external regulation
and reputation, other". In this case, they authors did not use a list
of questions. Instead, for each article, annotators were asked to
identify any of the 15 framing dimensions present in the article
and to label text blurbs that cued them (based on the definitions of
each of the frame dimensions) and decide the main frame of each
article. In our case, we followed the idea of detecting the main frame
by reading the text instead of answering questions, but instead of
using the 15 frames proposed in [
        <xref ref-type="bibr" rid="ref12">12</xref>
        ] , we used the 5 generic frames
proposed in [
        <xref ref-type="bibr" rid="ref52">52</xref>
        ].
      </p>
      <p>
        A final decision in our work was the type of text to analyze,
whether headlines or whole article. For this decision, the chosen
classification method was also going to be important. For example,
Khanehzar et al. [
        <xref ref-type="bibr" rid="ref33">33</xref>
        ] used traditional approaches such as SVMs as
baseline, and demonstrated the improvement in frame
classification with the use of pre-trained languages models such as BERT,
RoBERTa and XLNet, following a fine-tuning approach, setting
as input text a maximum of 256 tokens (although the maximum
number of input tokens in these models is 512 tokens.) Liu et al.
[
        <xref ref-type="bibr" rid="ref37">37</xref>
        ] classified news headlines about the gun problem in the United
States, arguing for the choice of headlines as a unit of analysis
based on previous journalism literature [
        <xref ref-type="bibr" rid="ref6">6</xref>
        ], [
        <xref ref-type="bibr" rid="ref44">44</xref>
        ], that advocated
for the importance and influence of headlines on readers and the
subsequent perception of articles. From a computational viewpoint,
using headlines is also an advantage, since you avoid the 512 token
limitation in BERT-based models. Therefore, we decided to work
with headlines about a controversial issue, namely the Covid-19
no-vax movement.
      </p>
      <p>
        Continuing with the question of the methods used for
classiifcation, much work has been developed in prompt engineering,
especially since the release of GPT-3. Liu et al.[
        <xref ref-type="bibr" rid="ref36">36</xref>
        ] presented a good
overview of the work done on this new NLP paradigm, not only
explaining the concept of prompt engineering, but also the
diferent strategies that can be followed both in the design of prompts,
the potential applications, and the challenges to face when using
this approach. Prompt engineering applications include knowledge
probing [
        <xref ref-type="bibr" rid="ref46">46</xref>
        ], information extraction [
        <xref ref-type="bibr" rid="ref53">53</xref>
        ], NLP reasoning [
        <xref ref-type="bibr" rid="ref57">57</xref>
        ],
question answering [
        <xref ref-type="bibr" rid="ref32">32</xref>
        ], text generation [
        <xref ref-type="bibr" rid="ref20">20</xref>
        ], multi-modal learning [
        <xref ref-type="bibr" rid="ref58">58</xref>
        ],
and text classification [
        <xref ref-type="bibr" rid="ref24">24</xref>
        ], the latter being the prompt-engineering
use case in our work. Puri et al.[
        <xref ref-type="bibr" rid="ref45">45</xref>
        ] presented a very interesting
idea that we apply to our classification task. This consists of
providing the language model with natural language descriptions of
classification tasks as input, and training it to generate the correct
answer in natural language via a language modeling objective. It is
a zero-shot learning approach, in which no examples are used to
explain the task to the model. Radford et al. [
        <xref ref-type="bibr" rid="ref48">48</xref>
        ] demonstrated that
language models can learn tasks without any explicit supervision.
We have followed this approach to find an alternative way to do
frame analysis.
      </p>
      <p>
        As mentioned before, the emergence of giant models like GPT-3,
BLOOM, and ChatGPT are a very active research topic. To the best
of our knowledge, on one hand our work extends the computational
analysis of news related to the covid-19 no-vax movement, which
illustrates the influence of the press on the ways societies think
about relevant issues [
        <xref ref-type="bibr" rid="ref40">40</xref>
        ], [
        <xref ref-type="bibr" rid="ref59">59</xref>
        ], and on the other hand it adds to
the literature of human-machine interaction, regarding the design
of GPT-3 prompts for classification tasks [
        <xref ref-type="bibr" rid="ref39">39</xref>
        ], [
        <xref ref-type="bibr" rid="ref2">2</xref>
        ].
      </p>
    </sec>
    <sec id="sec-4">
      <title>3 DATA: EUROPEAN COVID-19 NEWS</title>
    </sec>
    <sec id="sec-5">
      <title>DATASET</title>
      <p>
        We used part of the European Covid-19 News dataset collected in
our recent work [
        <xref ref-type="bibr" rid="ref3">3</xref>
        ]. This dataset contains 51320 articles on
Covid19 vaccination from 19 newspapers from 5 diferent countries: Italy,
France, Spain, Switzerland and UK. The articles cover a time period
of 22 months, from January 2020 to October 2021. All content was
translated into English to be able to work in a common language.
The dataset was used for various analyses, such as name entity
recognition, sentiment analysis, and subtopic modeling, to
understand how Covid-19 vaccination was reported in Europe through
the print media (in digital format.) The subtopic modeling analysis
revealed a subsample of articles on the no-vax movement, which is
the one we have used in this paper. We took the headlines of the
articles associated with the no-vax movement, selecting all articles
containing any of the keywords in Table 2 in the headline or in the
main text. This corresponds to a total of 1786 headlines.
In Table 3, we show the number of headlines per country and
newspaper. France is the country with the most no-vax articles in
the corpus, with 523 articles, followed by Italy with 508. However,
note that there are 6 newspapers from France, while only 2 from
Italy. Corriere della Sera is the newspaper that dealt most frequently
with the subject (429 articles), while The Telegraph is the second
one (206 articles). The total number of articles normalized by the
number of newspapers per country is also shown in the last column
of the Table. Using these normalized values, the ranking is Italy,
UK, France, Switzerland, and Spain.
To carry out the labeling of the frames in our corpus of headlines, we
ifrst designed a codebook, which contained the definitions of each
of the frame types and a couple of examples of each type, as well
as a definition of the corpus subject matter and definitions of the
concept of frame analysis, so that the annotators could understand
the task to be performed. The codebook follows the proposed by
[
        <xref ref-type="bibr" rid="ref52">52</xref>
        ] with 5 generic frames (attribution of responsibility, human
interest, conflict, morality, and economic consequences) plus one
additional ’no-frame’ category. Two researchers were engaged to
annotate a sample of the collected newspaper articles following a
three-phase training procedure.
      </p>
      <p>In the first phase, annotators had to read the codebook and get
familiar with the task. In the second phase, they were asked to
identify the main frame in the same subset of 50 headlines. At the
end of the second phase, the intercoder reliability (ICR) was 0.58
between the 2 annotators. We analyzed those cases where there
were discrepancies, and observed that in some cases, there was not a
unique main frame, because both annotators had valid arguments to
select one of the frames. In other cases, the discrepancies were due
to slight misunderstanding of the definitions. In the third phase, the
annotators coded again 50 headlines, and the ICR increased to was
0.66. We realized that the possibility of having two frames remained.
They discussed the cases in which they had disagreed, and if the
other person’s arguments were considered valid, it could be said that
there were two frames. After this three-phase training procedure,
annotators were ready to annotate the dataset independently. We
divided the dataset into two equal parts, and each person annotated
893 headlines.
4.2</p>
    </sec>
    <sec id="sec-6">
      <title>Fine-tuning GPT-3.5 and BERT-based models</title>
      <p>With the annotated dataset, we investigated two NLP approaches:
the first one involves fine-tuning a pre-trained model; the second
one is prompt engineering. Pre-trained language models have been
trained with large text strings based on two unsupervised tasks,
next sentence prediction and masked language model. Figure 1
summarizes these techniques.</p>
      <p>
        In the first approach, a model with a fixed architecture is
pretrained as a language model (LM), predicting the likelihood of the
observed textual data. This can be done due to the availability of
large, raw text data needed to train LMs. This learning process can
produce general purpose features of the modeled language. The
learning process produces robust, general-purpose features of the
language being modeled. The above pre-trained LM is then adapted
to diferent downstream tasks, by introducing additional parameters
and adjusting them using task-specific objective functions. In this
approach, the focus was primarily on goal engineering, designing
the training targets used in both the pre-training and the fine-tuning
stages [
        <xref ref-type="bibr" rid="ref36">36</xref>
        ].
      </p>
      <p>We present an example to illustrate the idea. Imagine that the
task is sentiment analysis, and we have a dataset with sentences
and their associated sentiment, and a pre-trained model, which is a
saved neural network trained with a much larger dataset. For that
pre-trained model to address the target task, we unfreeze a few of
the top layers of the saved model base and jointly train both the
newly-added classifier layers and the last layers of the base model.
This allows to "fine-tune" the higher-order feature representations
in the base model to make them more relevant for the sentiment
analysis task. In this way, instead of having to obtain a very large
dataset with target labels to train a model, we can reuse the
pretrained model and use a much smaller train dataset. We use a part
of our dataset as examples for the model to learn the task, while
the other part of the dataset is used to evaluate model performance.</p>
      <p>Previous works related to frame classification in the computing
literature have used fine-tuning, BERT-based models. In our work,
we have done the same as a baseline, but we aimed to go one step
further and also produce results using fine-tuning of GPT-3.5.
4.3</p>
    </sec>
    <sec id="sec-7">
      <title>Prompt-engineering with GPT-3.5</title>
      <p>
        Model fine-tuning has been widely used, but with the emergence
of generative models such as GPT-3, another way to approach
classification tasks has appeared. The idea is to use the pre-trained
model directly and convert the task to be performed into a format
as close as possible to the tasks for which it has been pre-trained.
That is, if the model has been pre-trained from next word prediction
as in the case of GPT-3, classification can be done by defining a
prompt, where the input to the model is an incomplete sentence,
and the model must complete it with a word or several words, just
as it has been trained. This avoids having to use part of the already
labeled dataset to teach the task to be performed to the model, and
a previous labeling is not needed [
        <xref ref-type="bibr" rid="ref36">36</xref>
        ].
      </p>
      <p>
        In this approach, instead of adapting pre-trained LMs to
downstream tasks via objective engineering, downstream tasks are
reformulated to look more like those solved during the original LM
training with the help of a textual prompt. For example, when
recognizing the emotion of a social media post, “I missed the bus today.”,
we may continue with a prompt “I felt so _”, and ask the LM to
ifll the blank with an emotion-bearing word. Or if we choose the
prompt “English: I missed the bus today. French: _”), an LM may
be able to fill in the blank with a French translation. In this way,
by selecting the appropriate prompts, we can influence the model
behavior so that the pre-trained LM itself can be used to predict the
desired output, even without any additional task-specific training
[
        <xref ref-type="bibr" rid="ref36">36</xref>
        ].
      </p>
      <p>
        We use this emerging NLP approach to classify frames at headline
level. We are not aware of previous uses of this strategy to classify
frames as we propose here. The idea is the following. Prompt
engineering consists of giving a prompt to the model, and understands
that prompt as an incomplete sentence. To do prompt
engineering with our dataset, we needed to define an appropriate prompt
that would produce the headline frames as output. We defined
several experiments with the Playground of GPT-3, in order to find
the best prompt for our task. In our initial experiments, we
followed existing approaches in prompt engineering to do sentiment
analysis, where the individual answer was an adjective, and this
adjective was matched with a sentiment. In a similar fashion, we
decided to build a thesaurus of adjectives that define each of the
frames. For instance, the human interest frame could be
’interesting’, ’emotional’, ’personal’, ’human’. The conflict frame could be:
’conflictive’, ’bellicose’, ’troublesome’, ’rowdy’, ’quarrelsome’,
’troublemaker’, ’agitator’, etc. After the list of adjectives was defined,
we needed to define the prompt in order to get, as an answer, one
of the adjectives in our thesaurus to match them with the frame.
We used the GPT-3 playground using the headline as input and
asking for the frame as output, but the strategy did not work. In
our final experiment, instead of giving the headline as input, we
gave the definitions of each type of frame plus the headline, and we
asked the model to choose between the diferent types of frames
as output. In this way, the output of the model was directly one of
the frames, and we avoided the step of matching adjectives with
frames. An example is shown in Figure 2.
For the GPT-3 configuration 1, there are 3 main concepts:
• TEMPERATURE [
        <xref ref-type="bibr" rid="ref1">0-1</xref>
        ]. This parameter controls randomness,
lowering it results in less random completions.
• TOP_P [
        <xref ref-type="bibr" rid="ref1">0-1</xref>
        ]. This parameter controls diversity via nucleus
sampling.
• MAX_TOKENS[
        <xref ref-type="bibr" rid="ref1 ref10 ref11 ref12 ref13 ref14 ref15 ref16 ref17 ref18 ref19 ref2 ref20 ref21 ref22 ref23 ref24 ref25 ref26 ref27 ref28 ref29 ref3 ref30 ref31 ref32 ref33 ref34 ref35 ref36 ref37 ref38 ref39 ref4 ref40 ref41 ref42 ref43 ref44 ref45 ref46 ref47 ref48 ref49 ref5 ref50 ref51 ref52 ref53 ref54 ref55 ref56 ref57 ref58 ref59 ref6 ref60 ref7 ref8 ref9">1-4000</xref>
        ]. This parameter indicates the
maximum number of tokens to generate,
• MODEL. GPT-3 ofer four main models with diferent levels
of power, suitable for diferent tasks. Davinci is the most
capable model, and Ada is the fastest.
      </p>
      <p>After testing with the GPT-3 playground and varying diferent
hyper-parameters to assess performance, we set the temperature to
0, since the higher the temperature the more random the response.
Furthermore, the Top-p parameter was set to 1, as it would likely
get a set of the most likely words for the model to choose from. The
maximum number of tokens was set to 2; in this way, the model
is asked to choose between one of the responses. As a model, we
used the one with the best performance at the time of experimental
design, which was TEXT-DAVINCI-003, recognized as GPT 3.5.
5</p>
    </sec>
    <sec id="sec-8">
      <title>RESULTS: HUMAN LABELING OF FRAMES</title>
    </sec>
    <sec id="sec-9">
      <title>IN NO-VAX NEWS HEADLINES (RQ1)</title>
      <p>In this section, we present and discuss the results of the analysis
related to our first RQ.</p>
      <p>Figure 3 shows the distribution of frames per country at headline
level, with human interest and no-frame being the predominant
1https://beta.openai.com/docs/introduction
ones. Attribution of responsibility is the third one except in
Switzerland, where the corresponding frame is conflict. Finally, morality
and economic are the least represented in the dataset for every
country.</p>
      <p>The monthly distribution of frames aggregated for all countries
is shown in Fig. 4. We can see two big peaks, the first one in January
2021 and the second one in August 2021. In all countries, the
vaccination process started at the end of December 2020, so it makes
sense that the no-vax movement started to be more predominant in
the news in January 2021. Human interest is the most predominant
frame. Manual inspection shows that this is because the headlines
are about personal cases of people who are pro- or anti- vaccine.
Attribution of responsibility is also present. Manual inspection
indicates that local politicians and health authorities had to make
decisions about who could be vaccinated at the beginning of the
process. The second peak at the end of summer 2021 coincided
with the health pass (also called Covid passport in some countries),
and we can observe a peak in the curve corresponding to the
conlfict frame, reflecting the demonstrations against the measure of
mandatory health passes taken by country governments.</p>
      <p>
        In Figure 5, we compare the sentiment per frame and per country,
to understand if there were any major diferences. The sentiment
analysis labels were obtained using BERT-sent from the Hugging
Face package [
        <xref ref-type="bibr" rid="ref47">47</xref>
        ], used in our previous work (please refer to our
original analysis in [
        <xref ref-type="bibr" rid="ref3">3</xref>
        ] for details.) We normalized the results
between 0 and 1 to compare frames between countries. We see that the
sentiment is predominantly neutral (in blue). Examining in more
detail the negative and positive sentiment of each frame category,
we observed a few trends:
• Attribution of responsibility: Negative sentiment represents
30-40% of the cases, while positive tone is only found in
residual form in Italy, Switzerland, and the United Kingdom.
• Conflict: Negative sentiment represents 20-35% of the cases.
• Economic: Predominantly neutral, with only negative tone
in Italy and UK (in the latter case, all headlines with this
frame were considered negative.)
• Human interest: Negative sentiment represents 30-40% of
the cases, while positive tone is only found in residual form
in Italy, Spain, and Switzerland.
• Morality: Predominantly neutral, with negative tone in Italy,
      </p>
      <p>Switzerland, and the United Kingdom,
• No frame: 20-30% of negative content.</p>
      <p>Regarding the results of the annotation process, the fact that the
distribution of the 6 frame types is relatively similar between
countries suggests that the anti-vaccine movement issue was treated
in a similar way in these countries. The fact that human interest
is the most dominant frame indicates that this issue was treated
from a more human and emotional approach, with headlines about
personal experiences, celebrities giving their opinion about
vaccination, and politicians defending vaccine policies. Moreover, the
reason for many headlines being classified as no-frame is partly
due to how data was selected. We chose articles that contained
words related to no-vax, either in the headline or in the article. This
resulted in many headlines not containing anything specific related
to no-vax, while the no-vax content was actually included in the
main text of the corresponding articles.</p>
      <p>It is worth mentioning that prior to obtaining the results, we had
expected that attribution of responsibility would be among the most
prominent frames, since governments took many measures such as
mandatory health pass requirements to access certain sites; we had
also expected that the conflict frame would be prominent, since
there were many demonstrations in Europe. In reality, however,
these frames categories were not reflected as frequently at the
headline level.</p>
      <p>Regarding the analysis at the temporal level, it is clear that certain
events were captured by the press, such as the start of vaccination
or the mandatory vaccination passport.</p>
      <p>
        Finally, the sentiment analysis of the diferent frames shows that
the predominant tone in all of them is neutral or negative, with very
similar trends between countries. This association between
sentiment analysis and frames has been discussed in previous literature
[
        <xref ref-type="bibr" rid="ref11">11</xref>
        ] [
        <xref ref-type="bibr" rid="ref43">43</xref>
        ].
6
      </p>
    </sec>
    <sec id="sec-10">
      <title>RESULTS: GPT-3.5 FOR FRAME</title>
    </sec>
    <sec id="sec-11">
      <title>CLASSIFICATION OF HEADLINES (RQ2)</title>
      <p>Here, we present and discuss the results related to our second RQ.
6.1</p>
    </sec>
    <sec id="sec-12">
      <title>Fine-tuning GPT-3.5</title>
      <p>Table 4 shows the results of the 6-class classification task using
5-cross validation. Three models were used: GPT-3.5 and two
BERTbased models. We observe that, on average, GPT-3.5 performs better
than the BERT-based models. This is somehow expected as
GPT3.5 is a much larger model. Overall, in the case of fine-tuning, the
best performance for the six-class frame classification task is 72%
accuracy, which is promising, with an improvement over previous
models based on BERT. Yet, it should be noted that the performance
diferences are modest (2% improvement between GPT-3.5 and
RoBERTa).</p>
      <p>On the other hand, BERT is open-source, while GPT-3 has an
economic cost as the use of the model is not free, which monetarily
limits the number of experiments that can be performed with it,
as well as the diferent configurations one can explore to improve
performance. This is important because much of the improvement
in performance requires empirical explorations of model parameters
More specifically, the cost of an experiment for each of the folds has
a cost of 4 dollars (at the time of writing this paper.) This represents
a limitation in practice.</p>
      <p>
        Furthermore, GPT-3 has a significant carbon footprint. Similarly,
for prompt engineering (discussed in the next subsection), choosing
the right prompt (i.e., the words that best define the task so that the
model is able to perform adequately) is also based on trial and error.
This also has an impact on carbon footprint. In connection with
this topic, Strubell et al.[
        <xref ref-type="bibr" rid="ref55">55</xref>
        ] argue that improvements in the
accuracy of models depend on the availability of large computational
resources, which involve large economic and environmental costs.
A criticism has been made as ’the rich get richer’, in the sense that
not all research groups have suficient infrastructure resources and
access to funding needed to use these models and improve their
performance. Also in relation to this analysis, the work of Bender
et al. [
        <xref ref-type="bibr" rid="ref4">4</xref>
        ] evaluates the costs and risks of the use of large language
models, stating that researchers should be aware of the impact that
these models have on the environment, and assess whether the
benefits outweigh the risks. The work in [
        <xref ref-type="bibr" rid="ref4">4</xref>
        ] provides a very telling
example, where people living in the Maldives or Sudan are afected
by floods and pay the environmental price of training English LLMs,
when similar models have not been produced for languages like
Dhivehi or Sudanese Arab. In short, there is a need to establish
ways to use this technological development responsibly, and it all
starts with being aware of the risks it presents.
6.2
      </p>
    </sec>
    <sec id="sec-13">
      <title>Prompt-engineering with GPT-3.5</title>
      <p>For each headline, we got the frame that the model considered the
most likely, and we compared these GPT-3.5 inferences with the
frames labeled by the annotators. The agreement between model
and annotator was of 49%. Analyzing the results, and specifically
looking at the cases where the annotator and GPT-3.5 disagreed,
we discovered that according to the frame definitions, the model
in some cases proposed a frame that indeed made sense. This
observation, together with our previous experience in the annotation
process, where headlines could have more than one valid frame,
led us to design a second post-hoc experiment. We took all the
headlines where each of the two annotators had disagreed with
GPT-3.5, and we asked the annotators to state whether they would
agree (or not) with each GPT-inferred label for a given headline.
It is important to emphasize that the annotators did not know the
origin of that label, i.e., they did not know if it was the label they
had originally assigned, or if it was a random one. In this way, we
could quantify how GPT-3.5 worked according to valid arguments
provided by the annotators. In this post-hoc experiment, the model
agreed in 76% of cases with the annotators.</p>
      <p>
        Looking at the results of the classification models, the 49%
accuracy of the prompt-engineering approach can be considered low,
yet we consider that it is a valid avenue for further investigation,
as in the second post-hoc analysis, we found that the model agrees
with human annotators in 76% of the cases. Clearly, framing
involves aspects of subjectivity [
        <xref ref-type="bibr" rid="ref42">42</xref>
        ]. Much of what we do as people
has a subjective component, influenced by how we feel or how we
express opinions.
      </p>
      <p>
        News reading is never fully objective, and the annotators
engaged in the frame classification task, influenced by their personal
state of mind, experience, and culture, may perceive information
diferently. Monarch afirms that "for simple tasks, like binary labels
on objective tasks, the statistics are fairly straightforward to decide
which is the ‘correct’ label when diferent annotators disagree. But
for subjective tasks, or even objective tasks with continuous data,
there are no simple heuristics for deciding what the correct label
should be" [
        <xref ref-type="bibr" rid="ref42">42</xref>
        ].
      </p>
      <p>
        Subjectivity is involved in both the generation and perception
of information: the assumption that there is only one frame is
complicated by the point of view of the reader. In the case of news, the
information sender (the journalist) has an intention, but the receiver
(the reader) plays a role and is influenced by it. In psychology, this
is known as the lens model of interpersonal communication, where
the sender has certain objectives, but the receiver can interpret
or re-interpret what the sender wants to say, with more or less
accuracy [
        <xref ref-type="bibr" rid="ref26">26</xref>
        ].
      </p>
      <p>Following this discussion on subjectivity, the question arose as to
what would happen if, instead of headlines, we used the complete
article as a source of analysis. We wondered if longer text could
make the frame labeling task clearer than when using headlines.
Yet another possible hypothesis is that having to read longer texts
could lead to the same subject being presented from diferent angles.
Please recall that in the existing literature discussed in Section 2,
both headlines and full articles have been used from frame analysis
(see Table 1.) This remains as an issue for future work.
7</p>
    </sec>
    <sec id="sec-14">
      <title>CONCLUSIONS</title>
      <p>In this paper, we first presented an analysis of human-generated
news frames on the covid-19 no-vax movement in Europe, and
then studied diferent approaches using large language models for
automatic inference of frames. We conclude by answering the two
research questions we posed:</p>
      <p>RQ1: What are the main frames in the news headlines about the
covid-19 anti-vaccine movement in 5 European countries? After
annotating the headlines, we found that of the 1786 headlines,
the predominant frame is human interest (45.3% of cases), which
presents a news item with an emotional angle, putting a face to a
problem or situation. We also found that a substantial proportion
of headlines were annotated as not presenting any frame (40.2% of
cases). Finally, the other frame types are found more infrequently.</p>
      <p>RQ2: Can prompt engineering be used for classification of
headlines according to frames? We first used fine-tuning of a number of
language models, and found that GPT-3.5 produced classicfiation
accuracy of 72% on a six-frame classification task. This represented a
modest 2% improvement over BERT-based models, at a significantly
larger environmental cost. We then presented a new way of
classifying frames using prompts. At the headline level, inferences made
with GPT-3.5 reached 49% of agreement with human-generated
frame labels. In many cases, the GPT-3.5 model inferred frame
types that were considered as valid choices by human annotators,
and in an post-doc experiment, the human-machine agreement
reached 76%. These results have opened several new directions for
future work.</p>
    </sec>
    <sec id="sec-15">
      <title>ACKNOWLEDGMENTS</title>
      <p>This work was supported by the AI4Media project, funded by the
European Commission (Grant 951911) under the H2020 Programme
ICT-48-2020. We also thank the newspapers for sharing their online
articles. Finally, we thank our colleagues Haeeun Kim and Emma
Bouton-Bessac for their support with annotations, and Victor Bros
and Oleksii Polegkyi for discussions.</p>
    </sec>
  </body>
  <back>
    <ref-list>
      <ref id="ref1">
        <mixed-citation>
          [1]
          <string-name>
            <given-names>Justito</given-names>
            <surname>Adiprasetio</surname>
          </string-name>
          and Annissa Winda Larasati.
          <year>2020</year>
          .
          <article-title>Pandemic crisis in online media: Quantitative framing analysis on Detik</article-title>
          .
          <source>com's coverage of Covid-19. Jurnal Ilmu Sosial Dan Ilmu Politik</source>
          <volume>24</volume>
          ,
          <issue>2</issue>
          (
          <year>2020</year>
          ),
          <fpage>153</fpage>
          -
          <lpage>170</lpage>
          .
        </mixed-citation>
      </ref>
      <ref id="ref2">
        <mixed-citation>
          [2]
          <string-name>
            <given-names>Neel</given-names>
            <surname>Alex</surname>
          </string-name>
          , Eli Lifland, Lewis Tunstall, Abhishek Thakur, Pegah Maham,
          <string-name>
            <given-names>C Jess</given-names>
            <surname>Riedel</surname>
          </string-name>
          , Emmie Hine, Carolyn Ashurst, Paul Sedille,
          <string-name>
            <given-names>Alexis</given-names>
            <surname>Carlier</surname>
          </string-name>
          , et al.
          <year>2021</year>
          .
          <article-title>RAFT: A real-world few-shot text classification benchmark</article-title>
          .
          <source>arXiv preprint arXiv:2109.14076</source>
          (
          <year>2021</year>
          ).
        </mixed-citation>
      </ref>
      <ref id="ref3">
        <mixed-citation>
          <source>[3] David Alonso del Barrio and Daniel Gatica-Perez</source>
          .
          <year>2022</year>
          .
          <article-title>How Did Europe's Press Cover Covid-</article-title>
          19
          <string-name>
            <given-names>Vaccination</given-names>
            <surname>News? A Five-Country</surname>
          </string-name>
          <string-name>
            <surname>Analysis.</surname>
          </string-name>
          (
          <year>2022</year>
          ),
          <fpage>35</fpage>
          -
          <lpage>43</lpage>
          . https://doi.org/10.1145/3512732.3533588
        </mixed-citation>
      </ref>
      <ref id="ref4">
        <mixed-citation>
          [4]
          <string-name>
            <surname>Emily</surname>
            <given-names>M Bender</given-names>
          </string-name>
          ,
          <string-name>
            <given-names>Timnit</given-names>
            <surname>Gebru</surname>
          </string-name>
          ,
          <string-name>
            <surname>Angelina McMillan-Major</surname>
            , and
            <given-names>Shmargaret</given-names>
          </string-name>
          <string-name>
            <surname>Shmitchell</surname>
          </string-name>
          .
          <year>2021</year>
          .
          <article-title>On the Dangers of Stochastic Parrots: Can Language Models Be Too Big? (</article-title>
          <year>2021</year>
          ),
          <fpage>610</fpage>
          -
          <lpage>623</lpage>
          .
        </mixed-citation>
      </ref>
      <ref id="ref5">
        <mixed-citation>
          [5]
          <string-name>
            <given-names>Santosh</given-names>
            <surname>Kumar</surname>
          </string-name>
          Biswal and Nikhil Kumar Gouda.
          <year>2020</year>
          .
          <article-title>Artificial intelligence in journalism: A boon or bane? In Optimization in machine learning and applications</article-title>
          . Springer,
          <fpage>155</fpage>
          -
          <lpage>167</lpage>
          .
        </mixed-citation>
      </ref>
      <ref id="ref6">
        <mixed-citation>
          [6]
          <string-name>
            <given-names>Erik</given-names>
            <surname>Bleich</surname>
          </string-name>
          , Hannah Stonebraker, Hasher Nisar, and
          <string-name>
            <given-names>Rana</given-names>
            <surname>Abdelhamid</surname>
          </string-name>
          .
          <year>2015</year>
          .
          <article-title>Media portrayals of minorities: Muslims in British newspaper headlines,</article-title>
          <year>2001</year>
          -
          <fpage>2012</fpage>
          .
          <source>Journal of Ethnic and Migration Studies</source>
          <volume>41</volume>
          ,
          <issue>6</issue>
          (
          <year>2015</year>
          ),
          <fpage>942</fpage>
          -
          <lpage>962</lpage>
          .
        </mixed-citation>
      </ref>
      <ref id="ref7">
        <mixed-citation>
          [7]
          <string-name>
            <given-names>Michael</given-names>
            <surname>Bommarito</surname>
          </string-name>
          and Daniel Martin Katz.
          <year>2022</year>
          .
          <article-title>GPT Takes the Bar Exam</article-title>
          . https://doi.org/10.48550/ARXIV.2212.14402
        </mixed-citation>
      </ref>
      <ref id="ref8">
        <mixed-citation>
          [8]
          <string-name>
            <given-names>Meredith</given-names>
            <surname>Broussard</surname>
          </string-name>
          , Nicholas Diakopoulos, Andrea L Guzman, Rediet Abebe, Michel Dupagne, and
          <string-name>
            <surname>Ching-Hua Chuan</surname>
          </string-name>
          .
          <year>2019</year>
          .
          <article-title>Artificial intelligence and journalism</article-title>
          .
          <source>Journalism &amp; Mass Communication Quarterly</source>
          <volume>96</volume>
          ,
          <issue>3</issue>
          (
          <year>2019</year>
          ),
          <fpage>673</fpage>
          -
          <lpage>695</lpage>
          .
        </mixed-citation>
      </ref>
      <ref id="ref9">
        <mixed-citation>
          [9]
          <string-name>
            <given-names>Tom</given-names>
            <surname>Brown</surname>
          </string-name>
          , Benjamin Mann, Nick Ryder, Melanie Subbiah,
          <string-name>
            <surname>Jared D Kaplan</surname>
            , Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry,
            <given-names>Amanda</given-names>
          </string-name>
          <string-name>
            <surname>Askell</surname>
          </string-name>
          , et al.
          <year>2020</year>
          .
          <article-title>Language models are few-shot learners</article-title>
          .
          <source>Advances in neural information processing systems</source>
          <volume>33</volume>
          (
          <year>2020</year>
          ),
          <fpage>1877</fpage>
          -
          <lpage>1901</lpage>
          .
        </mixed-citation>
      </ref>
      <ref id="ref10">
        <mixed-citation>
          [10]
          <string-name>
            <surname>Björn</surname>
            <given-names>Burscher</given-names>
          </string-name>
          , Daan Odijk, Rens Vliegenthart, Maarten De Rijke, and
          <string-name>
            <surname>Claes H De Vreese</surname>
          </string-name>
          .
          <year>2014</year>
          .
          <article-title>Teaching the computer to code frames in news: Comparing two supervised machine learning approaches to frame analysis</article-title>
          .
          <source>Communication Methods and Measures 8</source>
          ,
          <issue>3</issue>
          (
          <year>2014</year>
          ),
          <fpage>190</fpage>
          -
          <lpage>206</lpage>
          .
        </mixed-citation>
      </ref>
      <ref id="ref11">
        <mixed-citation>
          [11]
          <string-name>
            <surname>Bjorn</surname>
            <given-names>Burscher</given-names>
          </string-name>
          , Rens Vliegenthart, and
          <string-name>
            <surname>Claes H de Vreese</surname>
          </string-name>
          .
          <year>2016</year>
          .
          <article-title>Frames beyond words: Applying cluster and sentiment analysis to news coverage of the nuclear power issue</article-title>
          .
          <source>Social Science Computer Review</source>
          <volume>34</volume>
          ,
          <issue>5</issue>
          (
          <year>2016</year>
          ),
          <fpage>530</fpage>
          -
          <lpage>545</lpage>
          .
        </mixed-citation>
      </ref>
      <ref id="ref12">
        <mixed-citation>
          [12]
          <string-name>
            <surname>Dallas</surname>
            <given-names>Card</given-names>
          </string-name>
          , Amber Boydstun, Justin Gross, Philip Resnik, and
          <string-name>
            <given-names>Noah</given-names>
            <surname>Smith</surname>
          </string-name>
          .
          <year>2015</year>
          .
          <article-title>The Media Frames Corpus: Annotations of Frames Across Issues</article-title>
          .
          <volume>2</volume>
          (
          <issue>01</issue>
          <year>2015</year>
          ),
          <fpage>438</fpage>
          -
          <lpage>444</lpage>
          . https://doi.org/10.3115/v1/
          <fpage>P15</fpage>
          -2072
        </mixed-citation>
      </ref>
      <ref id="ref13">
        <mixed-citation>
          [13]
          <string-name>
            <surname>Daniel</surname>
            Catalan-Matamoros and
            <given-names>Carlos</given-names>
          </string-name>
          <string-name>
            <surname>Elías</surname>
          </string-name>
          .
          <year>2020</year>
          .
          <article-title>Vaccine hesitancy in the age of coronavirus and fake news: analysis of journalistic sources in the Spanish quality press</article-title>
          .
          <source>International Journal of Environmental Research and Public Health</source>
          <volume>17</volume>
          ,
          <issue>21</issue>
          (
          <year>2020</year>
          ),
          <fpage>8136</fpage>
          .
        </mixed-citation>
      </ref>
      <ref id="ref14">
        <mixed-citation>
          [14]
          <string-name>
            <surname>Daniel</surname>
            Catalán-Matamoros and
            <given-names>Carmen</given-names>
          </string-name>
          <string-name>
            <surname>Peñafiel-Saiz</surname>
          </string-name>
          .
          <year>2019</year>
          .
          <article-title>Media and mistrust of vaccines: a content analysis of press headlines</article-title>
          . Revista latina de comunicación social
          <volume>74</volume>
          (
          <year>2019</year>
          ),
          <fpage>786</fpage>
          -
          <lpage>802</lpage>
          .
        </mixed-citation>
      </ref>
      <ref id="ref15">
        <mixed-citation>
          [15]
          <string-name>
            <given-names>Mark</given-names>
            <surname>Coddington</surname>
          </string-name>
          .
          <year>2015</year>
          .
          <article-title>Clarifying journalism's quantitative turn: A typology for evaluating data journalism, computational journalism, and computer-assisted reporting</article-title>
          .
          <source>Digital journalism 3</source>
          ,
          <issue>3</issue>
          (
          <year>2015</year>
          ),
          <fpage>331</fpage>
          -
          <lpage>348</lpage>
          .
        </mixed-citation>
      </ref>
      <ref id="ref16">
        <mixed-citation>
          [16]
          <string-name>
            <surname>Stephen</surname>
            <given-names>D</given-names>
          </string-name>
          <string-name>
            <surname>Cooper</surname>
          </string-name>
          .
          <year>2010</year>
          .
          <article-title>The oppositional framing of bloggers</article-title>
          .
          <source>In Doing News Framing Analysis. Routledge</source>
          ,
          <volume>151</volume>
          -
          <fpage>172</fpage>
          .
        </mixed-citation>
      </ref>
      <ref id="ref17">
        <mixed-citation>
          [17]
          <string-name>
            <given-names>Robert</given-names>
            <surname>Dale</surname>
          </string-name>
          .
          <year>2021</year>
          .
          <article-title>GPT-3: What's it good for?</article-title>
          <source>Natural Language Engineering</source>
          <volume>27</volume>
          ,
          <issue>1</issue>
          (
          <year>2021</year>
          ),
          <fpage>113</fpage>
          -
          <lpage>118</lpage>
          .
        </mixed-citation>
      </ref>
      <ref id="ref18">
        <mixed-citation>
          [18]
          <string-name>
            <given-names>Astrid</given-names>
            <surname>Dirikx</surname>
          </string-name>
          and
          <string-name>
            <given-names>Dave</given-names>
            <surname>Gelders</surname>
          </string-name>
          .
          <year>2010</year>
          .
          <article-title>To frame is to explain: A deductive frame-analysis of Dutch and French climate change coverage during the annual UN Conferences of the Parties</article-title>
          .
          <source>Public Understanding of Science 19</source>
          ,
          <issue>6</issue>
          (
          <year>2010</year>
          ),
          <fpage>732</fpage>
          -
          <lpage>742</lpage>
          . https://doi.org/10.1177/0963662509352044 arXiv:https://doi.org/10.1177/0963662509352044 PMID:
          <fpage>21560546</fpage>
          .
        </mixed-citation>
      </ref>
      <ref id="ref19">
        <mixed-citation>
          [19]
          <string-name>
            <given-names>Astrid</given-names>
            <surname>Dirikx</surname>
          </string-name>
          and
          <string-name>
            <given-names>Dave</given-names>
            <surname>Gelders</surname>
          </string-name>
          .
          <year>2010</year>
          .
          <article-title>To frame is to explain: A deductive frameanalysis of Dutch and French climate change coverage during the annual UN Conferences of the Parties</article-title>
          .
          <source>Public understanding of science 19</source>
          ,
          <issue>6</issue>
          (
          <year>2010</year>
          ),
          <fpage>732</fpage>
          -
          <lpage>742</lpage>
          .
        </mixed-citation>
      </ref>
      <ref id="ref20">
        <mixed-citation>
          [20]
          <string-name>
            <surname>Zi-Yi</surname>
            <given-names>Dou</given-names>
          </string-name>
          , Pengfei Liu, Hiroaki Hayashi, Zhengbao Jiang, and
          <string-name>
            <given-names>Graham</given-names>
            <surname>Neubig</surname>
          </string-name>
          .
          <year>2020</year>
          .
          <article-title>Gsum: A general framework for guided neural abstractive summarization</article-title>
          . arXiv preprint arXiv:
          <year>2010</year>
          .
          <volume>08014</volume>
          (
          <year>2020</year>
          ).
        </mixed-citation>
      </ref>
      <ref id="ref21">
        <mixed-citation>
          [21]
          <string-name>
            <given-names>Sumayya</given-names>
            <surname>Ebrahim</surname>
          </string-name>
          .
          <year>2022</year>
          .
          <article-title>The corona chronicles: Framing analysis of online news headlines of the COVID-19 pandemic in Italy, USA and South Africa</article-title>
          .
          <source>Health SA Gesondheid (Online) 27</source>
          (
          <year>2022</year>
          ),
          <fpage>1</fpage>
          -
          <lpage>8</lpage>
          .
        </mixed-citation>
      </ref>
      <ref id="ref22">
        <mixed-citation>
          [22]
          <string-name>
            <given-names>Hend</given-names>
            <surname>Abdelgaber Ahmed El-Behary</surname>
          </string-name>
          .
          <year>2021</year>
          .
          <article-title>A Feverish Spring: A Comparative Analysis of COVID-19 News Framing in Sweden, the UK, and</article-title>
          <string-name>
            <surname>Egypt.</surname>
          </string-name>
          (
          <year>2021</year>
          ).
        </mixed-citation>
      </ref>
      <ref id="ref23">
        <mixed-citation>
          [23]
          <string-name>
            <surname>Robert</surname>
            <given-names>M</given-names>
          </string-name>
          <string-name>
            <surname>Entman</surname>
          </string-name>
          .
          <year>1993</year>
          .
          <article-title>Framing: Towards clarification of a fractured paradigm</article-title>
          .
          <source>McQuail's reader in mass communication theory 390</source>
          (
          <year>1993</year>
          ),
          <fpage>397</fpage>
          .
        </mixed-citation>
      </ref>
      <ref id="ref24">
        <mixed-citation>
          [24]
          <string-name>
            <surname>Tianyu</surname>
            <given-names>Gao</given-names>
          </string-name>
          , Adam Fisch, and
          <string-name>
            <given-names>Danqi</given-names>
            <surname>Chen</surname>
          </string-name>
          .
          <year>2020</year>
          .
          <article-title>Making pre-trained language models better few-shot learners</article-title>
          . arXiv preprint arXiv:
          <year>2012</year>
          .
          <volume>15723</volume>
          (
          <year>2020</year>
          ).
        </mixed-citation>
      </ref>
      <ref id="ref25">
        <mixed-citation>
          [25]
          <string-name>
            <given-names>Piyush</given-names>
            <surname>Ghasiya</surname>
          </string-name>
          and
          <string-name>
            <given-names>Koji</given-names>
            <surname>Okamura</surname>
          </string-name>
          .
          <year>2021</year>
          .
          <article-title>Investigating COVID-19 news across four nations: a topic modeling and sentiment analysis approach</article-title>
          .
          <source>Ieee Access</source>
          <volume>9</volume>
          (
          <year>2021</year>
          ),
          <fpage>36645</fpage>
          -
          <lpage>36656</lpage>
          .
        </mixed-citation>
      </ref>
      <ref id="ref26">
        <mixed-citation>
          [26]
          <string-name>
            <given-names>Robert</given-names>
            <surname>Giford</surname>
          </string-name>
          .
          <year>1994</year>
          .
          <article-title>A Lens-Mapping Framework for Understanding the Encoding and Decoding of Interpersonal Dispositions in Nonverbal Behavior</article-title>
          .
          <source>Journal of Personality and Social Psychology</source>
          <volume>66</volume>
          (02
          <year>1994</year>
          ),
          <fpage>398</fpage>
          -
          <lpage>412</lpage>
          . https: //doi.org/10.1037//0022-
          <fpage>3514</fpage>
          .
          <year>66</year>
          .2.
          <fpage>398</fpage>
        </mixed-citation>
      </ref>
      <ref id="ref27">
        <mixed-citation>
          [27]
          <string-name>
            <surname>Quentin</surname>
            <given-names>Grail</given-names>
          </string-name>
          , Julien Perez, and
          <string-name>
            <given-names>Eric</given-names>
            <surname>Gaussier</surname>
          </string-name>
          .
          <year>2021</year>
          .
          <article-title>Globalizing BERT-based transformer architectures for long document summarization</article-title>
          .
          <source>In Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics:</source>
          Main Volume.
          <fpage>1792</fpage>
          -
          <lpage>1810</lpage>
          .
        </mixed-citation>
      </ref>
      <ref id="ref28">
        <mixed-citation>
          [28]
          <string-name>
            <surname>Anushka</surname>
            <given-names>Gupta</given-names>
          </string-name>
          , Diksha Chugh,
          <string-name>
            <given-names>Rahul</given-names>
            <surname>Katarya</surname>
          </string-name>
          , et al.
          <year>2022</year>
          .
          <article-title>Automated news summarization using transformers</article-title>
          .
          <source>In Sustainable Advanced Computing</source>
          . Springer,
          <fpage>249</fpage>
          -
          <lpage>259</lpage>
          .
        </mixed-citation>
      </ref>
      <ref id="ref29">
        <mixed-citation>
          [29]
          <string-name>
            <given-names>Alfred</given-names>
            <surname>Hermida</surname>
          </string-name>
          and Mary Lynn Young.
          <year>2017</year>
          .
          <article-title>Finding the data unicorn: A hierarchy of hybridity in data and computational journalism</article-title>
          .
          <source>Digital Journalism</source>
          <volume>5</volume>
          ,
          <issue>2</issue>
          (
          <year>2017</year>
          ),
          <fpage>159</fpage>
          -
          <lpage>176</lpage>
          .
        </mixed-citation>
      </ref>
      <ref id="ref30">
        <mixed-citation>
          [30]
          <string-name>
            <surname>Karoliina</surname>
            <given-names>Isoaho</given-names>
          </string-name>
          , Daria Gritsenko, and
          <string-name>
            <given-names>Eetu</given-names>
            <surname>Mäkelä</surname>
          </string-name>
          .
          <year>2021</year>
          .
          <article-title>Topic modeling and text analysis for qualitative policy research</article-title>
          .
          <source>Policy Studies Journal</source>
          <volume>49</volume>
          ,
          <issue>1</issue>
          (
          <year>2021</year>
          ),
          <fpage>300</fpage>
          -
          <lpage>324</lpage>
          .
        </mixed-citation>
      </ref>
      <ref id="ref31">
        <mixed-citation>
          [31]
          <string-name>
            <surname>Carina</surname>
            <given-names>Jacobi</given-names>
          </string-name>
          , Wouter Van Atteveldt,
          <string-name>
            <given-names>and Kasper</given-names>
            <surname>Welbers</surname>
          </string-name>
          .
          <year>2016</year>
          .
          <article-title>Quantitative analysis of large amounts of journalistic texts using topic modelling</article-title>
          .
          <source>Digital journalism 4</source>
          ,
          <issue>1</issue>
          (
          <year>2016</year>
          ),
          <fpage>89</fpage>
          -
          <lpage>106</lpage>
          .
        </mixed-citation>
      </ref>
      <ref id="ref32">
        <mixed-citation>
          [32]
          <string-name>
            <surname>Zhengbao</surname>
            <given-names>Jiang</given-names>
          </string-name>
          , Frank F Xu,
          <string-name>
            <given-names>Jun</given-names>
            <surname>Araki</surname>
          </string-name>
          , and
          <string-name>
            <given-names>Graham</given-names>
            <surname>Neubig</surname>
          </string-name>
          .
          <year>2020</year>
          .
          <article-title>How can we know what language models know? Transactions of the Association for Computational Linguistics 8 (</article-title>
          <year>2020</year>
          ),
          <fpage>423</fpage>
          -
          <lpage>438</lpage>
          .
        </mixed-citation>
      </ref>
      <ref id="ref33">
        <mixed-citation>
          [33]
          <string-name>
            <surname>Shima</surname>
            <given-names>Khanehzar</given-names>
          </string-name>
          ,
          <string-name>
            <given-names>Andrew</given-names>
            <surname>Turpin</surname>
          </string-name>
          , and
          <string-name>
            <given-names>Gosia</given-names>
            <surname>Mikołajczak</surname>
          </string-name>
          .
          <year>2019</year>
          .
          <article-title>Modeling Political Framing Across Policy Issues and Contexts</article-title>
          .
          <source>In ALTA.</source>
        </mixed-citation>
      </ref>
      <ref id="ref34">
        <mixed-citation>
          [34]
          <string-name>
            <given-names>Jeesun</given-names>
            <surname>Kim</surname>
          </string-name>
          and
          <string-name>
            <given-names>Wayne</given-names>
            <surname>Wanta</surname>
          </string-name>
          .
          <year>2018</year>
          .
          <article-title>News framing of the US immigration debate during election years: Focus on generic frames</article-title>
          .
          <source>The Communication Review</source>
          <volume>21</volume>
          ,
          <issue>2</issue>
          (
          <year>2018</year>
          ),
          <fpage>89</fpage>
          -
          <lpage>115</lpage>
          .
        </mixed-citation>
      </ref>
      <ref id="ref35">
        <mixed-citation>
          [35]
          <string-name>
            <surname>Percy</surname>
            <given-names>Liang</given-names>
          </string-name>
          , Rishi Bommasani,
          <string-name>
            <given-names>Tony</given-names>
            <surname>Lee</surname>
          </string-name>
          , Dimitris Tsipras, Dilara Soylu, Michihiro Yasunaga, Yian Zhang, Deepak Narayanan, Yuhuai Wu,
          <string-name>
            <given-names>Ananya</given-names>
            <surname>Kumar</surname>
          </string-name>
          , et al.
          <year>2022</year>
          .
          <article-title>Holistic evaluation of language models</article-title>
          .
          <source>arXiv preprint arXiv:2211.09110</source>
          (
          <year>2022</year>
          ).
        </mixed-citation>
      </ref>
      <ref id="ref36">
        <mixed-citation>
          [36]
          <string-name>
            <surname>Pengfei</surname>
            <given-names>Liu</given-names>
          </string-name>
          , Weizhe Yuan, Jinlan Fu, Zhengbao Jiang, Hiroaki Hayashi, and
          <string-name>
            <given-names>Graham</given-names>
            <surname>Neubig</surname>
          </string-name>
          .
          <year>2021</year>
          .
          <article-title>Pre-train, prompt, and predict: A systematic survey of prompting methods in natural language processing</article-title>
          . (
          <year>2021</year>
          ). https://doi.org/10. 48550/ARXIV.2107.13586
        </mixed-citation>
      </ref>
      <ref id="ref37">
        <mixed-citation>
          [37]
          <string-name>
            <surname>Siyi</surname>
            <given-names>Liu</given-names>
          </string-name>
          , Lei Guo, Kate Mays, Margrit Betke, and Derry Tanti Wijaya.
          <year>2019</year>
          .
          <article-title>Detecting frames in news headlines and its application to analyzing news framing trends surrounding US gun violence</article-title>
          .
          <source>In Proceedings of the 23rd conference on computational natural language learning (CoNLL).</source>
        </mixed-citation>
      </ref>
      <ref id="ref38">
        <mixed-citation>
          [38]
          <string-name>
            <given-names>Jörg</given-names>
            <surname>Matthes</surname>
          </string-name>
          and
          <string-name>
            <given-names>Matthias</given-names>
            <surname>Kohring</surname>
          </string-name>
          .
          <year>2008</year>
          .
          <article-title>The Content Analysis of Media Frames: Toward Improving Reliability and Validity</article-title>
          .
          <source>Journal of Communication</source>
          <volume>58</volume>
          (06
          <year>2008</year>
          ). https://doi.org/10.1111/j.1460-
          <fpage>2466</fpage>
          .
          <year>2008</year>
          .
          <volume>00384</volume>
          .x
        </mixed-citation>
      </ref>
      <ref id="ref39">
        <mixed-citation>
          [39]
          <string-name>
            <surname>Selina</surname>
            <given-names>Meyer</given-names>
          </string-name>
          , David Elsweiler,
          <string-name>
            <given-names>Bernd</given-names>
            <surname>Ludwig</surname>
          </string-name>
          , Marcos Fernandez-Pichel, and
          <string-name>
            <given-names>David E</given-names>
            <surname>Losada</surname>
          </string-name>
          .
          <year>2022</year>
          .
          <article-title>Do We Still Need Human Assessors? Prompt-Based GPT-3 User Simulation in Conversational AI</article-title>
          .
          <source>In Proceedings of the 4th Conference on Conversational User Interfaces. 1-6.</source>
        </mixed-citation>
      </ref>
      <ref id="ref40">
        <mixed-citation>
          [40]
          <string-name>
            <surname>Stuart</surname>
            <given-names>E Middleton</given-names>
          </string-name>
          , Symeon Papadopoulos, and
          <string-name>
            <given-names>Yiannis</given-names>
            <surname>Kompatsiaris</surname>
          </string-name>
          .
          <year>2018</year>
          .
          <article-title>Social computing for verifying social media content in breaking news</article-title>
          .
          <source>IEEE Internet Computing</source>
          <volume>22</volume>
          ,
          <issue>2</issue>
          (
          <year>2018</year>
          ),
          <fpage>83</fpage>
          -
          <lpage>89</lpage>
          .
        </mixed-citation>
      </ref>
      <ref id="ref41">
        <mixed-citation>
          [41]
          <string-name>
            <given-names>Marko</given-names>
            <surname>Milosavljević</surname>
          </string-name>
          and
          <string-name>
            <given-names>Igor</given-names>
            <surname>Vobič</surname>
          </string-name>
          .
          <year>2021</year>
          . '
          <article-title>Our task is to demystify fears': Analysing newsroom management of automation in journalism</article-title>
          .
          <source>Journalism</source>
          <volume>22</volume>
          ,
          <issue>9</issue>
          (
          <year>2021</year>
          ),
          <fpage>2203</fpage>
          -
          <lpage>2221</lpage>
          .
        </mixed-citation>
      </ref>
      <ref id="ref42">
        <mixed-citation>
          [42]
          <string-name>
            <given-names>R.</given-names>
            <surname>Monarch</surname>
          </string-name>
          .
          <year>2021</year>
          .
          <article-title>Human-in-the-Loop Machine Learning: Active Learning and Annotation for Human-centered AI</article-title>
          . Manning. https://books.google.ch/books? id=LCh0zQEACAAJ
        </mixed-citation>
      </ref>
      <ref id="ref43">
        <mixed-citation>
          [43]
          <string-name>
            <given-names>Tom</given-names>
            <surname>Nicholls</surname>
          </string-name>
          and
          <string-name>
            <given-names>Pepper D</given-names>
            <surname>Culpepper</surname>
          </string-name>
          .
          <year>2021</year>
          .
          <article-title>Computational identification of media frames: Strengths, weaknesses, and opportunities</article-title>
          .
          <source>Political Communication</source>
          <volume>38</volume>
          ,
          <fpage>1</fpage>
          -
          <lpage>2</lpage>
          (
          <year>2021</year>
          ),
          <fpage>159</fpage>
          -
          <lpage>181</lpage>
          .
        </mixed-citation>
      </ref>
      <ref id="ref44">
        <mixed-citation>
          [44]
          <string-name>
            <given-names>Zhongdang</given-names>
            <surname>Pan and Gerald M Kosicki</surname>
          </string-name>
          .
          <year>1993</year>
          .
          <article-title>Framing analysis: An approach to news discourse</article-title>
          .
          <source>Political communication 10</source>
          ,
          <issue>1</issue>
          (
          <year>1993</year>
          ),
          <fpage>55</fpage>
          -
          <lpage>75</lpage>
          .
        </mixed-citation>
      </ref>
      <ref id="ref45">
        <mixed-citation>
          [45]
          <string-name>
            <given-names>Raul</given-names>
            <surname>Puri</surname>
          </string-name>
          and
          <string-name>
            <given-names>Bryan</given-names>
            <surname>Catanzaro</surname>
          </string-name>
          .
          <year>2019</year>
          .
          <article-title>Zero-shot text classification with generative language models</article-title>
          . arXiv preprint arXiv:
          <year>1912</year>
          .
          <volume>10165</volume>
          (
          <year>2019</year>
          ).
        </mixed-citation>
      </ref>
      <ref id="ref46">
        <mixed-citation>
          [46]
          <string-name>
            <given-names>Guanghui</given-names>
            <surname>Qin</surname>
          </string-name>
          and
          <string-name>
            <given-names>Jason</given-names>
            <surname>Eisner</surname>
          </string-name>
          .
          <year>2021</year>
          .
          <article-title>Learning how to ask: Querying lms with mixtures of soft prompts</article-title>
          .
          <source>arXiv preprint arXiv:2104.06599</source>
          (
          <year>2021</year>
          ).
        </mixed-citation>
      </ref>
      <ref id="ref47">
        <mixed-citation>
          [47]
          <string-name>
            <given-names>Rabindra</given-names>
            <surname>Lamsal</surname>
          </string-name>
          .
          <year>2021</year>
          .
          <article-title>Sentiment Analysis of English Tweets with BERTsent</article-title>
          . https://huggingface.co/rabindralamsal/finetuned-bertweet
          <article-title>-sentiment-analysis.</article-title>
        </mixed-citation>
      </ref>
      <ref id="ref48">
        <mixed-citation>
          [48]
          <string-name>
            <surname>Alec</surname>
            <given-names>Radford</given-names>
          </string-name>
          , Jefrey Wu, Rewon Child, David Luan,
          <string-name>
            <given-names>Dario</given-names>
            <surname>Amodei</surname>
          </string-name>
          ,
          <string-name>
            <given-names>Ilya</given-names>
            <surname>Sutskever</surname>
          </string-name>
          , et al.
          <year>2019</year>
          .
          <article-title>Language models are unsupervised multitask learners</article-title>
          .
          <source>OpenAI blog 1</source>
          ,
          <issue>8</issue>
          (
          <year>2019</year>
          ),
          <fpage>9</fpage>
          .
        </mixed-citation>
      </ref>
      <ref id="ref49">
        <mixed-citation>
          [49]
          <string-name>
            <surname>Nishant</surname>
            <given-names>Rai</given-names>
          </string-name>
          , Deepika Kumar, Naman Kaushik, Chandan Raj, and
          <string-name>
            <given-names>Ahad</given-names>
            <surname>Ali</surname>
          </string-name>
          .
          <year>2022</year>
          .
          <article-title>Fake News Classification using transformer based enhanced LSTM and BERT</article-title>
          .
          <source>International Journal of Cognitive Computing in Engineering</source>
          <volume>3</volume>
          (
          <year>2022</year>
          ),
          <fpage>98</fpage>
          -
          <lpage>105</lpage>
          . https://doi.org/10.1016/j.ijcce.
          <year>2022</year>
          .
          <volume>03</volume>
          .003
        </mixed-citation>
      </ref>
      <ref id="ref50">
        <mixed-citation>
          [50]
          <string-name>
            <surname>Frida</surname>
            <given-names>V</given-names>
          </string-name>
          <string-name>
            <surname>Rodelo</surname>
          </string-name>
          .
          <year>2021</year>
          .
          <article-title>Framing of the Covid-19 pandemic and its organizational predictors</article-title>
          .
          <source>Cuadernos. info 50</source>
          (
          <year>2021</year>
          ),
          <fpage>91</fpage>
          -
          <lpage>112</lpage>
          .
        </mixed-citation>
      </ref>
      <ref id="ref51">
        <mixed-citation>
          [51]
          <string-name>
            <given-names>Teven</given-names>
            <surname>Le</surname>
          </string-name>
          <string-name>
            <surname>Scao</surname>
          </string-name>
          , Angela Fan, Christopher Akiki, Ellie Pavlick, Suzana Ilić, Daniel Hesslow, Roman Castagné, Alexandra Sasha Luccioni, François Yvon,
          <string-name>
            <given-names>Matthias</given-names>
            <surname>Gallé</surname>
          </string-name>
          , et al.
          <year>2022</year>
          .
          <article-title>Bloom: A 176b-parameter open-access multilingual language model</article-title>
          .
          <source>arXiv preprint arXiv:2211.05100</source>
          (
          <year>2022</year>
          ).
        </mixed-citation>
      </ref>
      <ref id="ref52">
        <mixed-citation>
          [52]
          <string-name>
            <given-names>Holli</given-names>
            <surname>Semetko</surname>
          </string-name>
          and
          <string-name>
            <given-names>Patti</given-names>
            <surname>Valkenburg</surname>
          </string-name>
          .
          <year>2000</year>
          .
          <article-title>Framing European Politics: A Content Analysis of Press and Television News</article-title>
          .
          <source>Journal of Communication</source>
          <volume>50</volume>
          (06
          <year>2000</year>
          ),
          <fpage>93</fpage>
          -
          <lpage>109</lpage>
          . https://doi.org/10.1111/j.1460-
          <fpage>2466</fpage>
          .
          <year>2000</year>
          .tb02843.x
        </mixed-citation>
      </ref>
      <ref id="ref53">
        <mixed-citation>
          [53]
          <string-name>
            <surname>Richard</surname>
            <given-names>Shin</given-names>
          </string-name>
          , Christopher H Lin, Sam Thomson, Charles Chen, Subhro Roy, Emmanouil Antonios Platanios, Adam Pauls, Dan Klein, Jason Eisner, and Benjamin Van Durme.
          <year>2021</year>
          .
          <article-title>Constrained language models yield few-shot semantic parsers</article-title>
          .
          <source>arXiv preprint arXiv:2104.08768</source>
          (
          <year>2021</year>
          ).
        </mixed-citation>
      </ref>
      <ref id="ref54">
        <mixed-citation>
          [54]
          <string-name>
            <given-names>Efstathios</given-names>
            <surname>Sidiropoulos</surname>
          </string-name>
          and
          <string-name>
            <given-names>Andreas</given-names>
            <surname>Veglis</surname>
          </string-name>
          .
          <year>2017</year>
          .
          <article-title>Computer Supported Collaborative Work trends on Media Organizations: Mixing Qualitative and Quantitative Approaches</article-title>
          .
          <source>Studies in Media and Communication</source>
          <volume>5</volume>
          (
          <issue>04</issue>
          <year>2017</year>
          ),
          <volume>63</volume>
          . https://doi.org/10.11114/smc.v5i1.
          <fpage>2279</fpage>
        </mixed-citation>
      </ref>
      <ref id="ref55">
        <mixed-citation>
          [55]
          <string-name>
            <surname>Emma</surname>
            <given-names>Strubell</given-names>
          </string-name>
          , Ananya Ganesh, and
          <string-name>
            <surname>Andrew McCallum</surname>
          </string-name>
          .
          <year>2019</year>
          .
          <article-title>Energy and policy considerations for deep learning in NLP</article-title>
          . arXiv preprint arXiv:
          <year>1906</year>
          .
          <volume>02243</volume>
          (
          <year>2019</year>
          ).
        </mixed-citation>
      </ref>
      <ref id="ref56">
        <mixed-citation>
          [56]
          <string-name>
            <surname>Alex</surname>
            <given-names>Tamkin</given-names>
          </string-name>
          , Miles Brundage, Jack Clark, and
          <string-name>
            <given-names>Deep</given-names>
            <surname>Ganguli</surname>
          </string-name>
          .
          <year>2021</year>
          .
          <article-title>Understanding the capabilities, limitations, and societal impact of large language models</article-title>
          .
          <source>arXiv preprint arXiv:2102.02503</source>
          (
          <year>2021</year>
          ).
        </mixed-citation>
      </ref>
      <ref id="ref57">
        <mixed-citation>
          [57]
          <string-name>
            <surname>Trieu</surname>
            <given-names>H</given-names>
          </string-name>
          <string-name>
            <surname>Trinh and Quoc V Le</surname>
          </string-name>
          .
          <year>2018</year>
          .
          <article-title>A simple method for commonsense reasoning</article-title>
          . arXiv preprint arXiv:
          <year>1806</year>
          .
          <volume>02847</volume>
          (
          <year>2018</year>
          ).
        </mixed-citation>
      </ref>
      <ref id="ref58">
        <mixed-citation>
          [58]
          <string-name>
            <surname>Maria</surname>
            <given-names>Tsimpoukelli</given-names>
          </string-name>
          , Jacob L Menick,
          <article-title>Serkan Cabi</article-title>
          , SM Eslami,
          <string-name>
            <surname>Oriol Vinyals</surname>
            , and
            <given-names>Felix</given-names>
          </string-name>
          <string-name>
            <surname>Hill</surname>
          </string-name>
          .
          <year>2021</year>
          .
          <article-title>Multimodal few-shot learning with frozen language models</article-title>
          .
          <source>Advances in Neural Information Processing Systems</source>
          <volume>34</volume>
          (
          <year>2021</year>
          ),
          <fpage>200</fpage>
          -
          <lpage>212</lpage>
          .
        </mixed-citation>
      </ref>
      <ref id="ref59">
        <mixed-citation>
          [59]
          <string-name>
            <surname>Sandra</surname>
            <given-names>A Vannoy</given-names>
          </string-name>
          and
          <string-name>
            <given-names>Prashant</given-names>
            <surname>Palvia</surname>
          </string-name>
          .
          <year>2010</year>
          .
          <article-title>The social influence model of technology adoption</article-title>
          .
          <source>Commun. ACM 53</source>
          ,
          <issue>6</issue>
          (
          <year>2010</year>
          ),
          <fpage>149</fpage>
          -
          <lpage>153</lpage>
          .
        </mixed-citation>
      </ref>
      <ref id="ref60">
        <mixed-citation>
          [60]
          <string-name>
            <given-names>Tuukka</given-names>
            <surname>Ylä-Anttila</surname>
          </string-name>
          ,
          <string-name>
            <given-names>Veikko</given-names>
            <surname>Eranti</surname>
          </string-name>
          , and
          <string-name>
            <given-names>Anna</given-names>
            <surname>Kukkonen</surname>
          </string-name>
          .
          <year>2022</year>
          .
          <article-title>Topic modeling for frame analysis: A study of media debates on climate change in India and USA</article-title>
          .
          <source>Global Media and Communication</source>
          <volume>18</volume>
          ,
          <issue>1</issue>
          (
          <year>2022</year>
          ),
          <fpage>91</fpage>
          -
          <lpage>112</lpage>
          .
        </mixed-citation>
      </ref>
    </ref-list>
  </back>
</article>