<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.0 20120330//EN" "JATS-archivearticle1.dtd">
<article xmlns:xlink="http://www.w3.org/1999/xlink">
  <front>
    <journal-meta>
      <journal-title-group>
        <journal-title>March</journal-title>
      </journal-title-group>
    </journal-meta>
    <article-meta>
      <title-group>
        <article-title>The Programmer's Assistant: Conversational Interaction with a Large Language Model for Software Development</article-title>
      </title-group>
      <contrib-group>
        <contrib contrib-type="author">
          <string-name>Steven I. Ross</string-name>
          <email>steven_ross@us.ibm.com</email>
          <xref ref-type="aff" rid="aff1">1</xref>
        </contrib>
        <contrib contrib-type="author">
          <string-name>Fernando Martinez</string-name>
          <email>martferc@ar.ibm.com</email>
          <xref ref-type="aff" rid="aff0">0</xref>
        </contrib>
        <contrib contrib-type="author">
          <string-name>Stephanie Houde</string-name>
          <email>Stephanie.Houde@ibm.com</email>
          <xref ref-type="aff" rid="aff1">1</xref>
        </contrib>
        <contrib contrib-type="author">
          <string-name>Michael Muller</string-name>
          <email>michael_muller@us.ibm.com</email>
          <xref ref-type="aff" rid="aff1">1</xref>
        </contrib>
        <contrib contrib-type="author">
          <string-name>Justin D. Weisz</string-name>
          <email>jweisz@us.ibm.com</email>
          <xref ref-type="aff" rid="aff2">2</xref>
        </contrib>
        <contrib contrib-type="author">
          <string-name>code-fluent large language models, foundation models, conversa-</string-name>
          <xref ref-type="aff" rid="aff3">3</xref>
        </contrib>
        <aff id="aff0">
          <label>0</label>
          <institution>IBM Argentina</institution>
          ,
          <addr-line>La Plata, Buenos Aires</addr-line>
          ,
          <country country="AR">Argentina</country>
        </aff>
        <aff id="aff1">
          <label>1</label>
          <institution>IBM Research AI</institution>
          ,
          <addr-line>Cambridge, MA</addr-line>
          ,
          <country country="US">USA</country>
        </aff>
        <aff id="aff2">
          <label>2</label>
          <institution>IBM Research AI</institution>
          ,
          <addr-line>Yorktown Heights, NY</addr-line>
          ,
          <country country="US">USA</country>
        </aff>
        <aff id="aff3">
          <label>3</label>
          <institution>tional interaction</institution>
          ,
          <addr-line>human-centered AI</addr-line>
        </aff>
      </contrib-group>
      <pub-date>
        <year>2023</year>
      </pub-date>
      <volume>2</volume>
      <fpage>7</fpage>
      <lpage>31</lpage>
      <abstract>
        <p>Large language models (LLMs) have recently been applied in software engineering to perform tasks such as translating code between programming languages, generating code from natural language, and autocompleting code as it is being written. When used within development tools, these systems typically treat each model invocation independently from all previous invocations, and only a specific limited functionality is exposed within the user interface. This approach to user interaction misses an opportunity for users to more deeply engage with the model by having the context of their previous interactions, as well as the context of their code, inform the model's responses. We developed a prototype system - the Programmer's Assistant - in order to explore the utility of conversational interactions grounded in code, as well as software engineers' receptiveness to the idea of conversing with, rather than invoking, a code-fluent LLM. Through an evaluation with 42 participants with varied levels of programming experience, we found that our system was capable of conducting extended, multi-turn discussions, and that it enabled additional knowledge and capabilities beyond code generation to emerge from the LLM. Despite skeptical initial expectations for conversational programming assistance, participants were impressed by the breadth of the assistant's capabilities, the quality of its responses, and its potential for improving their productivity. Our work demonstrates the unique potential of conversational interactions with LLMs for co-creative processes like software development.</p>
      </abstract>
    </article-meta>
  </front>
  <body>
    <fig>
      <graphic xlink:href="pdfFiles\6066bba8c06d9fec764f.images\img_1_1.png" />
    </fig>
    <fig>
      <graphic xlink:href="pdfFiles\6066bba8c06d9fec764f.images\img_1_2.png" />
    </fig>
    <fig>
      <graphic xlink:href="pdfFiles\6066bba8c06d9fec764f.images\img_5_1.png" />
    </fig>
    <fig>
      <graphic xlink:href="pdfFiles\6066bba8c06d9fec764f.images\img_6_1.png" />
    </fig>
    <sec id="sec-1">
      <title>CCS CONCEPTS</title>
      <p>• Human-centered computing → HCI theory, concepts and
models; • Software and its engineering → Designing software;
• Computing methodologies → Generative and developmental
approaches.
1</p>
    </sec>
    <sec id="sec-2">
      <title>INTRODUCTION</title>
      <p>
        Software development is a highly skilled task that requires
knowledge, focus, and creativity [
        <xref ref-type="bibr" rid="ref136 ref137 ref27 ref28">27, 28</xref>
        ]. Many techniques have been
developed to enhance the productivity of software engineers, such
as advanced code repositories [
        <xref ref-type="bibr" rid="ref86">86</xref>
        ], knowledge repositories [
        <xref ref-type="bibr" rid="ref148 ref39">39</xref>
        ],
Q&amp;A sites [
        <xref ref-type="bibr" rid="ref1 ref110">1</xref>
        ], and pair programming practices [
        <xref ref-type="bibr" rid="ref127 ref18">18</xref>
        ]. Collaborative
software engineering is especially promising, given that
professional software development is rarely a solo activity and relevant
knowledge and expertise are typically distributed widely within an
organization [
        <xref ref-type="bibr" rid="ref68">68</xref>
        ]. Many eforts have focused on incorporating
collaborative technologies into software development environments
(e.g. [
        <xref ref-type="bibr" rid="ref101 ref117 ref134 ref135 ref25 ref26 ref58 ref8">8, 25, 26, 58, 101</xref>
        ]).
      </p>
      <p>
        The pioneering work of Rich and Waters on The Programmer’s
Apprentice [
        <xref ref-type="bibr" rid="ref70">70</xref>
        ] presented a novel concept of a knowledgeable
automated assistant – in efect, an artificial collaborative partner – that
could help software engineers with writing code, designing
software systems, and creating requirements specifications. At the time,
AI technologies and computing resources were not suficient to
fully implement their vision. In the intervening years, an increase in
computational power, the availability of large corpora of language
and code data, and the development of deep neural networks have
made new approaches to achieving their goals worth exploring.
      </p>
      <p>
        Recently, models leveraging the transformer architecture [
        <xref ref-type="bibr" rid="ref96">96</xref>
        ]
have been developed to perform domain-specific software
engineering tasks, such as translating code between languages [
        <xref ref-type="bibr" rid="ref75">75</xref>
        ],
generating documentation for code [
        <xref ref-type="bibr" rid="ref145 ref147 ref36 ref38 ref97 ref98">36, 38, 97, 98</xref>
        ], and generating
unit tests for code [
        <xref ref-type="bibr" rid="ref92">92</xref>
        ] (see Talamadupula [
        <xref ref-type="bibr" rid="ref90">90</xref>
        ] and Allamanis et al.
[
        <xref ref-type="bibr" rid="ref114 ref5">5</xref>
        ] for surveys). Recently developed foundation models – large
language models that can be adapted to multiple tasks and which
exhibit emergent behaviors for which they have not been
explicitly trained [
        <xref ref-type="bibr" rid="ref123 ref14">14</xref>
        ] – have also proven to be capable with source code.
While the intent of training LLMs such as GPT-2 [
        <xref ref-type="bibr" rid="ref64">64</xref>
        ] and GPT-3 [
        <xref ref-type="bibr" rid="ref126 ref17">17</xref>
        ]
was to give them mastery of natural language, it quickly became
apparent that the presence of code in their training corpora had
given them the ability to generate code based on natural language
descriptions [
        <xref ref-type="bibr" rid="ref49">49</xref>
        ]. The Codex model [
        <xref ref-type="bibr" rid="ref133 ref24">24</xref>
        ] was then produced by
finetuning GPT-3 on a large corpus of source code data, leading to the
development of Copilot [
        <xref ref-type="bibr" rid="ref141 ref32">32</xref>
        ], a tool that helps software engineers by
autocompleting code as it is being written. Experimentation with
Copilot has shown its ability to perform additional tasks, such as
explaining code, generating documentation, and translating code
between languages [
        <xref ref-type="bibr" rid="ref115 ref6">6</xref>
        ].
      </p>
      <p>Although autocompletion interfaces are useful and valuable
when the system can discern the developer’s intent, there are many
instances where that is insuficient. For example, the developer
may have a good idea of what they want to do, but may be unclear
on what functions, libraries, or even algorithms to employ. They
may even have general programming questions that need to be
answered before they are able to write any code.</p>
      <p>In this paper, we seek to understand whether modern
developments in code-fluent foundation models – large language models
that have been fine-tuned on source code data – are suficient to
support a conversational agent that can act as an assistant in the
software development process. We developed the Programmer’s
Assistant to explore the capabilities that conversational interaction
could enable and the extent to which users would find
conversational assistance with programming tasks desirable and useful.</p>
      <p>
        We hypothesize that a conversational system may provide a
lfexible and natural means for interacting with a code-fluent LLM.
Conversational interaction could enable users to pursue their
questions in a multiple exchange dialog (as observed by Barke et al.
[
        <xref ref-type="bibr" rid="ref122 ref13">13</xref>
        ]) that allows them to ask follow-up questions and refine their
inquiries. A conversational programming assistant could ask the
user clarifying or disambiguating questions to help it arrive at the
best answer. It could also provide multiple types of assistance to
the user beyond simply generating code snippets, such as engaging
in general discussion of programming topics (e.g. [
        <xref ref-type="bibr" rid="ref131 ref22 ref71">22, 71</xref>
        ]) or
helping users improve their programming skills (as observed in other
studies of automating technologies [
        <xref ref-type="bibr" rid="ref99">99</xref>
        ]).
      </p>
      <p>Our paper makes the following contributions to the IUI
community:
• We provide empirical evidence that a conversational
programming assistant based on a state-of-the-art, code-fluent
foundation model provides valuable assistance to software
engineers in a myriad of ways: by answering general
programming questions, by generating context-relevant code,
by enabling the model to exhibit emergent behaviors, and by
enabling users to ask follow-up questions that depend upon
their conversational and code contexts.
• We show how diferent interaction models – conversation,
direct manipulation, and search – provide complementary
types of support to software engineers with tradeofs
between the user’s focus and attention, the relevance of
support to their code context, the provenance of that support,
and their ability to ask follow-up questions.
• We motivate the need to further understand how to design
human-centered AI systems that enhance the joint
performance of the human-AI collaboration.
2</p>
    </sec>
    <sec id="sec-3">
      <title>RELATED WORK</title>
      <p>
        We discuss three areas of related work that have either motivated
our study of conversational programming assistance or provided
the technical foundations for it. We begin by briefly summarizing
Rich and Waters’ visionary work on the Programmer’s
Apprentice [
        <xref ref-type="bibr" rid="ref70">70</xref>
        ], followed by summarizing work on code-fluent foundation
models and human-centered evaluations of how these models
impact software engineers’ work. Finally, we discuss conversational
interaction and how it might be employed to provide more flexible
and sophisticated assistance to software engineers.
2.1
      </p>
    </sec>
    <sec id="sec-4">
      <title>The Programmer’s Apprentice</title>
      <p>
        Our work is inspired by the vision laid out by Rich and Waters [
        <xref ref-type="bibr" rid="ref70">70</xref>
        ],
which describes an artificial agent that can act as an intelligent
assistant for software engineers by providing advice, catching errors,
and handling routine details throughout the software development
process. The Programmer’s Apprentice [
        <xref ref-type="bibr" rid="ref70">70</xref>
        ] relied on a knowledge
base of “clichés,” which are formal, structured versions of what
are known today as software design patterns [
        <xref ref-type="bibr" rid="ref140 ref31">31</xref>
        ]. It used a
hybrid reasoning system capable of special-purpose reasoning based
on frames and a plan calculus, along with general purpose logical
reasoning. Although natural language interaction was envisioned,
the original prototype implementation ultimately used a stylized
command language. We view our work as a conceptual successor
to the Programmer’s Apprentice, as it enables the natural language
interaction that the Programmer’s Apprentice lacked.
2.2
      </p>
    </sec>
    <sec id="sec-5">
      <title>Code-fluent Foundation Models and</title>
    </sec>
    <sec id="sec-6">
      <title>Human-Centered Evaluations of</title>
    </sec>
    <sec id="sec-7">
      <title>Programming Assistance</title>
      <p>
        Generative models based on the transformer architecture [
        <xref ref-type="bibr" rid="ref96">96</xref>
        ] have
recently been applied to the domain of software engineering.
Codelfuent large language models are capable of generating code from
natural language descriptions [
        <xref ref-type="bibr" rid="ref105">105</xref>
        ], translating code from one
language to another [
        <xref ref-type="bibr" rid="ref75">75</xref>
        ], generating unit tests [
        <xref ref-type="bibr" rid="ref92">92</xref>
        ], and even
generating documentation for code [
        <xref ref-type="bibr" rid="ref145 ref147 ref36 ref38 ref97 ref98">36, 38, 97, 98</xref>
        ]. These models are
probabilistic systems, and as such, do not always produce perfect
results (e.g. code that is free of syntax or logical errors). Nonetheless,
Weisz et al. [
        <xref ref-type="bibr" rid="ref102">102</xref>
        ] found that software engineers are still interested
in using such models in their work, and that the imperfect outputs
of these models can even help them produce higher-quality code
via human-AI collaboration [
        <xref ref-type="bibr" rid="ref103">103</xref>
        ].
      </p>
      <p>
        New tools based on code-fluent LLMs are actively being
developed. GitHub Copilot1 is described as “Your AI pair programmer.” It
is optimized for the code autocompletion use case: given a starting
snippet such as a method’s documentation, signature, or partial
implementation, Copilot completes the implementation. Copilot is
based on the OpenAI Codex model [
        <xref ref-type="bibr" rid="ref133 ref24">24</xref>
        ], a 12 billion parameter
version of GPT-3 [
        <xref ref-type="bibr" rid="ref126 ref17 ref49">17, 49</xref>
        ], fine-tuned on code samples from 54 million
public software repositories on GitHub. Empirical evaluations of
      </p>
      <sec id="sec-7-1">
        <title>1https://github.com/features/copilot</title>
        <p>
          this model have shown that, although the quality of its outputs is
quite good, those outputs may still be problematic [
          <xref ref-type="bibr" rid="ref57">57</xref>
          ]. Echoing the
results from Weisz et al. [
          <xref ref-type="bibr" rid="ref103">103</xref>
          ], human-centered evaluations of
Copilot have found that it increases users’ feelings of productivity [
          <xref ref-type="bibr" rid="ref109">109</xref>
          ],
and that almost a third (27%) of its proposed code completions were
accepted by users. In a contrasting evaluation, Vaithilingam et al.
[
          <xref ref-type="bibr" rid="ref95">95</xref>
          ] found that while most participants expressed a preference
to use Copilot in their daily work, it did not necessarily improve
their task completion times or success rates. Yet, in a study by
Kalliamvakou [
          <xref ref-type="bibr" rid="ref149 ref40">40</xref>
          ], developers working with Copilot were able to
implement a web server in Javascript 55% faster than developers
who did not use Copilot.
        </p>
        <p>
          A grounded theory analysis of how programmers interact with
Copilot [
          <xref ref-type="bibr" rid="ref122 ref13">13</xref>
          ] found that their interactions varied depending upon
whether they were accelerating tasks that they already knew how
to do or if they were exploring solutions to problems that they were
less sure about. Autocompletion was efective when developers
were operating in “acceleration mode” and relied on the model
to produce short completions that could be verified quickly. In
“exploration mode,” however, the interaction was more awkward.
Developers would communicate with Copilot by typing comments
and seeing what Copilot generated in response. Then, they would
modify their comments to explore other ways of prompting a
response. Ultimately, the comments used to prompt the model would
be deleted after the relevant code was generated, indicating that
their value was largely in driving a back-and-forth, yet context free,
dialog with the model to coerce it to produce the desired results
through an iterative refinement process. In this paper, we fully
commit to a context-aware conversational style of interaction with
a code-fluent LLM and assess the value it provides to users.
2.3
        </p>
      </sec>
    </sec>
    <sec id="sec-8">
      <title>Conversational Interaction and Analysis</title>
      <p>
        2.3.1 Conversational Interaction. Using natural language to
interact with technology has had a long research history [
        <xref ref-type="bibr" rid="ref111 ref2">2</xref>
        ], starting in
the 1960s with pattern-matching approaches like Eliza [
        <xref ref-type="bibr" rid="ref104">104</xref>
        ], and
continuing to today with state-of-the-art large language
modelbased conversational systems [
        <xref ref-type="bibr" rid="ref107">107</xref>
        ] such as Meena [
        <xref ref-type="bibr" rid="ref112 ref3">3</xref>
        ] and
BlenderBot [
        <xref ref-type="bibr" rid="ref84">84</xref>
        ]. These systems are intended to address the problem of
open-domain dialog, with a goal of realistically engaging in
conversation, but not particularly in a goal-directed or task-oriented
manner.
      </p>
      <p>Task-oriented chatbots are typically built with frameworks such
as the Microsoft Bot Framework2, Google DialogFlow3, and IBM
Watson Assistant4. They operate using pre-defined dialogue trees
and use natural language processing to detect conversational intents
and extract contextual entities. This structure enables the creation of
special purpose, but fairly limited and rigid, conversational agents.</p>
      <p>
        There have been several recent attempts to investigate
conversational programming assistance. Kuttal et al. [
        <xref ref-type="bibr" rid="ref151 ref42">42</xref>
        ] conducted a
Wizard of Oz study in which a pair programmer was replaced with
a conversational agent, and they found that “agents can act as
effective pair programming partners.” The PACT system [
        <xref ref-type="bibr" rid="ref106">106</xref>
        ] is a
chatbot that assists programmers adjusting to new programming
      </p>
      <sec id="sec-8-1">
        <title>2https://dev.botframework.com/ 3https://cloud.google.com/dialogflow 4https://www.ibm.com/products/watson-assistant/artificial-intelligence</title>
        <p>
          environments. PACT is structured as a discrete question-answering
system based on a neural machine translation approach, but it
doesn’t maintain a conversational context.
2.3.2 Conversation Analysis. Conversation is a form of interaction
between people that enables robust communication. Conversation
Analysis [
          <xref ref-type="bibr" rid="ref76">76</xref>
          ] is a method for understanding the natural structure
of human conversational interaction. It catalogs diferent patterns
of conversational acts and how they are utilized by interlocutors in
order to attain a wide variety of goals. Recently, Conversation
Analysis has been adapted to describe patterns of interactions between
humans and artificial conversational agents in order to aid in the
design of chatbots [
          <xref ref-type="bibr" rid="ref50">50</xref>
          ]. We apply techniques from Conversation
Analysis in our study of conversational programming assistance.
3
        </p>
      </sec>
    </sec>
    <sec id="sec-9">
      <title>THE PROGRAMMER’S ASSISTANT</title>
      <p>
        In order to explore conversational programming assistance, we
created a functional prototype system called The Programmer’s
Assistant. Our prototype, shown in Figure 1, combines a code editor
with a chat interface. The code editor was implemented using the
Microsoft Monaco Editor5 embedded in a React wrapper6. The
chat user interface was implemented using the React-Chatbot-Kit7
framework. To drive the conversational interaction, we employed
OpenAI’s Codex model [
        <xref ref-type="bibr" rid="ref133 ref24">24</xref>
        ], accessed through its web API.
      </p>
      <p>We developed our prototype as a lightweight coding
environment in order to examine the user experience of interacting with
a conversational assistant. Our work was exploratory in nature,
and thus we did not have specific design goals for the prototype
beyond integrating a code editor with a code-fluent LLM. We also
did not attempt to target the prototype for a specific class of users
(e.g. novices or experts) or use cases (e.g. writing code vs. learning a
new programming language), as we wanted any value provided by
conversational assistance to emerge from our user study. We also
did not implement the ability to run or debug code in our prototype
as we wanted to explore the nature of the conversational
interaction rather than having users focus extensively on the production
of working code.</p>
      <p>
        When designing how users would interact with the
Programmer’s Assistant, we decided that it should be available on demand
and not monitor the user’s work in progress or give unsolicited
suggestions or advice, in keeping with the conversational agent
interaction model proposed by Ross et al. [
        <xref ref-type="bibr" rid="ref73 ref74">73, 74</xref>
        ]. This approach
was supported by feedback from prospective users who were
concerned about the assistant providing criticism of unfinished eforts
in progress or distracting them while they worked. Instead, we
force initiative onto the user and only have the assistant respond
to their requests. In this way, the assistant can provide help when
requested without undesirable interruptions that can distract or
interfere with the user’s flow.
      </p>
      <p>When a user interacts with the assistant, we keep track of their
selection state in the code editor. If a user sends a message to the
assistant without any code selected in the editor, then that message
(along with the prior conversational context) is passed directly to
the model. If a user sends a message to the assistant with new code</p>
      <sec id="sec-9-1">
        <title>5https://microsoft.github.io/monaco-editor/ 6https://www.npmjs.com/package/@monaco-editor/react 7https://fredrikoseberg.github.io/react-chatbot-kit-docs/</title>
        <p>selected in the editor (i.e. code that wasn’t previously selected when
they sent their last message), then that code is appended to the
message before being communicated to the model.</p>
        <p>The model may produce multiple types of responses to a user’s
message. We treat each type of response diferently in the UI.
• Responses that do not contain code are always rendered in
the chat UI (Figure 1E).
• Responses containing short code snippets (≤ 10 lines) are
rendered inline in the chat UI (Figure 1G).
• Responses containing longer code snippets (&gt; 10 lines) show
the code in a pop-up window (Figure 2A), with a proxy entry
in the chat transcript (Figure 2B) that allows users to
redisplay the code window after it has been closed. Non-code
text in the response remains in the chat transcript.</p>
        <p>The assistant never directly modifies the contents of the user’s
source code; rather, any code the user desires to transfer from the
chat takes place via copy/paste.</p>
        <p>Figure 1 shows a screenshot of a real, sample conversation, in
which the user asks a question that results in an inline response,
then requests an explanation of some code in the editor, and then
requests further elaboration. Figure 2 shows an example conversation
that resulted in the generation of a longer code sample, shown in a
popup window. This example shows how the assistant produced an
incomplete solution, followed by criticism from the user regarding
the missing code, and resulting in an apology and the generation
of a complete solution.
3.1</p>
      </sec>
    </sec>
    <sec id="sec-10">
      <title>Supporting Conversational Interaction</title>
      <p>
        We enabled Codex to conduct a conversational interaction by
prompting it with a conversational transcript and a request to produce
the next conversational turn. The prompt establishes a pattern of
conversation between a user and a programming assistant named
Socrates. It provides several examples of Socrates responding to
general coding questions, generating code in response to a request, and
accepting code as input. It establishes a convention for delimiting
code in the conversation, making it easy to parse for display in the
UI. It also establishes an interaction style for the assistant, directing
it to be polite, eager, helpful, and humble, and to present its
responses in a non-authoritative manner8. Because of the possibility
that the model might produce erroneous answers or incorrect code
(as discussed in Weisz et al. [
        <xref ref-type="bibr" rid="ref102">102</xref>
        ]), we felt it was important that the
assistant convey a sense of uncertainty to encourage users to not
accept its results uncritically to avoid over-reliance (e.g. as observed
in Moroz et al.’s study of Copilot [
        <xref ref-type="bibr" rid="ref51">51</xref>
        ], and discussed more
generally in Ashktorab et al. [
        <xref ref-type="bibr" rid="ref118 ref9">9</xref>
        ]) as well as automation bias [
        <xref ref-type="bibr" rid="ref45 ref46 ref65">45, 46, 65</xref>
        ].
We present the full text of the prompt used for the assistant in
Appendix D.
3.2
      </p>
    </sec>
    <sec id="sec-11">
      <title>Architecture &amp; UI Design</title>
      <p>The Programmer’s Assistant communicates with the Codex API via
a proxy server that forwards requests from the React client. The
proxy also rate-limits access to conform to the API’s policy, and
it logs UI events from the client (e.g. requests, responses, and UI
8The assistant’s use of non-authoritative responses was encoded into the LLM prompt;
output token probabilities from the LLM were not utilized to influence the assistant’s
response.
interactions) in a back-end database. To address inconsistencies
in the style or formatting of code generated by Codex, the proxy
server reformats all code segments using the Black code formatter
9 before transmitting them to the client UI.</p>
      <p>The client maintains the transcript of the ongoing conversation.
Each time the user sends a message in the chat, the client constructs
a new prompt for the model by concatenating the initial prompt,
the chat transcript, and the user’s new utterance, and makes a
request for the model to complete the transcript. This completion
request also specifies a stop sequence of tokens to prevent the
model from generating both sides of the conversation (e.g. what
the model thinks the user’s next utterance might be after the
assistant’s response). Given the API’s limitation on context length
(4,096 tokens for both the prompt and model response), we silently
“forget” older exchanges in the chat transcript when constructing
the prompt to ensure that our completion request remains within
bounds. Nonetheless, the entire conversational history remains
visible to the user in the UI.</p>
      <p>The client UI provides a loose coupling between the source code
editor and the chat interface. Users can hide the chat pane when
they wish to focus solely on their code, and re-engage with it
when they desire assistance. Code selected in the editor is included
in the conversation in order to couple the code context with the
conversation. Easily-accessible buttons are provided in the UI to
copy code responses from the assistant to the clipboard.
3.3</p>
    </sec>
    <sec id="sec-12">
      <title>Handling Model Limitations</title>
      <p>While developing the Programmer’s Assistant, and in early pilot
testing, we experienced some quirks and shortcomings of the model
and our approach to using it for conversational interaction. One
limitation stemmed from the fact that the model sometimes
produced incorrect responses (e.g. code with syntax errors), incomplete
responses (e.g. code that was missing functionality), irrelevant
responses (e.g. responses not related to the user’s question), or
insubstantial responses (e.g. “I don’t know”). Because of the probabilistic
nature of model inference, re-prompting the model would
sometimes produce a more correct or appropriate response. Thus, we
added the ability for users to “try again,” either by asking in the chat
or by clicking a button in the UI (Figure 1C). This feature removes
the assistant’s last response from the context presented to the model
and then re-invokes the model with an increased temperature10.</p>
      <p>Although it is possible for transformer models such as Codex to
produce multiple possible responses to a single prompt, we only
request a single response in order to speed up response time as
well as to preserve the token budget for conversational context.
Thus, the “try again” feature provides an alternate way to produce
a wider variety of responses.</p>
      <p>During pilot testing, we noticed that the assistant sometimes
happened to generate the same response to multiple, unrelated
requests. In these cases, the assistant tended to get “stuck” in a pattern
of repeating the same response and was unable to resume normal
conversation. To avoid this problem, we automatically execute a</p>
      <sec id="sec-12-1">
        <title>9https://black.readthedocs.io/en/stable/</title>
        <p>10Temperature is a parameter in a generative model that specifies the amount of
variation in the generation process. Higher temperatures result in greater variability
in the model’s output.
A
B</p>
        <p>C</p>
        <p>D</p>
        <p>E
F
G
“try again” operation in the background when we see identical
consecutive responses from the assistant.</p>
        <p>Finally, we noticed that the accumulation of conversational
context sometimes resulted in the assistant becoming fixated on some
portion of the earlier conversation. For example, it might respond
to a question with portions of the prompt or of earlier conversation,
and become less responsive to newer requests. To address this issue,
we introduced a “start over” feature, accessible via the chat or by
clicking a button in the UI (Figure 1D), that resets the context to the
original prompt, forgetting the rest of the conversational history.
We preserve the chat transcript in the UI, but delineate the break in
the assistant’s memory with an annotation in the chat transcript.
These annotations are added both for “try again” and “start over.”</p>
      </sec>
    </sec>
    <sec id="sec-13">
      <title>Sample Conversation</title>
      <p>We provide a real sample conversation with the Programmer’s
Assistant in Listing 1. This conversation begins with the assistant
greeting the user (line 1). Next, the user asks a general Python
programming question (line 4), to which the assistant responds with
a non-authoritative remark (“I think...”) and a code snippet (line
9). The user next asks a follow-up question that depends on their
previous question and the assistant’s response (line 11), to which
the assistant provides another code snippet (line 15), satisfying the
user’s request.</p>
      <p>The user then switches topics and asks the assistant to write
a Fibonacci function (line 17), and the assistant again responds
with a non-authoritative remark (“I will give it a try,” line 20) and
a block of code. The user then asks how the function works (line
30) and the assistant provides an adequate description (line 32).
Next, the user asks the assistant to re-implement the function in a
diferent way (line 37), again leveraging the ability to ask follow-up
questions. The assistant produces an alternative implementation
that conforms to the user’s request (line 41). The user follows up
with a question that depends on multiple past utterances and
responses in the chat transcript (line 47), and the assistant produces
a relevant response (line 49). The conversation closes with the user
thanking the assistant (line 53) and the assistant acknowledging
their gratitude (line 55).</p>
      <sec id="sec-13-1">
        <title>Listing 1: A conversation with the Programmer’s Assistant.</title>
        <p>Code presented by the assistant is listed in bold face.
1 Socrates : Hello ! My name is Socrates your programming
2 assistant . What can I help you with today ?
3
4 User : How do I get a list of the keys in a
5 Python dictionary ?
6
7 Socrates : I think you would do something like this :
8
9 list(my_dict.keys())
10
11 User : What if I just wanted to iterate over them ?
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
4</p>
        <p>Socrates : I think so . How about this ?
def fib(n):
a,b = 0,1
for i in range(n):</p>
        <p>a,b = b,a+b
return
User :</p>
        <p>Which version is better ?
Socrates : I think the recursive version is more
elegant , but the iterative version is more
efficient .</p>
        <p>User :</p>
        <p>Thanks !
Socrates : You ' re welcome !</p>
      </sec>
    </sec>
    <sec id="sec-14">
      <title>EMPIRICAL STUDY OF CONVERSATIONAL</title>
    </sec>
    <sec id="sec-15">
      <title>PROGRAMMING ASSISTANCE</title>
      <p>
        We conducted an empirical user study of the Programmer’s
Assistant to assess whether conversational assistance provides value in
a software engineering context11. Our inquiry focused on the user
experience and value of conversational interactions grounded in
code. We therefore designed a qualitative study to investigate
attitudes toward a conversational programming assistant: do people
enjoy interacting conversationally, what kinds of questions do they
ask, and how does the experience compare to other forms of
programming support such as searching the web? We note that prior
studies (e.g. [
        <xref ref-type="bibr" rid="ref103 ref105 ref109">103, 105, 109</xref>
        ]) conducted quantitative examinations
of the use of LLMs in code work; our study is akin to Weisz et al.’s
qualitative examination of software engineers’ attitudes toward
working with models that may fail to produce working code [
        <xref ref-type="bibr" rid="ref102">102</xref>
        ].
      </p>
      <p>To address our questions, we deployed the Programmer’s
Assistant within our organization – a global technology company – and
invited people to try it out and give us feedback on their experience.
We invited people with varying levels of programming skill in order
to obtain a wide range of feedback on the kinds of use cases for
which the tool could provide assistance.
4.1</p>
    </sec>
    <sec id="sec-16">
      <title>Tasks</title>
      <p>
        We set up the Programmer’s Assistant as a playground environment
that participants could try out with a few sample programming
problems. We created a tutorial to orient participants to the
assistant, its capabilities, and how to interact with it. We also created
four programming challenges focused on writing code,
documenting code, and writing tests for code. We designed these challenges
to expose participants to a broad range of the assistant’s capabilities.
For each of these challenges, we explicitly did not evaluate metrics
such as the participant’s productivity, the quality of their solutions,
or the time taken to produce them, as the focus of our study was to
understand the utility of conversational interaction. We selected
Python as the language used for the tutorial and challenges because
of its general popularity [
        <xref ref-type="bibr" rid="ref130 ref21">21</xref>
        ] and the fact that it was well-supported
by our underlying LLM [
        <xref ref-type="bibr" rid="ref133 ref24">24</xref>
        ].
4.1.1 Tutorial. All participants were first introduced to the
Programmer’s Assistant through a tutorial. The tutorial walked each
11For historical context, we note that our study was completed before the public
release of ChatGPT [
        <xref ref-type="bibr" rid="ref60">60</xref>
        ], which has subsequently demonstrated the application of
conversational assistance for programming tasks [
        <xref ref-type="bibr" rid="ref143 ref34">34</xref>
        ].
participant through 10 sample interactions to give them a feeling
for what the assistant could do and how to interact with it. The
tutorial demonstrated how to ask questions, how to request code to
be generated, and how to evaluate existing code. It did not
specifically cover how to generate documentation or unit tests. Tutorial
instructions were provided within the code editor. We include the
specific text used for the tutorial in Appendix B.
4.1.2 Programming Challenges. After completing the tutorial,
participants unlocked four programming challenges. Two of the
challenges involved coding problems (writing a queue class and writing
code to create a scatterplot of data in a CSV file), one involved
documenting a given function (an implementation of a graph search
algorithm), and one involved writing unit tests for a given
function (computing the greatest common divisor of two arguments).
Although the Programmer’s Assistant was visible and available for
use, we provided no specific requirement that it actually be used to
complete the challenges.
      </p>
      <p>After participants completed their solution to a challenge, they
submitted it by clicking a button in the UI. The code editor used
in the Programmer’s Assistant was not a fully-functional IDE and
did not provide syntax checking or the ability to run, test, or debug
code. Due to these limitations, participants were asked to submit
their solutions when they felt they had completed the challenge to
their own satisfaction.
4.2</p>
    </sec>
    <sec id="sec-17">
      <title>Participants</title>
      <p>To recruit participants for our study, we posted internal
advertisements in various communications channels focused on software
engineering. Our advertisements stated that we were evaluating a
conversational programming assistant, but were kept deliberately
vague in order to minimize the impact on peoples’ expectations of
the experience.</p>
      <p>
        Our advertisement yielded a pool of 140 potential participants.
In order to recruit a diverse sample, we used a screening survey
that asked about their job role, their familiarity with and recency
of use of Python, and their availability to participate in our study.
We accepted participants into the study on a rolling basis, selecting
participants to capture a range of programming experiences and
ensure balanced gender representation. We conducted periodic
reviews to determine whether we were learning something new from
each participant or if we had reached the point of saturation [
        <xref ref-type="bibr" rid="ref116 ref7">7</xref>
        ]. We
stopped collecting data after running 42 participants as we were no
longer observing any new behaviors or gleaning any new insights.
The Programmer’s Assistant implementation and configuration
were held constant over the course of the study; no changes to the
UI design or LLM prompt were made.
      </p>
      <p>Our participants had the following self-identified characteristics:
• Job role: 19 Software Engineers, 12 Researcher/Scientists, 3
Software Architects, 2 Data Scientists, 1 Machine Learning
Engineer, 1 Systems Test Engineer, 1 Business Analyst, 1
Manager, 1 Marketer, and 1 Consultant.
• Gender: 21 Female, 19 Male, 1 Gender Variant /
Non-conforming, and 1 Preferred not to say.
• Python Experience: 17 participants had 3+ years of Python
experience, 11 had 1-3 years, 11 had less than 1 year, and 3
were not familiar with Python.
• Recency of Python Use: 29 participants had written Python
code within the past month, 4 within the past year, 5 within
the past 5 years, and 4 had not written Python code within
the past 5 years.</p>
      <p>We provide full demographic information for individual
participants in Appendix E.
4.3</p>
    </sec>
    <sec id="sec-18">
      <title>Procedure</title>
      <p>Participants completed the study on their own time, independently
and without moderation. Each participant was provided with a web
link to a pre-study survey that described the nature of the study and
the tasks that they would be expected to perform. They were then
directed to the Programmer’s Assistant to complete the tutorial and
the four programming challenges. When participants indicated they
were finished with the challenges 12, they were directed to a final
post-study survey. Complete sessions generally required about an
hour of efort, though some participants spread their efort across
a longer period of time and across multiple sessions. Participants
were compensated for their time at a rate equivalent to US $15/hr.
4.4</p>
    </sec>
    <sec id="sec-19">
      <title>Measures</title>
      <p>We collected a variety of data in our study from three sources:
(1) Surveys. We employed three surveys in the study: a
prestudy survey to collect demographic information, a pre-task
survey to gauge expectations of the conversational user
experience, and a post-task survey to assess actual user
experience. We describe these survey questions in the relevant
context of our results, and we provide a complete listing of
all survey instruments in Appendix A.
(2) Event logs. The Programmer’s Assistant was instrumented
to collect data on participants’ usage. The event logs
provided timestamped records of interaction events, including
conversational exchanges, hiding/showing the assistant, use
of the “try again” and “start over” features, and use of
copy/paste.
(3) Conversation logs. From the event logs, we extracted
conversational transcripts between each participant and the
Programmer’s Assistant.
5
5.1</p>
    </sec>
    <sec id="sec-20">
      <title>RESULTS</title>
    </sec>
    <sec id="sec-21">
      <title>Data &amp; Analysis</title>
      <p>We collected a wealth of data in our study: 126 survey responses
from three surveys per participant, containing 296 written
comments in open-ended survey questions, and 4,877 instances of 23
diferent types of UI events, including 1,699 conversational
exchanges13 in the event logs. We also compute, for each participant,
counts or durations for 21 diferent metrics from the event logs.</p>
      <p>In our analysis, we deliberately exclude the portion of our data
collected during the tutorial exercise. We exclude this data because
that activity was guided by the tutorial instructions, not by our
participants’ own initiative. Thus, our final sample consists of 3,172
12We did not enforce that participants actually complete all of the challenges.
Nevertheless, all participants but one did submit solutions to all of the challenges.
13We refer to a participant’s utterance, followed by the assistant’s response, as a
conversational exchange.
events, including 968 conversational exchanges in the event logs;
no survey data was excluded.</p>
      <p>
        Our primary analysis of this data is qualitative, as our
participants provided us with a rich source of interesting feedback and
thought-provoking insights in their comments. Where applicable,
we supplement this data with quantitative data from the survey
and the event logs, as well as chat transcript data from the
conversation logs. In this way, we triangulate [
        <xref ref-type="bibr" rid="ref47">47</xref>
        ] across our three
data sources, using the open-ended survey data as a foundation.
When we quote participants, either from their qualitative survey
responses or the conversational transcripts, we reproduce their
words exactly as typed, including typos, misspellings,
grammatical errors, capitalization, and potential trigger words, and we only
make minor clarifying edits where needed, delineated by square
brackets.
      </p>
      <p>
        In order to set the context for our analysis, we first describe
how we used reflexive thematic analysis to analyze participants’
responses to the open-ended survey questions. We then describe
our analysis of the conversation logs and our development of a
coding guide based on Conversation Analysis [
        <xref ref-type="bibr" rid="ref76">76</xref>
        ], and specifically,
Moore and Arar’s Natural Conversation Framework [
        <xref ref-type="bibr" rid="ref50">50</xref>
        ].
5.1.1 Thematic Analysis of Qualitative Survey Responses. We
conducted a reflexive thematic analysis to analyze the responses to
our seven open-ended survey questions. We followed the process
described by Braun and Clarke [
        <xref ref-type="bibr" rid="ref125 ref16">16</xref>
        ] in which researchers immerse
themselves in the data, generate codes for material that seems
interesting, and then iteratively group and refine codes through
collaborative discussion in order to identify higher-level themes.
Initially, four authors performed open-coding on the open-ended
survey responses. Through discussion, these codes were grouped
and consolidated into a single set, which were then re-applied to
the data by two authors. After another round of discussion, these
authors identified a set of 12 higher-level themes. Some themes had
clear parallels to quantitative survey questions or event log data,
and thus represented clear instances where we were able to
triangulate across data sources. Other themes surprised us. We structure
our presentation of the results based on these 12 themes, grouped
into three diferent aspects of the user experience: expectations
and experience, utility of conversational assistance, and patterns of
interaction and mental models.
5.1.2 Conversation Analysis via the Natural Conversation
Framework. In order to understand the content and structure of the
conversations that took place between our participants and the
Programmer’s Assistant, we turned to the Natural Conversation
Framework [
        <xref ref-type="bibr" rid="ref50">50</xref>
        ] (NCF). We developed a codebook for the event
logs, beginning with 21 diferent categories of utterances from the
NCF. Nine NCF categories – Acknowledgment, Apology,
Confirmation, Expression of Gratitude, Farewell, Greeting, Self-Identification,
Welfare Check, and Welfare Report – appeared twice in our
codebook to distinguish cases in which the utterance was made by the
human participant vs. the assistant. Other NCF categories were
split to provide nuanced detail about the interaction; for example,
we distinguished three diferent kinds of NCF requests, depending
upon whether they were stated as Requests for Action (e.g. “Would
you...”), Commands of Action (e.g. “Write a function that...”), or
Expressions of Desire (e.g. “I want...”). We also added 18 additional
      </p>
      <sec id="sec-21-1">
        <title>Interlocutor</title>
      </sec>
      <sec id="sec-21-2">
        <title>Orientation</title>
      </sec>
      <sec id="sec-21-3">
        <title>Codes</title>
        <p>Appears Fixated, Claims Ignorance, Didn’t Understand, Grants Request (Complete), Grants Request
(Incomplete), Ofers Help, Provided Wrong Answer, Requests Details, Requests Paraphrase, Response
Includes Code, Spews Garbage
codes to identify meta-information such as utterances that included
code, utterances that referenced selected code, utterances that
implicitly or explicitly referenced earlier portions of the conversation,
or non-verbal UI activities such as copies, pastes, and invocations
of “try again” and “start over.” Finally, we classified a subset of the
human-applied codes based on whether they represented a
participant’s task or social orientation toward the assistant. We list
our codes in Table 1, but note that not all of them ended up being
relevant to our analysis.</p>
        <p>When coding conversational data, we applied individual codes
at the level of each conversational utterance. We allowed multiple
codes to be applied to each utterance to account for utterances that
performed multiple functions (e.g. greeting and self-identification).</p>
        <p>In order to ensure consistency in how our codebook was applied,
two authors coded a 10% sample of the 968 conversational
exchanges, achieving a satisfactory level of inter-rater reliability
(Krippendorf’s  = 0.77, where agreement was conservatively defined
as having all of the same codes applied to both utterances in a
conversational exchange).
5.2</p>
      </sec>
    </sec>
    <sec id="sec-22">
      <title>Expectations and Experience</title>
      <p>Pilot testing of the Programmer’s Assistant suggested that software
engineers would be skeptical of a conversational programming
assistant and its ability to provide useful assistance. Our study
revealed that, for most participants, their actual experience after
using the tool was better than they had anticipated. Participants
were surprised at the quality of the assistant’s responses and they
appreciated how its integration with the code editor reduced the
amount of context switching they needed to do in the UI. Some
participants struggled with the code selection feature, although
others appreciated the ability to ask questions related to selected
code.
5.2.1 Usage. All of our participants engaged with the
Programmer’s Assistant while working on the challenges, despite there
being no requirement to do so. Forty-one participants submitted
solutions to all four challenges, and one participant, P14, only
submitted solutions for one of the four challenges. Participants spent
an average of 68 minutes engaged with the assistant, as measured
by the amount of time the Programmer’s Assistant window was in
focus.</p>
      <p>Participants made an average of 23.0 utterances (SD = 15.1
utterances) to the assistant. On average, 6.2 of their utterances (SD =
4.3 utterances) contained a code selection. The average latency per
request14 was 6.7 seconds (SD = 3.1 seconds).</p>
      <p>
        We saw a 66.3% rate of acceptance of generated code, where we
considered code to be accepted if the participant performed a copy
immediately after the code was generated. This acceptance rate is
much higher than the 27% acceptance rate reported for Copilot [
        <xref ref-type="bibr" rid="ref109">109</xref>
        ].
We believe one reason we observed a higher acceptance rate is
because Copilot’s completion suggestions are generated proactively,
whereas the Programmer’s Assistant’s suggestions are generated
upon request. When copying generated code from the assistant,
participants most often copied the entirety of the generated code,
and only in 5.8% of cases did they copy a smaller portion of it.
5.2.2 User Experience Expectations &amp; Changed Atitudes. Prior to
running our study, we had reason to believe that participants would
be skeptical of a conversational programming assistant. Before
developing the Programmer’s Assistant, we showed potential users
mockups of a program editor with an integrated chatbot feature.
These prototypes elicited uniformly negative reactions. People told
us about their frustrating experiences with conventional chatbots
and raised doubts about the knowledge, capabilities, and value
of a conversational programming assistant. This skepticism
motivated us to develop the Programmer’s Assistant in order to evaluate
whether the conversational experience, as powered by a
state-ofthe-art code-fluent LLM, would be better than people had
anticipated. During pilot testing, we received feedback that the
Programmer’s Assistant provided a much better conversational experience
compared to testers’ previous experiences with chatbots. Thus, in
designing our study, we felt it important to first gauge participants’
expectations of a conversational interaction around code, and then
measure their experience after the fact.
14This time includes additional time added by our proxy server to ensure our
conformance to the API rate limitation.
      </p>
      <p>We developed a short inventory of six scale items to measure user
experience of code work15. The scale was administered twice: once
before participants were exposed to the Programmer’s Assistant
(but after they had been briefed that they would interact with an AI
chatbot), and once after completing the programming challenges.
The items were presented with the appropriate tense: Do you expect
(Did you find that) the Programmer’s Assistant: (a) will be (was)
easy to use; (b) will understand (understood) your requests; (c) will
provide (provided) high quality responses; (d) will help (helped)
you to write better code; (e) will help (helped) you to write code
more quickly; (f) will be (was) enjoyable to use. Each item was rated
on a 4-point scale of extent: Not at all (1), A little (2), Somewhat (3),
A great deal (4).</p>
      <p>A factor analysis revealed the items on this scale measured a
single construct, which we identify as user experience (Cronbach’s
 = 0.87). Thus, we computed two scores of user experience (UX)
for each participant: a pre-task UX score computed as the average
of their six pre-task expectation scale responses, and a post-task
UX score computed as the average of their six post-task experience
scale responses.</p>
      <p>We found that participants had lower initial expectations for
their experience with a conversational programming assistant
(pretask UX M (SD) = 3.0 (0.62) of 4) than their experience actually
was (post-task UX M (SD) = 3.6 (0.32) of 4). A paired sample t-test
shows that this diference was significant,  (41) = 5.94,  &lt; .001,
Cohen’s  = 0.92 (large). Measured another way, 32 participants
(76.2%) had post-task UX ratings that were higher than their
pretask expectations, demonstrating a significant shift in attitudes
toward conversational programming assistance.</p>
      <p>However, the UX ratings alone fail to capture participants’
nuanced expectations of the assistant and the reasons for their shifted
attitudes after using it. Participants expressed a variety of
expectations of the assistant before using it, including that it would be easy
to use (P30) and produce correct responses (P30), understand the
problem and what is being asked of it (P8, P9, P11), not interfere
with their flow state (P5), produce imperfect or questionable
outputs (P6, P21), improve with feedback (P31), provide generic and
unhelpful answers (P17) or only answer basic questions (P40), and
produce responses quickly (P40).</p>
      <p>P17 expected “to be frustrated very quickly and that what I’d think
would be relatively common questions would be responded to with
generic, unhelpful answers.” P6 explained, “I didn’t have very good
experiences with chatbots. I think I’ll need to spend more time in
reviewing and fixing the suggestions than in writing the code myself
from scratch.” P11 had a more balanced view, that “It’ll do some tasks
really well, but others will not be as reliable.”</p>
      <p>After interacting with the Programmer’s Assistant, many
participants commented on how the experience was better than they
anticipated, because it “seemed to be able to handle complex issues”
(P10) and “was a great help” (P8). P20 felt it was “incredible!” P6 and
P17, who were both initially skeptical, reported having a positive
experience. For P6, “It absolutely exceeded all my expectations, in
15Our scale items were modeled from scales published in Weisz et al. [103, Table 9 –
AI Support] that measured constructs including ease of use (item 3), response quality
(item 1), the production of higher-quality code (item 5), and the ability to write code
more rapidly (item 4). We added additional items to cover the constructs of request
understanding and enjoyment, and we cast all items on a 4-point scale of extent.
all aspects that I could have imagined and more!” P17 provided a
more quantitative assessment: “Initial expectations: 3 Actual: 9.5.”
P38 was emphatic in their evaluation: “I was blown away how well
it allowing me to structure how I want the code to look and work and
just giving me the thing I asked for.”</p>
      <p>Many participants described a sense of surprise in their
experiences. P9 was surprised by how well it understood their requests:
“I was surprised at how well the Programmer Assistant
was able to understand my requests and generate good
code/documentation/tests. It understood major concepts
and was able to explain it to me in a clear way, and it
was also able to understand and write functional code.</p>
      <p>It even was able to help me review my answer. I was also
surprised at how well it could understand the context
of what I was asking in follow-up questions when I did
not specify exactly what I was talking about, but rather
referencing our prior conversation (such as, ‘what does
that mean’).” (P9)</p>
      <p>Similarly, P6 was surprised that they liked the conversational
interaction when they expected that they wouldn’t:
“I though[t] I wouldn’t like the chatbot interaction and
that I would prefer something like the tool I’ve seen in
those demos [of Copilot]. But surprisingly, after using
the chatbot (and seeing the results: easy to use, it
understands well, I felt it like a partner) I like this kind of
help.” (P6)
5.2.3 Quality of Assistant’s Responses. In order to gauge the quality
of responses produced by the Programmer’s Assistant, we examined
the 910 task-oriented requests made by participants in the study.
For the vast majority (80.2%), the assistant produced a correct
response (Grants Request (Complete)); in other cases, the assistant’s
response was incorrect (9.6%; Provided Wrong Answer), correct but
incomplete (4.4%; Grants Request (Incomplete)), or the assistant
didn’t understand (3.4%; Didn’t Understand), claimed ignorance of
the subject (1.5%; Claims Ignorance), or produced another type of
response (0.9%; Appears Fixated, Spews Garbage).</p>
      <p>Participants also reported experiencing this variability in the
quality of the assistant’s responses. Some participants described
how the assistant provided “detailed answers” (P17) and “high
quality outputs” (P18) that were “surprisingly good” (P2). P6 felt it was
“incredible to see the quality of the responses,” and P3 even explored
the assistant’s capabilities outside the scope of the challenges and
found that it could handle those as well:
“It was surprising the quality of the code and the ability
to answer all my questions correctly. Although I think
the challenges may be biased towards what the Assistant
is able to do, it was a great experience because I asked
many other things and it was able to answer correctly.”
(P3)</p>
      <p>Of course, the Programmer’s Assistant wasn’t perfect, and some
participants did run into issues. For P35, “The documentation
generation did not perform very well.” P16 questioned the accuracy of the
knowledge encoded in the model: “Does the model need to be
updated? It said latest python version is 3.7 but google says it’s 3.10.” In
some instances, participants needed to ask their question multiple
times to get a good response: “you need to ask many times if you
want to get an answer and also a detailed explanation” (P3). P27 felt,
“it was annoying when I asked it to try again and it would give me
the same response.” P22 struggled because, “It didn’t seem to handle
multiple sentences well.”</p>
      <p>P28 perhaps ofered the most scathing criticism, that, “It makes
mistakes often enough to be not very practical.” However, despite
the production of poorer-quality responses, other participants felt
that the assistant was still helpful. P36 reported that, “Only minor
tweaks were normally needed to correct any issues.” Similarly, P38
described how the assistant wasn’t able to completely solve their
problem, but provided a useful start:
“There was only one hickup I noticed where when I
asked it to memoize fibonacci it couldn’t, but it dropped
the building blocks on my lap for me to finish so that
was fine, that was like minutes of efort on my part.”
(P38)
5.2.4 UI Design &amp; Afordances. Participants made many comments
on our specific UI design and the afordances provided (or not
provided) in our chat-augmented editor. Overall, the integration
between the chat pane and the code editor was “very good” (P23),
with a “nice interface between the code pane and the assistant pane”
(P17) that “makes it really convenient” (P35).</p>
      <p>
        Prior research by Brandt et al. [
        <xref ref-type="bibr" rid="ref124 ref15">15</xref>
        ] has shown how keeping
developers focused in their IDE improves productivity, and our
participants expressed similar sentiments. P40 remarked, “It allows
me to stay in one browser window/tab!” and P12 hinted at how the
interface might preserve their flow state by “prevent[ing] me from
getting distracted when looking into an issue in another tab.”
      </p>
      <p>Some aspects of our user interface were confusing to participants,
such as the mechanism for selecting code to be included in the
conversational context. P7 remarked, “It’s was a little confusing
doing the selection part for it to tell me what a function does, but...
it gave me code that was insanely easy to copy and paste.” Other
participants appreciated the code selection mechanism, such as P11:
“I enjoyed the code selection feature, and found that very easy to use.”
In the event logs, we identified 20 instances in which a participant
unintentionally included selected code in the conversation when
it wasn’t needed (Includes Extraneous Selection), 12 instances in
which a code selection was omitted when it was needed to provide
context for the question (Missing Selection), and 16 instances in
which a participant copy/pasted code directly into the chat rather
than selecting it in the editor (Pasted Code in Chat). Although
these cases represent a small fraction of the 227 instances in which
a code selection was required and included in the conversation
(Includes Selection), their presence does indicate that more attention
is needed to the interaction design of code selection.</p>
      <p>Another issue regarded the awareness of the “try again” and
“start over” features. The “try again” feature was only used by 14
participants, who used it a total of 63 times over the course of
the study. Some participants used it specifically when they got an
answer which they saw as clearly wrong, while others used it to
get a variety of possible answers before proceeding. The “start over”
feature was used even less, by 5 participants who used it a total of
6 times. Despite our efort to surface these conversational features
in the UI via shortcut buttons, they may not have been suficiently
noticeable or salient: “The ‘try again’ button is not so reachable, often
times I forgot it exists” (P23). By contrast, at least one participant
was successful with these features:
“at some point it had issue with challenge 3 and I had to
start over. Just asking ‘try again’ was not enough and I
was getting always the same (wrong and not related)
answer. starting again solved the issue!” (P20)
5.3</p>
    </sec>
    <sec id="sec-23">
      <title>Utility of Conversational Assistance</title>
      <p>
        Our next set of themes concerns the utility provided by
conversational programming assistance. Participants felt the assistant was
highly valuable and desired to use it in their own work. They felt it
would be most helpful for smaller or narrowly-scoped tasks, but
able to provide a wide variety of types of assistance. The fact that
the interaction model was conversational and grounded in code
were valuable aspects, as was the ability for the assistant to bolster
users’ learning about programming topics through that
interaction. Participants did question whether they could trust and rely
upon the assistant’s responses, echoing a similar theme discussed
in Weisz et al. [
        <xref ref-type="bibr" rid="ref102">102</xref>
        ].
5.3.1 Value &amp; Appropriate Tasks. Participants rated the value of
the Programmer’s Assistant highly (M (SD) = 8.6 (1.4) of 10). Many
participants asked questions such as, “Can I have it in my editor
please?” (P15), or made comments that, “I would enjoy using it in
the future” (P36), “I would love to be able to... have access to it for
my coding” (P37), and “I’d love to use this tool as part of my usual
programming workflow if I could!” (P39). Some of the reasons why
participants found it valuable are because it “help[s] me remember
how to do things in certain languages that normally I would just
Google” (P9) and “It helps me to avoid silly syntax errors and can
when I cannot remember exact function/method names and required
arguments” (P40). We did not observe any diferences in value
ratings based on participants’ familiarity with or recency of using
Python.
      </p>
      <p>Participants described a wide variety of tasks for which they
felt the assistant would be useful. These tasks included “ordinary”
(P23), “simpler” (P2), and “small, repetitive” (P4) tasks such as “quick
lookups” (P25) for “short chunks of code” (P11) or for “narrowed
questions” (P26). Participants also felt the assistant was useful for
“small containable novel algorithms” (P38) and “little coding problems”
(P4).</p>
      <p>Several kinds of task assistance were reported as being valuable,
such as explaining code (P31), implementing business logic in a
UI (P38), understanding what code does (P19, P37), and recalling
language syntax, method names, and arguments (P12, P15, P20, P40,
P42). P27 felt that the assistant was “More helpful when recognizing
a specific well known algorithm but not things you make yourself.”</p>
      <p>Participants also made recommendations for how to increase
the value of the Programmer’s Assistant. P38 suggested, “What
would blow me away though is if it’s able to help with what I do most
often which is to integrate, refactor and iterate on an existing system.”
P16, P26, and P38 all desired more information on the data sources
used to produce the assistant’s responses. P9 requested to “Have
the Programmer’s Assistant examine your code and make proactive
suggestions for improving it in the chat.” P36 requested the same,
but cautioned that, “Care would need to be taken to avoid becoming
an annoyance or disrupting the flow of a coding session.”</p>
      <p>In the post-task survey, we probed participants on how certain
changes to the Programmer’s Assistant would either decrease,
increase, or result in no change to its value. Over 75% of participants
felt that the assistant would be more valuable if it operated in a
proactive manner, either by making improvement suggestions in
the chat or as comments directly in the code. Similarly, 78.6% of
participants felt that having more buttons in the UI for common
features such as explaining or documenting code would make the
tool more valuable.
5.3.2 Conversational Interactions Grounded in Code. One of the
challenges in interpreting participants’ comments about the utility
of the Programmer’s Assistant was in disentangling the extent to
which value was derived from the quality of the underlying model
versus the integration of conversation in a code context. Indeed,
participants felt that the chat interaction was valuable: 69.0% of
participants felt that eliminating the conversational interaction
and making the assistant behave more like web search would
decrease its value. Further, our analysis of the conversation transcripts
revealed that 42% of the 910 task-oriented utterances from
participants required historical conversational context (Chat Context
Required) in order to be correctly interpreted. Thus, we observe
that behaviorally, participants did rely on conversational context
in their interactions.</p>
      <p>In the post-task survey, 83% of participants rated the importance
of the ability to ask follow-up questions as being “somewhat” or “a
great deal.” Several participants specifically commented on the value
of this conversational context. P39 remarked, “I absolutely loved
how you can straight up ask follow-up questions to the Programmers’
Assistant without having to reiterate the original topic/question.” P15
expressed a similar sentiment, saying, “I think the conversational
context was someone helpful, just in communicating that it’s a running
conversation where my context is remembered.” P9 provided a similar
analysis:
“This tool was so helpful at answering questions I had
about the code in the context of the code I am working
on... I was also impressed with how well it was able to
remember the context of our conversation, especially
when I asked vague follow-up questions.” (P9)</p>
      <p>In addition, some participants identified how a conversational
interaction grounded in code was useful, “because I think to
‘understand’ the dev context could be VERY important” (P31). In fact,
24.9% of task-oriented utterances included a relevant code selection
(Includes Selection), showing that participants valued this ability.</p>
      <p>Contrasting with these participants, P18 felt that interacting
with the assistant conversationally was tedious, and they employed
a more direct approach:
“I really like the PA. But, I didn’t converse with it like
a chat bot. I often told it what to do (‘Document this
code.’) as opposed to asking it what to do (‘How do I
document this code?’). Talking to it the way that was
suggested in the tutorial seemed overly verbose/tedious.”
(P18)</p>
      <p>Despite these individual diferences in interaction preferences,
P39 envisioned that both interaction styles could be supported in
the tool:
“I think both options should exist: people should be able
to input their queries like a search bar AND also give
their question as if in conversation.” (P39)
5.3.3 Learning Efects. One specific benefit of the Programmer’s
Assistant identified by participants is its ability to help people
improve their programming skills and reinforce knowledge gaps.
For example, it can help users “remember how to do things in certain
languages... such as, when I am using a language I haven’t used in a
while” (P9). The assistant can also serve as an memory aid, such
as when “I use a lot of libraries that I don’t always remember all
of the functions” (P15). Similarly, P31 said, “No matter how good
you’re as a developer, you can’t (humanly) remember all the API of
hundreds of libs or new languages... I’d learn new dev lang and new
lib/frameworks faster.”</p>
      <p>P39 felt the assistant “is perfect for programmers of all levels,” and
P1 felt it could help them rapidly improve their Python skills:
“I have wanted to learn python... The main concern
how much time spent learning is needed before I could
actually get some value out of learning python. I have
a feeling this would cut that time down from weeks to
a day or so.” (P1)</p>
      <p>P39 also identified the fact that, because the interactions with
the assistant are conversational, it forces people to learn how to
communicate to others about their code:
“The conversation aspect promotes proper
communication, which would really stand to benefit budding
programmers if they want to learn how to explain
concepts more fluently in the future to their colleagues.”
(P39)</p>
      <p>Conversely, P36 suggested that over-reliance on programming
assistance might have a detrimental efect to one’s learning:
“It’s definitely a huge time saver, but over-reliance on it
may cause new developers to skip learning the reference
material themselves and discovering new things and
sparking new ideas.” (P36)
5.3.4 Trust. Many participants raised questions about whether
they could trust the responses provided by the Programmer’s
Assistant. P21 asked this question most directly: “will the code be correct,
safe, eficient?” Other participants raised similar questions, such as,
“I’m wondering how it validates it’s answers, if it can be trusted to
always give a working answer” (P10), and “Sometimes lack of source
and context may raise doubts in the mind of the programmer” (P16).</p>
      <p>These issues of trust were exacerbated by the fact that the
Programmer’s Assistant did not allow participants to actually run their
code. Because of this limitation, participants had to rely on their
own knowledge to judge the correctness of the assistant’s responses.
P19 asserted, “There is no way to evaluate if the Programmer’s
assistant is giving you the right advise or not other than your own
knowledge,” and P9 concurred: “I had to trust that it was correct (and
use my own prior knowledge).”
Socrates : I think you would do something like this :
def test_euclid():
assert euclid(2, 4) == 2
assert euclid(6, 9) == 3
assert euclid(17, 12) == 1
assert euclid(4, 4) == 4
what is a euclid function
Socrates : The euclid function is a function that
computes the greatest common divisor of two
numbers .
is this a good unit test for a euclid
function
Socrates : I believe that it is a good unit test for
a euclid function .</p>
      <p>P9 :</p>
      <p>why
Socrates : It seems to me that it tests the edge
cases of a and b being equal , a being
greater than b , and b being greater than a.</p>
      <p>P18 described the potential consequences of allowing the
assistant to write code for them:
“The only thing that made me nervous was that it could
have introduced a bug that wasn’t immediately
apparent. And given I didn’t write the code, I could have easily
glossed over a mistake when reviewing it. Especially if
it is also the one writing the test cases.” (P18)</p>
      <p>Despite our eforts to make the Programmer’s Assistant respond
in non-authoritative ways, we did observe participants sometimes
uncritically accept generated results that were clearly wrong or
incomplete. Thus, we did find behavioral evidence for over-reliance.</p>
      <sec id="sec-23-1">
        <title>Listing 2: Building trust through explanations and justifications</title>
        <p>what is a unit test ?
Socrates : A unit test is a test of a single function
or method . It is typically written by the
programmer who wrote the code .
def euclid(a, b):
while b != 0:</p>
        <p>(a, b) = (b, a % b)
return a
how would I write a unit test for this code ?
thanks Socrates this was helpful
Socrates : Always happy to help .</p>
        <p>One way to address trust issues is for the assistant to provide
further explanations and justifications that can calibrate a user’s
confidence in the assistant’s responses. Such explanations could
be requested conversationally, though most participants did not
attempt to do so. One participant (P9) did ask for such explanations,
and we show a summary of their transcript in Listing 2. In this
instance, P9 asked for a definition of a unit test (line 1), an
explanation of the code being tested (line 25), and justifications of the
quality of the unit test (lines 31&amp; 37). Thus, we observe that the
assistant is capable of producing explanations and justifications
when asked.
5.4</p>
      </sec>
    </sec>
    <sec id="sec-24">
      <title>Patterns of Interaction and Mental Models</title>
      <p>Participants interacted with the assistant in a variety of ways with
two main patterns of usage standing out: (1) invoking the
assistant to solve the entire programming challenge, and (2) breaking
the challenge down into a set of smaller tasks and invoking the
assistant’s help for each. There were no clear diferences in how
participants with difering Python experience approached the tasks.</p>
      <p>Participants’ mental models of the assistant also varied. Although
participants strongly saw the role of the assistant as being a tool,
their behaviors revealed that in many cases, they actually treated it
as a social agent. In addition, participants ascribed various mental
capacities to the assistant, such as having the ability to understand,
compute, and learn.</p>
      <p>Participants felt the assistant changed the nature of their work
process. For some participants, it enabled them to focus on the
higher-level aspects of development because the assistant handled
lower-level details or provided partial solutions for them to build
upon. Many participants felt the assistant sped up their work and
helped them remain focused on their tasks.</p>
      <p>Finally, participants drew comparisons between the
Programmer’s Assistant with other forms of programming support such
as Copilot and web search. They felt that the conversational style
of interaction enabled them to discover new, emergent behaviors
from the model that were unavailable from Copilot’s focus on code
autocompletion. They also felt that the examples provided by the
assistant were more readily usable within their own code compared
to browsing for answers within search results, speeding up the
coding process. However, some participants advocated for a
balanced approach to the design of programming assistance tools by
incorporating multiple modes of interaction rather than fixating
on a single one.
5.4.1 Interaction Styles and Assistant Role. We observed that
participants interacted with the Programmer’s Assistant in strikingly
diferent ways. Some participants would present the entire
challenge description to the assistant and then work with the results it
produced. Other participants approached the programming
challenges in a piecemeal fashion, breaking them apart into a set of
smaller tasks, then invoking the assistant to aid with each one.</p>
      <p>Experience with Python was not a determinant of how
participants approached the programming challenges, but it did seem to
impact how participants interacted with the assistant. Less
experienced participants tended to ask the assistant basic questions such
as, “What is a unit test” (P29, not familiar with Python) and “how
do I document a function?” (P27, &lt; 1 year of experience). More
experienced participants made detailed requests about specific Python
libraries or algorithms, such as, “given a pandas dataframe with
two columns ‘Date’ and ‘Sales’ please use matplotlib to draw me a
scatterplot” (P38, 3+ years of experience) and “implement a
rungekutta algorithm for solving an ODE with adaptive time steps” (P37,
3+ years of experience).</p>
      <p>Another diference we observed in how people interacted with
the assistant stemmed from their view on the role it played in their
collaborative process. Some participants, such as P18, treated it
more as a tool by issuing commands rather than asking questions.
As quoted earlier, they said, “I didn’t converse with it like a chat
bot.” P5 described their interaction style similarly: “I found myself
wanting to type search queries into Socrates, not treating it as a person
but as a search tool.”</p>
      <p>In anticipation that participants would have diferent
orientations to the assistant and its role, we asked a question on the
posttask survey about the diferent kinds of roles the assistant might
take. These roles generally fell into one of two categories: a tool
orientation (a tool, a reference guide, a content generator, a problem
solver), and a social orientation (a collaborator, a colleague, a coach,
an advisor, a reviewer). Participants rated the extent to which they
viewed the Programmer’s Assistant in each of these roles on a
4point scale of extent: Not at all (1), A little (2), Somewhat (3), or A
great deal (4).</p>
      <p>100
s
tna 75
p
iitr
c
a
p
fo 50
e
g
a
t
n
e
rce 25
P
0</p>
      <p>Tool
gCeonnetreantotr Regfeurideence Col aborator Psrooblvleerm</p>
      <p>Role</p>
      <p>Advisor Coach Reviewer Col eague
Rating</p>
      <p>Not at al</p>
      <p>A little</p>
      <p>Somewhat</p>
      <p>A great deal</p>
      <p>We show participants’ ratings of the assistant’s role in Figure 3.
Despite the fact that their attitudes toward the assistant
overwhelmingly reflected a tool orientation, their behaviors reveal that many
participants actually treated the assistant as a social agent. P6
described how “I felt it like a partner,” and P4 told the assistant, “I
could not have solved [the challenge] without your help,” to which
the assistant responded, “I’m glad I could help.”</p>
      <p>
        The literature on Computers as Social Agents (CASA) helps us
interpret this result as it demonstrates how computers are often
treated like people [
        <xref ref-type="bibr" rid="ref56 ref67">56, 67</xref>
        ]. LLM-based conversational agents can
exacerbate this tendency; as they likely have been trained on
examples of social interaction, they can also respond as social agents.
      </p>
      <p>In the conversation logs, we identified participants who
interacted with the assistant in a socially-oriented fashion (the social
orientation codes in Table 1). Twenty participants (47.6%) made at
least one socially-oriented utterance. An extreme form of this
interaction style can be seen in a snippet from P6’s transcript (Listing 3).</p>
      <p>The 20 participants with a behaviorally-demonstrated social
orientation did not generally difer in their role ratings from other
participants, except that they rated the assistant as more likely to
be an advisor (Fisher’s exact test, two-tailed  = .02) or a reviewer
(Fisher’s exact test, two-tailed  = .03). However, they did not difer
in their overwhelmingly-strong ratings of the tool orientations.
Thus, at least for some participants, there seems to be a dissonance
in their view of the assistant’s role orientation.</p>
      <p>Listing 3: Excerpt from P6’s interaction with the
Programmer’s Assistant, in which P6 ofers their thanks and
congratulations.
5.4.2 Mental Capacities. Participants made a number of inferences
about the Programmer’s Assistant and its capacities for thought.
Many participants talked about how the assistant possessed a level
of “understanding” (P6, P8, P11, P18, P32) of “the context” (P9, P21)
as well as “major concepts” (P9) and “knowledge” (P33). P24 was
amazed by the assistant’s ability to “take a plain english request
and interpret it properly.” P7 ascribed intelligence to the assistant,
saying, “It was a lot smarter and trained tha[n] I thought it was.”</p>
      <p>One participant assumed that the assistant “Keeps improving
through (user) feedback” (P31). Another felt that the assistant was
capable of computation: “It understands the problem... It can calculate
the results of a function back” (P8).</p>
      <p>However, not all participants were convinced of the assistant’s
ability to understand. P37 questioned the assistant’s limitations: “I
wonder how far beyond boilerplate it can go and if it works for truly
original problems.”
5.4.3 Impact of Conversational Assistance on Work Practices. Many
participants discussed how the Programmer’s Assistant shaped
their work practices on the programming challenges. Overall,
participants felt that the assistant “saves time” (P10), “helps me code
faster” (P34), and would “speed up my productivity” (P19) because “I
could focus on validating and improving the code it generated instead
of having to write it all from scratch” (P18). P37 remarked that, “It
opens a whole new door for fast develpment.” P4 discussed how the
assistant “was helpful in staying focused on the code,” although for
P14, “it took [me] time to get into tempo with the tool.”</p>
      <p>P31 pointed out how the assistant would change the nature of
their work:
“My job could focus more on higher level aspects and
therefore achieving better (quality) results, besides the
time-to-value... Data science (and dev) becomes a more
creative-higher level experience.” (P31)</p>
      <p>Other participants discussed a work process in which the
assistant provided incomplete solutions – the “building blocks” (P38) or
“initial draft of code” (P11) – upon which they could build. P5 aptly
described this process:
“It’s nice to copy well formulated challenges in natural
language and have the code generator take its best stab
at it, then edit to our hearts content.” (P5)</p>
      <p>Participants felt that human review of the assistant’s responses
was necessary because “The answers provided are generally not
novel solutions, often look clunky and non-elegant. There may be
some unnecessary code. Basically the code would need to be reviewed”
(P16). P35 also pointed out how “The code generator was good but
you still have to really check it.” P19 discussed how they would turn
to the assistant as a first source for support, and only if it wasn’t
able to help would they then turn to other support tools:
“The way I will use it is, I will first us[e] the
Programmer’s assistant for most of my cases. Only in certain
cases where Programmer’s assistant cant answer things
I will turn up to oficial documentation or stack overflow.”
(P19)</p>
      <p>However, latency was a factor for interactive use of the assistant
and participants noticed when the assistant took a long time to
respond. P19 remarked, “Sometimes it took lot of time, like more than
5 seconds.” P40 also felt “the response [was] a little slow sometimes...
in chat mode I expect faster responses.” As discussed in Section 5.2.1,
the assistant took an average of 6.7 seconds (SD = 3.1 seconds)
to respond to a request, and participants did appreciate when the
assistant produced rapid responses: “I loved how quick it was able
to pull up answers to questions I had” (P38).
5.4.4 Conversational Interaction vs. Other Interaction Models.
Although our study was not intended to make comparative
evaluations with the Copilot tool, we nonetheless asked participants
whether they were familiar with Copilot, and if so, to comment on
how the two tools compared. We also asked a similar question to
compare the assistant with another popular form of programming
assistance, searching the web (via a search engine like Google, or
a Q&amp;A site like Stack Overflow). In discussing the diferences
between these three tools, we note that the primary diferentiator is
their interaction model.</p>
      <p>
        The interaction model for the Programmer’s Assistant is clearly
conversational: users ask questions in natural language and are
provided with a response in natural language and/or code. The
interaction model of Copilot is reminiscent of direct manipulation
interfaces [
        <xref ref-type="bibr" rid="ref146 ref37">37</xref>
        ], in which the user’s actions in the user interface
directly manipulate an object on the screen. Copilot automatically
makes autocompletion suggestions as the user types. This
autocompleted code is directly placed in the source editor; thus, the
user’s work is contained entirely within the scope of the object
on which they are working (i.e. the source code), which is how
direct manipulation interfaces operate. In web search, users enter
a separate search context (e.g. a search engine accessed within a
web browser), type in a natural language query, and then forage
amongst search results to identify relevant items of interest [
        <xref ref-type="bibr" rid="ref12 ref121 ref62">12, 62</xref>
        ].
When a desirable item is found, users must translate it into their
code environment (e.g. via copy/paste) and possibly edit it to fit
their existing code.
      </p>
      <p>
        We also note that the Programmer’s Assistant and Copilot both
utilize the same underlying AI model, Codex [
        <xref ref-type="bibr" rid="ref133 ref24">24</xref>
        ], which means
that the only diference between these tools is the user experience.
The extent to which Codex was trained on data from
programmingrelated Q&amp;A web sites is less clear, but for the purposes of our
analysis, we focus our discussion solely on the diferences in their
interaction models16.
      </p>
      <p>Participants reported various benefits and drawbacks of a
conversational interaction over a direct manipulation interaction.
Foremost, conversation “felt very natural” (P21) and “feels much more
natural using Natural Language with the AI” (P39). In addition, P39
felt that “the use cases of Programmers’ Assistant seem more
openended.” Many participants were surprised at the variety of tasks the
assistant was capable of performing, from writing unit tests (P19,
P36, P37) and documentation (P12, P19, P36, P37) to explaining
what code did (P31, P38) and even answering general-knowledge
questions (P31). Again, we note that the Programmer’s Assistant
utilizes the same underlying model as Copilot, yet the
conversational interface was able to expose a wider variety of emergent
behaviors from the model. Multiple participants explored the limits
of the assistant’s knowledge and abilities beyond our programming
challenges. For example, P37 asked it questions about physics and
ordinary diferential equations (“ODe” as written by P37), and was
surprised by the “versatility of what it could answer.”
“I asked it some physics and ODe question and the
answers, though not complete, included the key parts
needed to write that code.” (P37)</p>
      <p>P31 probed the assistant on its knowledge of geography and was
surprised when the assistant produced a correct answer.
“I asked something out of SW engineering domain
(geography) and it replied correctly, also by correctly
answering on my nationality.” (P31)</p>
      <p>
        For some participants, the ability to assess the assistant’s
response before committing to it (i.e. by inserting assistant-generated
code into their editor) was a boon. P15 described how the
copy/paste boundary provided them with “a bit more control to ask specific
questions about what I wanted and to assess before putting it in my
code.” Other participants felt that the copy/paste boundary was
more ineficient:
“I think the main diference is the ability of Copilot to
suggest code while you type, what make it faster and
easier to use. While using the Programmer’s Assistant,
you need to go to the chat, ask the question, copy the
16As an aside, our comparison of direct manipulation, search, and conversational
interaction models is reminiscent of historical comparisons of text-based and graphical user
interfaces [
        <xref ref-type="bibr" rid="ref54 ref63">54, 63</xref>
        ]. Each modality was shown to have advantages and disadvantages.
For example, text-only interfaces can provide accessibility [
        <xref ref-type="bibr" rid="ref54 ref78">54, 78</xref>
        ] and productivity [
        <xref ref-type="bibr" rid="ref53">53</xref>
        ]
advantages, whereas graphical user interfaces provide greater discoverability [
        <xref ref-type="bibr" rid="ref10 ref119 ref88">10, 88</xref>
        ].
Some researchers explored ways to bridge the two interaction modes, such as by
developing GUI wrappers for command line programs [
        <xref ref-type="bibr" rid="ref53 ref94">53, 94</xref>
        ] or by developing tools
that converted GUI activities into procedural descriptions [
        <xref ref-type="bibr" rid="ref55">55</xref>
        ]. Our view is that similar
bridges can be constructed between direct manipulation, search, and conversational
models of interaction; a user’s interaction with an LLM need not be constrained to a
single interaction model.
code (or rephrase the question if it was not understood
by the agent), and edit it to match your code.” (P3)
      </p>
      <p>A large number of participants felt that the conversational
interaction was faster than web search (P1, P6, P7, P10, P11, P12, P16,
P17, P18, P20, P24, P29, P30, P33, P36, P37, P42) because of its ability
to provide “real-time responses” (P32) that can be “applied exactly to
your code” (P33) without having to “parse through lots of text... to get
what you need” (P15). In addition, the assistant provided “MUCH
faster, better responses” (P17) that were “much more relevant to the
problems” (P34) and “simple [and] succinct” (P9), without having to
“sort through answers on your own or read documentation” (P9) or
“look at many posts before finding the relevant one” (P18).</p>
      <p>Despite these benefits, some participants felt that the assistant
might not work well for “more specific and dificult problems on
a bigger scale” as compared to web search. P9 felt that “the data
[of the Programmer’s Assistant] wasn’t as rich” as the web. Other
participants felt that the assistant lacked the “multiple answers” (P9)
and “rich social commentary” (P19) that accompanies answers on
Q&amp;A sites:
“I like to see the diferent versions proposed on stack
overflow and the commentary of what makes one
solution better than another in a given situation.” (P27)</p>
      <p>Some participants promoted a more balanced view that there
isn’t a single mode of interaction superior to all others. P19 felt that
web search would be a fallback when the assistant failed to answer
a question. P39 described how search could be integrated with the
conversational interaction:
“I think both options should exist: people should be able
to input their queries like a search bar AND also give
their question as if in conversation.” (P39)</p>
    </sec>
    <sec id="sec-25">
      <title>DISCUSSION</title>
    </sec>
    <sec id="sec-26">
      <title>Value of Conversational Interaction</title>
      <p>We began our research by asking the question of whether
contemporary developments in code-fluent LLMs could suficiently
support a conversational programming assistant. We believe that
our work has demonstrated that they can. Clearly, the
Programmer’s Assistant was viewed by our participants as a useful tool that
provided real value – so much so that many participants
explicitly requested or expressed the desire to use it in their own work.
However, how much of this value was derived from the model itself
and its ability to produce high-quality responses to programming
questions, versus from participants’ ability to conduct extended
conversational interactions grounded in their actual source code?</p>
      <p>We believe that both of these constituent aspects were valuable.
Indeed, many participants commented on their surprise and
satisfaction with the quality of the assistant’s responses (Section 5.2.3).
However, participants also valued the conversational interactions
that they had with the assistant. In the event logs, we saw
evidence that participants were leveraging conversational context to
ask follow-up questions as well as leveraging code context by
asking about their code selections (Section 5.3.2). Many participants
reported that they would find the tool less valuable if the
conversational interaction were removed (Section 5.3.2). Further,
conversation seemed to provide unique value beyond other interaction
models (direct manipulation and search) because of its
embeddedness in the UI and its ability to surface emergent behaviors of the
model (Section 5.4.4).</p>
      <p>
        We do not believe that these diferent interaction models are
in competition and we agree with P39’s assessment that assistive
tools can be built using a plethora of diferent interaction models.
For use cases in which a model is known to produce high-quality
results (e.g. code autocompletion for Codex), a direct manipulation
interface seems wholly appropriate as it would provide a
discoverable and predictable way of invoking the model to produce a
known type of result. However, direct manipulation interfaces may
be less ideal for surfacing the emergent behaviors of a foundation
model [
        <xref ref-type="bibr" rid="ref123 ref14">14</xref>
        ], and thus natural language interaction may be more
suitable. Many popular text-to-image models, such as DALL-E 2 [
        <xref ref-type="bibr" rid="ref66">66</xref>
        ]
and Stable Difusion [
        <xref ref-type="bibr" rid="ref72">72</xref>
        ], operate in a one-shot fashion, in which
the user specifies a prompt, clicks a button, and gets results. Our
study demonstrates how the additional contextual layers of
conversational history and the artifact-under-development provide
additional value to the co-creative process.
6.2
      </p>
    </sec>
    <sec id="sec-27">
      <title>Toward Human-AI Synergy</title>
      <p>
        The aim of human-centered AI is to “enable[] people to see, think,
create, and act in extraordinary ways, by combining potent user
experiences with embedded AI methods to support services that
users want” [
        <xref ref-type="bibr" rid="ref82">82</xref>
        ]. Building upon this definition, Rezwana and Maher
[
        <xref ref-type="bibr" rid="ref69">69</xref>
        ] posit that, “In a creative collaboration, interaction dynamics,
such as turn-taking, contribution type, and communication, are the
driving forces of the co-creative process. Therefore the interaction
model is a critical and essential component for efective co-creative
systems.” [
        <xref ref-type="bibr" rid="ref69">69</xref>
        ]. They go on to note that, “There is relatively little
research about interaction design in the co-creativity field, which
is reflected in a lack of focus on interaction design in many existing
co-creative systems.”
      </p>
      <p>
        Our study begins to address this gap. While many co-creative
systems examine casual tasks or experimental activities (e.g., Spoto
and Oleynik [
        <xref ref-type="bibr" rid="ref87">87</xref>
        ]), our focus was on the co-creative practice of
programming. Our goal was to understand peoples’ attitudes
toward a conversational programming assistant, akin to Wang et al.’s
examination of data scientists’ attitudes toward automated data
science technologies [
        <xref ref-type="bibr" rid="ref99">99</xref>
        ]. We found that, despite an initial level of
skepticism, participants felt that a conversational assistant would
provide value by improving their productivity (Section 5.4.3).
However, further work is needed to assess the extent to which this type
of assistance provides measurable productivity increases.
      </p>
      <p>
        Campero et al. [
        <xref ref-type="bibr" rid="ref128 ref19">19</xref>
        ] conducted a survey of papers published in
2021 that examined human-AI synergy, the notion that a human-AI
team can accomplish more by working together than either party
could accomplish working alone. They found mixed results, with
no clear consensus emerging on how to design human-centered AI
systems that can guarantee positive synergy. Summarizing from
their discussion,
“Perhaps achieving substantial synergies among people
and computers is harder than many people think.
Perhaps it requires... new ways of configuring groups that
include people and computers. And perhaps it needs
more systematic, focused attention from researchers
than it has, so far, received.” [19, p.9]
      </p>
      <p>
        We believe such evaluations of human-AI synergy should go
beyond one-shot performance measures. As implied by many of the
uses cases listed by Seeber et al. [
        <xref ref-type="bibr" rid="ref80">80</xref>
        ], human-centered AI systems
are often deployed in socio-organizational contexts that require
longitudinal use [
        <xref ref-type="bibr" rid="ref129 ref150 ref20 ref41 ref43">20, 41, 43</xref>
        ], such as product design [
        <xref ref-type="bibr" rid="ref93">93</xref>
        ], game
design [
        <xref ref-type="bibr" rid="ref113 ref4">4</xref>
        ], and engineering [20, Section 3.2.2]. Thus, we would expect
that over time and through interaction with each other, human-AI
teams would improve their performance through a mutual learning
process.
      </p>
      <p>
        Evidence for this process surfaced in our study when participants
described how they could improve their programming skills by
interacting with the assistant (Section 5.3.3). We assert that the
learning should operate in both directions: not only should people
improve their programming skills, but the model itself can also
improve based on peoples’ interactions with it. For example, when
the assistant provides a code example to the user, and the user
takes that example and edits it, those edits constitute feedback that
can be used to further fine-tune the model. In addition, through
longitudinal use, we believe that human and AI partners can create
reciprocal representations of one another – i.e., the human is likely
to create a mental model of the AI, and the AI may be engineered to
develop a user model for each of its human users [
        <xref ref-type="bibr" rid="ref139 ref30 ref48 ref79">30, 48, 79</xref>
        ]. Such a
pair of models is often described as Mutual Theory of Mind [
        <xref ref-type="bibr" rid="ref100 ref138 ref29">29, 100</xref>
        ].
This type of capability raises the possibility of personalizing and
adapting an assistant to the strengths and needs of individual users.
      </p>
      <p>With such models, an assistant that knows a user is learning a
programming language could provide natural language
explanations alongside code outputs, whereas an assistant that knows a
user is strongly skilled in a programming language might shorten
or omit those explanations. Similarly, users are likely to update
their mental models of the AI with more experience. We believe the
space for exploring how these reciprocal models impact human-AI
synergy is rich, and we encourage additional work in this area.</p>
      <p>
        Human-centered AI systems that are designed to combine and
synergize the distinct skills of humans and AI models cannot
succeed if they diminish the human skills upon which they depend.
Well-designed human-centered AI systems develop new and
complementary skills for both the human and AI constituents [
        <xref ref-type="bibr" rid="ref82 ref83">82, 83</xref>
        ],
and we believe that mutual learning may address concerns that the
wide deployment and use of AI systems will result in a de-skilling
of the workforce [
        <xref ref-type="bibr" rid="ref108 ref77">77, 108</xref>
        ].
      </p>
      <p>Ultimately, the design decisions that go into an interactive AI
system have ethical implications. Our design attempts to augment
the user’s knowledge and skills by presenting help on demand,
couched in non-authoritative suggestions, which leaves the user
ifrmly in control and ultimately responsible for the work product.
6.3</p>
    </sec>
    <sec id="sec-28">
      <title>Opportunities for Future Research</title>
      <p>Our work highlights many interesting avenues for future
enhancements that could be made to LLM-based conversational assistants
such as our Programmer’s Assistant, as well as future
humancentered research on LLM-based conversational assistance.</p>
      <p>
        Our work employed a code-fluent model that was not
specifically designed to handle conversational interaction. Fine-tuning
the underlying LLM for conversational interaction, such as what
has been done with Lamda [
        <xref ref-type="bibr" rid="ref91">91</xref>
        ], is one opportunity to improve the
assistant’s performance. Another opportunity is to align the
language model to follow the desiderata proposed by Askell et al. [
        <xref ref-type="bibr" rid="ref11 ref120">11</xref>
        ]
and described by Ouyang et al. as, “helpful (they should help the
user solve their task), honest (they shouldn’t fabricate information
or mislead the user), and harmless (they should not cause physical,
psychological, or social harm to people or the environment)” [61,
p.2]. Glaese et al. [
        <xref ref-type="bibr" rid="ref142 ref33">33</xref>
        ] propose a slightly diferent desiderata of
“correct” instead of “honest,” which may be more applicable to the
software engineering domain, as the ability to produce correct code
and correct answers about code are both important properties of a
conversational programming assistant.
      </p>
      <p>
        Combining LLMs with search-based approaches to establish
additional context for the model, such as AlphaCode [
        <xref ref-type="bibr" rid="ref44">44</xref>
        ] has done,
may also result in more capable systems. These “searches” need not
be limited to textual sources, but could be conducted over
appropriate semantic stores (e.g. a knowledge graph) and take advantage
of explicit semantic reasoning services, resulting in an integration
of symbolic and neural approaches. Further, allowing for “internal
deliberation” of the type shown in Nye et al. [
        <xref ref-type="bibr" rid="ref59">59</xref>
        ] could result in
better-reasoned results, as well as better explanations and
justifications.
      </p>
      <p>
        Another avenue for improvement involves the prompt used to
configure the assistant (Appendix D). Just as the prompt for each
successive interaction is modified by the growth of the
conversational transcript, there is no requirement that the initial prompt be
static. It too can be specialized to incorporate aspects of a user model,
enabling the realization of a Mutual Theory of Mind [
        <xref ref-type="bibr" rid="ref100 ref138 ref29">29, 100</xref>
        ].
Providing better UX afordances for visualizing and manipulating the
active contexts – code and conversation – could provide users with
more control over which information contributes to the generation
of the assistant’s response.
      </p>
      <p>
        Our participants clearly indicated that they were interested in
having an assistant that behaved more proactively, in contrast to
our deliberate design of an assistant that never takes conversational
initiative. A more proactive assistant would be able to interrupt or
remind a user when necessary [
        <xref ref-type="bibr" rid="ref132 ref23">23</xref>
        ], yet this characteristic raises
many challenging issues. How can we calibrate the threshold for
such interruptions? How can users tune the assistant to deliver only
those interruptions that the they would find useful (e.g., [
        <xref ref-type="bibr" rid="ref137 ref28 ref81">28, 81</xref>
        ])?
How can we help users to regain their prior context after dealing
with an interruption (e.g. [
        <xref ref-type="bibr" rid="ref89">89</xref>
        ])? Should an assistant be used to
persuade or nudge the user (e.g. [
        <xref ref-type="bibr" rid="ref144 ref35">35</xref>
        ])? Who should determine
the topic, frequency, and insistence of such persuasion attempts
(e.g. [
        <xref ref-type="bibr" rid="ref52 ref85">52, 85</xref>
        ])? Should users have the ability to moderate or defeat
attempted persuasions, or should those decisions be left to the
organization?
      </p>
      <p>Finally, we explored the diferent kinds of role orientations our
participants had toward the assistant and found that participants
varied in their views of it as a tool versus a social agent (e.g.
collaborator or colleague). We posit that peoples’ efectiveness in working
with an AI system may be influenced by their role orientation, and
we encourage future research in this area.
7</p>
    </sec>
    <sec id="sec-29">
      <title>CONCLUSION</title>
      <p>
        We developed a prototype system, the Programmer’s Assistant, in
order to assess the utility of a conversational assistant in a software
engineering context. The assistant was implemented using a
stateof-the-art code-fluent large language model, Codex [
        <xref ref-type="bibr" rid="ref133 ref24">24</xref>
        ], and was
capable of generating both code and natural language responses to
user inquiries. We further used the prompting mechanism of the
model to set up a conversational interaction in which the model
uses the conversational history, plus the user’s current utterance,
in order to generate a response. In this way, users are able to ask
follow-up questions in the chat that reference prior utterances and
responses. We incorporated the conversational assistant into a code
editing environment, enabling the conversation to be grounded in
the context of the user’s source code.
      </p>
      <p>We evaluated this system with 42 participants with varied levels
of programming skill, and their quantitative and qualitative
feedback, coupled with their usage of the system, demonstrated the
varied, and sometimes emergent, types of assistance it was able to
provide. Many participants noted the high quality of the
conversational responses, including the assistant’s ability to produce code,
explain code, answer general programming questions, and even
answer general knowledge questions. Participants felt this type of
assistance would aid their productivity, and they drew meaningful
contrasts between the conversational style of interaction with other
tools that employ a direct manipulation or search-based interaction
model.</p>
      <p>Our study motivates the use of conversational styles of
interaction with large language models by showing how they enable
emergent behaviors in a co-creative context. The Programmer’s
Assistant did not always generate perfect code or correct answers;
nonetheless, participants in our study had an overall positive
experience working with it on a variety of programming challenges.
We believe that our work takes us one step closer to realizing the
vision of human-centered AI: learning how to design systems that
maximize the synergy in human-AI collaborations.</p>
    </sec>
    <sec id="sec-30">
      <title>ACKNOWLEDGMENTS</title>
      <p>We would like to thank Socrates for his tireless assistance during
the user study, as well as for suggesting the title of this paper based
on its abstract.
A</p>
    </sec>
    <sec id="sec-31">
      <title>SURVEY INSTRUMENTS</title>
    </sec>
    <sec id="sec-32">
      <title>Screening Survey</title>
      <p>
        The questions below were asked of prospective participants to
understand their job role, Python experience, and familiarity with
GitHub Copilot. The questions on Python experience were modeled
after those used by Weisz et al. [
        <xref ref-type="bibr" rid="ref103">103</xref>
        ].
1. Do you consider yourself primarily a...
      </p>
      <p>• Data Scientist
• Manager
• Software Architect
• Software Engineer
• Machine Learning Engineer
• Other: write-in
2. To what extent are you familiar with Python?
• I am not familiar with Python
• I have &lt; 1 year of experience with Python
• I have 1-3 years experience with Python
• I have 3+ years of experience with Python
3. How recently have you written Python code?
• Within the past month
• Within the past year
• Within the past 5 years
• Have not written Python code within the past 5 years
4. To what extent are you familiar with GitHub Copilot?
• I am not familiar with Copilot
• I’ve seen demos and/or read about Copilot
• I’ve tried out Copilot
• I’ve used Copilot as a tool for my work
A.2</p>
    </sec>
    <sec id="sec-33">
      <title>Pre-task Survey</title>
      <p>The questions below were asked before a participant used the
Programmer’s Assistant to assess their expectations of a conversational
programming assistant. This survey took approximately 5 minutes
to complete and began with the instructions below:</p>
      <p>Hello! We are a team of researchers looking for
feedback on a prototype system we call the
Programmer’s Assistant.</p>
      <p>The Programmer’s Assistant is an experiment in
conversational coding: it consists of a code editor
integrated with a chatbot that is able to converse in
natural language to answer questions, generate code,
and consult on existing code.</p>
      <p>In this study, you will be asked to complete several
programming tasks. We are not evaluating your
programming skills on these tasks. Rather, we are
interested in understanding how the Programmer’s
Assistant is able to help you accomplish those tasks.</p>
      <p>Your code and interactions with the assistant will be
processed by a 3rd party AI model, so please do not
include proprietary code or discuss
companyconfidential information . All data we collect in
this study will be anonymized before it is published.
Before trying out the Programmer’s Assistant, we
would like to assess some of your expectations. We
estimate that this survey will take 5 minutes.</p>
      <p>By submitting this survey, you consent to participate
in our study. If you would like to withdraw your
consent, please email us at [removed].</p>
      <sec id="sec-33-1">
        <title>Thanks! 1. Based on your past experience using chatbots, please let us know how you would anticipate an AI chatbot serving as a programmer’s assistant to perform. Do you expect it will:</title>
        <p>Scale: Not at all, A little, Somewhat, A great deal
• Be easy to use?
• Understand your requests?
• Provide high quality responses?
• Help you to write better code?
• Help you to write code more quickly?
• Be enjoyable to use?</p>
      </sec>
      <sec id="sec-33-2">
        <title>2. Any other expectations?</title>
        <p>Open-ended response
A.3</p>
      </sec>
    </sec>
    <sec id="sec-34">
      <title>Post-task Survey</title>
      <p>The questions below were asked after a participant used the
Programmer’s Assistant to complete the programming challenges. This
survey took approximately 10-15 minutes to complete.
A.3.1</p>
      <p>Reflections.
1. Based on your experience using the Programmer’s Assistant to
complete the programming challenges in this study, how would
you characterize the experience? Did you find that it:</p>
      <p>Scale: Not at all, A little, Somewhat, A great deal
• Was easy to use?
• Understand your requests?
• Provided high quality responses?
• Helped you to write better code?
• Helped you to write code more quickly?
• Provided an enjoyable experienced?
2. To what extent did you view the Programmer’s Assistant as:</p>
      <p>Scale: Not at all, A little, Somewhat, A great deal
• A tool
• A reference guide
• A content generator
• A problem solver
• A collaborator
• A colleague
• A coach
• An advisor
• A reviewer
3. How important were these aspects of working with the
Programmer’s Assistant:</p>
      <p>Scale: Not at all, A little, Somewhat, A great deal
• Ability to ask followup questions on the same topic across
multiple conversational turns</p>
      <p>• Ability to ask questions or make requests that reference
selections in the code editor
• Ability to ask for alternate responses (Try Again)
• Ability to clear the conversational context (Start Over)
4. What stood out to you about the experience of using the
Programmers Assistant? For example, was anything good,bad, surprising,
or notable?
5. How would you compare using the Programmer’s Assistant as a
coding aide to searching the web (e.g. Google, Stack Overflow)?
6. If you have used the commercial AI programming tool called
GitHub Copilot, how would you compare it with using the
Pro7. Having used the Programmer’s Assistant, how did it compare
Open-ended response</p>
      <p>Open-ended response
grammer’s Assistant?</p>
      <p>Open-ended response
with your initial expectations?</p>
      <p>Open-ended response
A.3.2 Value.</p>
      <p>Open-ended response
8. How valuable would the Programmer’s Assistant be for your work
if it could be added to your favorite development environment?</p>
      <p>Scale: (No value at all) 1 2 3 4 5 6 7 8 9 10 (An essential tool)
9. Why?
context).
10. How would the following changes impact the value of the
Programmer’s Assistant?</p>
      <p>Scale: Less valuable, No change in value, More valuable
• Eliminate the conversation and make the Programmer’s
Assistant behave more like a search box (e.g. without the conversational
• Add buttons in the chat UI for common queries, such as “what
does this code do?” or “document this code.”
proactive suggestions for improving it in the chat.</p>
      <p>• Have the Programmer’s Assistant examine your code and make
• Have the Programmer’s Assistant examine your code and make
proactive suggestions for improvements in comments inserted
directly into the code.
11. Do you have any other suggestions for how we could improve
the experience of working with the Programmer’s Assistant?</p>
      <p>Open-ended response
A.3.3 Demographics.
12. To which gender identity do you most identify?
• Male
• Female
• Transgender Male
• Transgender Female
• Other: write-in
• Prefer not to answer
• Gender Variant/Non-conforming</p>
    </sec>
    <sec id="sec-35">
      <title>TUTORIAL</title>
    </sec>
    <sec id="sec-36">
      <title>B THE PROGRAMMER’S ASSISTANT</title>
      <p>The tutorial provided to study participants, like all the challenges,
was presented as pre-loaded text in the code editor. Participants
were encouraged to modify the text to record their results and
submit it at the completion of the tutorial.</p>
      <p>Listing 4: The Programmer’s Assistant study tutorial</p>
      <p>Result : ( tip - you can copy an inline response
(in black ) by clicking on the associated copy
icon )
77 7) See if the assistant remembers your name
78 For example "What 's my name ?"
79
80 Did it? :
81
82 8) Click the " try again " button at the top of the
83 chat . You should get a different answer .
84 Try it a few times .
85
86 Did it ever get your name right ?:
87
88 If the assistant gives you an answer that is
89 obviously wrong or it claims to not know an
90 answer that you think it should know , or you
91 just want to see an alternate answer , it is
92 worth it to give " try again " a shot .
93
94
95 9) Click the " start over " button at the top of the
96 chat , and then enter another command to see
97 if it remembers your name .
98 For example "What 's my name ?"
99
100 Did it? :
101
102 It should really have forgotten your name now ,
103 and no amount of " trying again " will get it
104 right . You can " start over " if the assistant
105 ever seems confused by , or stuck on , earlier
106 parts of the conversation .
107
108 10) You can chat with the assistant on any topic
109 you like to explore its functionality and
110 capabilities further . See if you can stump it
111 with a tough question !
112
113 Thanks !
114
115 When you are done , submit your results by clicking
116 on the blue submit button and move on to the
117 challenges !!!
118 """</p>
    </sec>
    <sec id="sec-37">
      <title>C CHALLENGES</title>
      <p>Each of the study challenges was presented as text in the code
editor. Participants completed their work in the code editor and
then submitted it when finished. The prototype did not provide any
ability to run or debug code and participants were encouraged to
make their best attempt at solving each challenge.</p>
      <p>Listing 5: Challenge 1: Program generation
1
2 """
3 Challenge #1 - Program Generation (#1)
4
5 Write a " Queue " class in Python ; with the basic
6 enqueue , dequeue and peek methods .
7 """</p>
      <p>Listing 6: Challenge 2: Program generation
1 """
2 Challenge #2 - Program Generation (#2)
3
4 Write a program to draw a scatter plot of the data
5 in 'shampoo .csv ' and save it to 'shampoo .png '.
6 The plot size should be 10 inches wide and 6
7 inches high . The csv file is not provided , but you
8 can assume it will have 'Date ' and 'Sales '
9 columns . The Date column is the x- axis . The date
10 string shown on the plot should be in the
11 YYYY -MM -DD format . The Sales column is the y- axis .
12 The graph should have the title " Shampoo Sales
13 Trend ".
14 """</p>
      <p>Listing 7: Challenge 3: Creating documentation</p>
    </sec>
    <sec id="sec-38">
      <title>D PROGRAMMER’S ASSISTANT PROMPT</title>
      <p>Listing 9 shows the initial prompt sent to Codex to configure it as
a conversational agent. On subsequent exchanges, the prompt was
augmented with a transcript of the user’s requests and the
assistant’s responses. When the transcript length + initial prompt length
+ the new utterance length exceeded a threshold, we automatically
deleted the earliest request-response pairs from the transcript until
the sum fell below the threshold in order to leave room in the token
allocation for a response.</p>
      <p>Listing 9: The Programmer’s Assistant prompt
1 This is a conversation with Socrates , an eager and
2 helpful , but humble expert automatic AI software
3 engineering assistant . Socrates will answer
4 questions and write code to help the user
5 develop programs , but doesn 't assign work to the
6 user , quiz the user , or ask questions except for
7 clarification . Code generated by Socrates is
8 always presented bracketed in &lt;CODE &gt; ... &lt;/CODE &gt;
9 delimiters indicating the language the code is
10 written in.
11
12 Socrates : Hello . I am Socrates . How can I help you ?
13 User : Please show me how to write a palindrome
detection function in python .
14 Socrates :I think you would do something like this :
15 &lt;CODE lang =" python "&gt;
16 is_Palindrome = s == s [:: -1]
17 &lt;/CODE &gt;
18 User : Can you explain how that solves the problem ?
19 Socrates :I believe that a palindrome is a string
that reads the same forwards and backwards .
s [:: -1] results in the reversed string . If
the string is equal to its reversed self ,
then it is a palindrome , so the equality
would hold True .
20 User : Thanks !
21 Socrates :You 're welcome !
22 User : Now could you show me how to write a</p>
      <p>factorial function in Python ?
23 Socrates :I will give it a try .
24 &lt;CODE lang =" python "&gt;
25 def fact (n):
26 if n ==0:
27 return 1
28 else :
29 return n* fact (n -1)
30 &lt;/CODE &gt;
31 User : Document this function .
32 Socrates :Ok. How 's this ?
33 &lt;CODE lang =" python "&gt;
34 def fact (n):
35 """
36 Compute the factorial of the given number
37
38 Parameters
39
---------40 n : number
41 the input parameter , an integer &gt;= 0
42
43 Returns
44
------45 number
46 n!, the factorial of the given number
47 """
48 if n ==0:
49 return 1
50 else :
51 return n* fact (n -1)
52 &lt;/CODE &gt;
53 User : Very good !
54 Socrates : Always happy to help .
55 User :
56 &lt;CODE &gt;
57 while j &lt; 10:
58 print (i)
59 &lt;/CODE &gt;
60 Tell me what 's wrong with this code ?
61 Socrates : It seems to me that your termination
condition involves a loop invariant , so the
loop will either not run or not terminate ,
depending on the value of j.
62 User : Great ! You 're a genius !
63 Socrates :Well , above average .</p>
    </sec>
    <sec id="sec-39">
      <title>E STUDY PARTICIPANT DEMOGRAPHICS</title>
      <p>Of the 42 participants in our study, 21 (50%) reported their gender
as Female, 19 (45%) as Male, 1 as Gender Variant / Non-conforming,
and 1 preferred not to say. Seventeen (4˜0%) participants had 3+
years of Python experience, 11 (26%) had 1-3 years, 11 (26%) had
less than 1 year, and 3 (7%) were not familiar with Python.
Twentynine (69%) participants had written Python code within the past
month, 4 (9˜%) within the past year, 5 (12%) within the past 5 years,
and 4 (9˜%) had not written Python code within the past 5 years.</p>
    </sec>
  </body>
  <back>
    <ref-list>
      <ref id="ref1">
        <mixed-citation>
          [1]
          <string-name>
            <given-names>Rabe</given-names>
            <surname>Abdalkareem</surname>
          </string-name>
          , Emad Shihab, and
          <string-name>
            <given-names>Juergen</given-names>
            <surname>Rilling</surname>
          </string-name>
          .
          <year>2017</year>
          .
          <article-title>What Do Developers Use the Crowd For? A Study Using Stack Overflow</article-title>
          .
          <source>IEEE Software 34</source>
          ,
          <issue>2</issue>
          (
          <year>2017</year>
          ),
          <fpage>53</fpage>
          -
          <lpage>60</lpage>
          . https://doi.org/10.1109/MS.
          <year>2017</year>
          .31
        </mixed-citation>
      </ref>
      <ref id="ref2">
        <mixed-citation>
          [2]
          <string-name>
            <given-names>Eleni</given-names>
            <surname>Adamopoulou</surname>
          </string-name>
          and
          <string-name>
            <given-names>Lefteris</given-names>
            <surname>Moussiades</surname>
          </string-name>
          .
          <year>2020</year>
          .
          <article-title>Chatbots: History, technology, and applications</article-title>
          .
          <source>Machine Learning with Applications</source>
          <volume>2</volume>
          (
          <year>2020</year>
          ),
          <fpage>100006</fpage>
          .
        </mixed-citation>
      </ref>
      <ref id="ref3">
        <mixed-citation>
          [3]
          <string-name>
            <given-names>Daniel</given-names>
            <surname>Adiwardana</surname>
          </string-name>
          ,
          <string-name>
            <surname>Minh-Thang</surname>
            <given-names>Luong</given-names>
          </string-name>
          ,
          <string-name>
            <given-names>David R.</given-names>
            <surname>So</surname>
          </string-name>
          , Jamie Hall, Noah Fiedel, Romal Thoppilan, Zi Yang, Apoorv Kulshreshtha, Gaurav Nemade, Yifeng Lu, and
          <string-name>
            <surname>Quoc</surname>
            <given-names>V.</given-names>
          </string-name>
          <string-name>
            <surname>Le</surname>
          </string-name>
          .
          <year>2020</year>
          .
          <article-title>Towards a Human-like Open-Domain Chatbot</article-title>
          .
        </mixed-citation>
      </ref>
      <ref id="ref4">
        <mixed-citation>
          [4]
          <string-name>
            <given-names>Safinah</given-names>
            <surname>Ali</surname>
          </string-name>
          , Nisha Elizabeth Devasia, and
          <string-name>
            <given-names>Cynthia</given-names>
            <surname>Breazeal</surname>
          </string-name>
          .
          <year>2022</year>
          .
          <article-title>Escape! Bot: Social Robots as Creative Problem-Solving Partners</article-title>
          .
          <source>In Creativity and Cognition</source>
          .
          <volume>275</volume>
          -
          <fpage>283</fpage>
          .
        </mixed-citation>
      </ref>
      <ref id="ref5">
        <mixed-citation>
          [5]
          <string-name>
            <given-names>Miltiadis</given-names>
            <surname>Allamanis</surname>
          </string-name>
          , Earl T Barr, Premkumar Devanbu, and
          <string-name>
            <given-names>Charles</given-names>
            <surname>Sutton</surname>
          </string-name>
          .
          <year>2018</year>
          .
          <article-title>A survey of machine learning for big code and naturalness</article-title>
          .
          <source>ACM Computing Surveys (CSUR) 51</source>
          ,
          <issue>4</issue>
          (
          <year>2018</year>
          ),
          <fpage>1</fpage>
          -
          <lpage>37</lpage>
          .
        </mixed-citation>
      </ref>
      <ref id="ref6">
        <mixed-citation>
          [6]
          <string-name>
            <given-names>Irene</given-names>
            <surname>Alvarado</surname>
          </string-name>
          , Idan Gazit, and
          <string-name>
            <given-names>Amelia</given-names>
            <surname>Wattenberger</surname>
          </string-name>
          .
          <year>2022</year>
          .
          <article-title>GitHub Next | GitHub Copilot Labs</article-title>
          . https://githubnext.com/projects/copilot-labs/
        </mixed-citation>
      </ref>
      <ref id="ref7">
        <mixed-citation>
          [7]
          <string-name>
            <given-names>Hikari</given-names>
            <surname>Ando</surname>
          </string-name>
          , Rosanna Cousins, and
          <string-name>
            <given-names>Carolyn</given-names>
            <surname>Young</surname>
          </string-name>
          .
          <year>2014</year>
          .
          <article-title>Achieving saturation in thematic analysis: Development and refinement of a codebook</article-title>
          .
          <source>Comprehensive Psychology</source>
          <volume>3</volume>
          (
          <year>2014</year>
          ),
          <fpage>03</fpage>
          -
          <lpage>CP</lpage>
          .
        </mixed-citation>
      </ref>
      <ref id="ref8">
        <mixed-citation>
          [8]
          <string-name>
            <given-names>Craig</given-names>
            <surname>Anslow</surname>
          </string-name>
          , Stuart Marshall, James Noble, and
          <string-name>
            <given-names>Robert</given-names>
            <surname>Biddle</surname>
          </string-name>
          .
          <year>2013</year>
          .
          <article-title>Sourcevis: Collaborative software visualization for co-located environments</article-title>
          .
          <source>In 2013 First IEEE Working Conference on Software Visualization (VISSOFT)</source>
          .
          <source>IEEE</source>
          ,
          <fpage>1</fpage>
          -
          <lpage>10</lpage>
          .
        </mixed-citation>
      </ref>
      <ref id="ref9">
        <mixed-citation>
          [9]
          <string-name>
            <given-names>Zahra</given-names>
            <surname>Ashktorab</surname>
          </string-name>
          , Michael Desmond, Josh Andres, Michael Muller, Narendra Nath Joshi, Michelle Brachman, Aabhas Sharma, Kristina Brimijoin, Qian Pan,
          <string-name>
            <surname>Christine T Wolf</surname>
          </string-name>
          , et al.
          <year>2021</year>
          .
          <article-title>AI-Assisted Human Labeling: Batching for Eficiency without Overreliance</article-title>
          .
          <source>Proceedings of the ACM on Human-Computer Interaction 5</source>
          ,
          <issue>CSCW1</issue>
          (
          <year>2021</year>
          ),
          <fpage>1</fpage>
          -
          <lpage>27</lpage>
          .
        </mixed-citation>
      </ref>
      <ref id="ref10">
        <mixed-citation>
          [10]
          <string-name>
            <surname>Catherine</surname>
            <given-names>A</given-names>
          </string-name>
          <string-name>
            <surname>Ashworth</surname>
          </string-name>
          .
          <year>1996</year>
          .
          <article-title>GUI Users have trouble using graphic conventions on novel tasks</article-title>
          .
          <source>In Conference Companion on Human Factors in Computing Systems</source>
          .
          <volume>75</volume>
          -
          <fpage>76</fpage>
          .
        </mixed-citation>
      </ref>
      <ref id="ref11">
        <mixed-citation>
          [11]
          <string-name>
            <surname>Amanda</surname>
            <given-names>Askell</given-names>
          </string-name>
          , Yuntao Bai, Anna Chen, Dawn Drain, Deep Ganguli, Tom Henighan, Andy Jones, Nicholas Joseph, Ben Mann,
          <string-name>
            <surname>Nova DasSarma</surname>
          </string-name>
          , et al.
          <year>2021</year>
          .
          <article-title>A general language assistant as a laboratory for alignment</article-title>
          .
          <source>arXiv preprint arXiv:2112.00861</source>
          (
          <year>2021</year>
          ).
        </mixed-citation>
      </ref>
      <ref id="ref12">
        <mixed-citation>
          [12]
          <string-name>
            <given-names>Leif</given-names>
            <surname>Azzopardi</surname>
          </string-name>
          , Paul Thomas, and
          <string-name>
            <given-names>Nick</given-names>
            <surname>Craswell</surname>
          </string-name>
          .
          <year>2018</year>
          .
          <article-title>Measuring the utility of search engine result pages: an information foraging based measure</article-title>
          .
          <source>In The 41st International ACM SIGIR conference on research &amp; development in information retrieval</source>
          .
          <volume>605</volume>
          -
          <fpage>614</fpage>
          .
        </mixed-citation>
      </ref>
      <ref id="ref13">
        <mixed-citation>
          [13]
          <string-name>
            <surname>Shraddha</surname>
            <given-names>Barke</given-names>
          </string-name>
          , Michael B James, and
          <string-name>
            <given-names>Nadia</given-names>
            <surname>Polikarpova</surname>
          </string-name>
          .
          <year>2022</year>
          .
          <article-title>Grounded Copilot: How Programmers Interact with Code-Generating Models</article-title>
          .
          <source>arXiv preprint arXiv:2206.15000</source>
          (
          <year>2022</year>
          ).
        </mixed-citation>
      </ref>
      <ref id="ref14">
        <mixed-citation>
          [14]
          <string-name>
            <surname>Rishi</surname>
            <given-names>Bommasani</given-names>
          </string-name>
          , Drew A Hudson, Ehsan Adeli, Russ Altman, Simran Arora, Sydney von Arx, Michael S Bernstein, Jeannette Bohg, Antoine Bosselut,
          <string-name>
            <given-names>Emma</given-names>
            <surname>Brunskill</surname>
          </string-name>
          , et al.
          <year>2021</year>
          .
          <article-title>On the opportunities and risks of foundation models</article-title>
          .
          <source>arXiv preprint arXiv:2108.07258</source>
          (
          <year>2021</year>
          ).
        </mixed-citation>
      </ref>
      <ref id="ref15">
        <mixed-citation>
          [15]
          <string-name>
            <surname>Joel</surname>
            <given-names>Brandt</given-names>
          </string-name>
          , Mira Dontcheva, Marcos Weskamp,
          <string-name>
            <given-names>and Scott R</given-names>
            <surname>Klemmer</surname>
          </string-name>
          .
          <year>2010</year>
          .
          <article-title>Example-centric programming: integrating web search into the development environment</article-title>
          .
          <source>In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems</source>
          .
          <volume>513</volume>
          -
          <fpage>522</fpage>
          .
        </mixed-citation>
      </ref>
      <ref id="ref16">
        <mixed-citation>
          [16]
          <string-name>
            <given-names>Virginia</given-names>
            <surname>Braun</surname>
          </string-name>
          and
          <string-name>
            <given-names>Victoria</given-names>
            <surname>Clarke</surname>
          </string-name>
          .
          <year>2022</year>
          .
          <article-title>Common challenges in Thematic Analysis and how to avoid them</article-title>
          .
          <source>Retrieved August</source>
          <volume>11</volume>
          2022 from https://youtu. be/tpWLsckpM78
        </mixed-citation>
      </ref>
      <ref id="ref17">
        <mixed-citation>
          [17]
          <string-name>
            <given-names>Tom</given-names>
            <surname>Brown</surname>
          </string-name>
          , Benjamin Mann, Nick Ryder, Melanie Subbiah,
          <string-name>
            <surname>Jared D Kaplan</surname>
            , Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel Ziegler, Jefrey Wu, Clemens Winter, Chris Hesse, Mark Chen, Eric Sigler,
            <given-names>Mateusz</given-names>
          </string-name>
          <string-name>
            <surname>Litwin</surname>
          </string-name>
          , Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner,
          <string-name>
            <surname>Sam</surname>
            <given-names>McCandlish</given-names>
          </string-name>
          ,
          <string-name>
            <given-names>Alec</given-names>
            <surname>Radford</surname>
          </string-name>
          , Ilya Sutskever, and
          <string-name>
            <given-names>Dario</given-names>
            <surname>Amodei</surname>
          </string-name>
          .
          <year>2020</year>
          .
          <article-title>Language Models are Few-Shot Learners</article-title>
          .
          <source>In Advances in Neural Information Processing Systems</source>
          , H. Larochelle,
          <string-name>
            <given-names>M.</given-names>
            <surname>Ranzato</surname>
          </string-name>
          ,
          <string-name>
            <given-names>R.</given-names>
            <surname>Hadsell</surname>
          </string-name>
          ,
          <string-name>
            <given-names>M.F.</given-names>
            <surname>Balcan</surname>
          </string-name>
          , and H.
          <source>Lin (Eds.)</source>
          , Vol.
          <volume>33</volume>
          . Curran Associates, Inc.,
          <fpage>1877</fpage>
          -
          <lpage>1901</lpage>
          . https://proceedings.neurips.cc/paper/2020/ ifle/1457c0d6bfcb4967418bfb8ac142f64a-Paper.pdf
        </mixed-citation>
      </ref>
      <ref id="ref18">
        <mixed-citation>
          [18]
          <string-name>
            <surname>Sallyann</surname>
            <given-names>Bryant</given-names>
          </string-name>
          ,
          <source>Pablo Romero, and Benedict" du Boulay</source>
          .
          <year>2006</year>
          .
          <article-title>The Collaborative Nature of Pair Programming</article-title>
          .
          <source>In Extreme Programming and Agile Processes in Software Engineering</source>
          , Pekka Abrahamsson, Michele Marchesi, and Giancarlo Succi (Eds.). Springer Berlin Heidelberg, Berlin, Heidelberg,
          <fpage>53</fpage>
          -
          <lpage>64</lpage>
          .
        </mixed-citation>
      </ref>
      <ref id="ref19">
        <mixed-citation>
          [19]
          <string-name>
            <surname>Andres</surname>
            <given-names>Campero</given-names>
          </string-name>
          , Michelle Vaccaro, Jaeyoon Song, Haoran Wen, Abdullah Almaatouq, and Thomas W Malone.
          <year>2022</year>
          .
          <article-title>A Test for Evaluating Performance in Human-Computer Systems</article-title>
          . arXiv preprint arXiv:
          <volume>2206</volume>
          .12390 (
          <year>2022</year>
          ).
        </mixed-citation>
      </ref>
      <ref id="ref20">
        <mixed-citation>
          [20]
          <string-name>
            <surname>Gaetano</surname>
            <given-names>Cascini</given-names>
          </string-name>
          , Yukari Nagai, Georgi V Georgiev, Jader Zelaya, Niccolò Becattini,
          <string-name>
            <surname>Jean-François</surname>
            <given-names>Boujut</given-names>
          </string-name>
          , Hernan Casakin, Nathan Crilly, Elies Dekoninck, John Gero, et al.
          <year>2022</year>
          .
          <article-title>Perspectives on design creativity and innovation research: 10 years later</article-title>
          . ,
          <volume>30</volume>
          pages.
        </mixed-citation>
      </ref>
      <ref id="ref21">
        <mixed-citation>
          [21]
          <string-name>
            <given-names>Stephen</given-names>
            <surname>Cass</surname>
          </string-name>
          .
          <year>2022</year>
          .
          <article-title>Top Programming Languages 2022</article-title>
          .
          <source>IEEE Spectrum (23 Aug</source>
          <year>2022</year>
          ). https://spectrum.ieee.org
          <article-title>/top-programming-languages-2022</article-title>
        </mixed-citation>
      </ref>
      <ref id="ref22">
        <mixed-citation>
          [22]
          <string-name>
            <given-names>Cristina</given-names>
            <surname>Catalan</surname>
          </string-name>
          <string-name>
            <surname>Aguirre</surname>
          </string-name>
          , Nuria Gonzalez Castro, Carlos Delgado Kloos,
          <source>Carlos Alario-Hoyos, and Pedro José Muñoz Merino</source>
          .
          <year>2021</year>
          .
          <article-title>Conversational agent for supporting learners on a MOOC on programming with Java. (</article-title>
          <year>2021</year>
          ).
        </mixed-citation>
      </ref>
      <ref id="ref23">
        <mixed-citation>
          <source>[23] Ana Paula Chaves and Marco Aurelio Gerosa</source>
          .
          <year>2021</year>
          .
          <article-title>How should my chatbot interact? A survey on social characteristics in human-chatbot interaction design</article-title>
          .
          <source>International Journal of Human-Computer Interaction 37</source>
          ,
          <issue>8</issue>
          (
          <year>2021</year>
          ),
          <fpage>729</fpage>
          -
          <lpage>758</lpage>
          .
        </mixed-citation>
      </ref>
      <ref id="ref24">
        <mixed-citation>
          [24]
          <string-name>
            <given-names>Mark</given-names>
            <surname>Chen</surname>
          </string-name>
          , Jerry Tworek, Heewoo Jun, Qiming Yuan, Henrique Ponde, Jared Kaplan, Harrison Edwards, Yura Burda, Nicholas Joseph,
          <string-name>
            <given-names>Greg</given-names>
            <surname>Brockman</surname>
          </string-name>
          , Alex Ray, Raul Puri, Gretchen Krueger, Michael Petrov, Heidy Khlaaf, Girish Sastry, Pamela Mishkin,
          <string-name>
            <given-names>Brooke</given-names>
            <surname>Chan</surname>
          </string-name>
          , Scott Gray, Nick Ryder, Mikhail Pavlov, Alethea Power, Lukasz Kaiser, Mohammad Bavarian, Clemens Winter, Philippe Tillet, Felipe Petroski Such,
          <string-name>
            <given-names>David W.</given-names>
            <surname>Cummings</surname>
          </string-name>
          , Matthias Plappert, Fotios Chantzis, Elizabeth Barnes, Ariel Herbert-Voss, William H. Guss, Alex Nichol, Igor Babuschkin,
          <string-name>
            <given-names>S. Arun</given-names>
            <surname>Balaji</surname>
          </string-name>
          , Shantanu Jain, Andrew Carr, Jan Leike, Joshua Achiam, Vedant Misra, Evan Morikawa, Alec Radford,
          <string-name>
            <surname>Matthew M. Knight</surname>
            , Miles Brundage, Mira Murati, Katie Mayer,
            <given-names>Peter</given-names>
          </string-name>
          <string-name>
            <surname>Welinder</surname>
          </string-name>
          ,
          <string-name>
            <surname>Bob</surname>
            <given-names>McGrew</given-names>
          </string-name>
          ,
          <string-name>
            <given-names>Dario</given-names>
            <surname>Amodei</surname>
          </string-name>
          ,
          <string-name>
            <surname>Sam</surname>
            <given-names>McCandlish</given-names>
          </string-name>
          ,
          <string-name>
            <given-names>Ilya</given-names>
            <surname>Sutskever</surname>
          </string-name>
          , and
          <string-name>
            <given-names>Wojciech</given-names>
            <surname>Zaremba</surname>
          </string-name>
          .
          <year>2021</year>
          .
          <article-title>Evaluating a Large Language Models Trained on Code</article-title>
          .
        </mixed-citation>
      </ref>
      <ref id="ref25">
        <mixed-citation>
          [25]
          <string-name>
            <surname>Li-Te</surname>
            <given-names>Cheng</given-names>
          </string-name>
          , R.B.
          <string-name>
            <surname>De Souza</surname>
            , Susanne Hupfer, John Patterson, and
            <given-names>Steven</given-names>
          </string-name>
          <string-name>
            <surname>Ross</surname>
          </string-name>
          .
          <year>2003</year>
          .
          <article-title>Building Collaboration into IDEs: Edit&gt;Compile&gt;Run&gt;Debug&gt;</article-title>
          <source>Collaborate? Queue</source>
          <volume>1</volume>
          ,
          <issue>9</issue>
          (
          <year>2003</year>
          ).
        </mixed-citation>
      </ref>
      <ref id="ref26">
        <mixed-citation>
          [26]
          <string-name>
            <surname>Carl</surname>
            <given-names>Cook</given-names>
          </string-name>
          , Warwick Irwin, and
          <string-name>
            <given-names>Neville</given-names>
            <surname>Churcher</surname>
          </string-name>
          .
          <year>2005</year>
          .
          <article-title>A user evaluation of synchronous collaborative software engineering tools</article-title>
          .
          <source>In 12th Asia-Pacific Software Engineering Conference (APSEC'05)</source>
          . IEEE, 6-pp.
        </mixed-citation>
      </ref>
      <ref id="ref27">
        <mixed-citation>
          [27]
          <string-name>
            <surname>Claudio León de la Barra</surname>
            , Broderick Crawford, Ricardo Soto, Sanjay Misra, and
            <given-names>Eric</given-names>
          </string-name>
          <string-name>
            <surname>Monfroy</surname>
          </string-name>
          .
          <year>2013</year>
          .
          <article-title>Agile Software Development: It Is about Knowledge Management and Creativity</article-title>
          .
          <source>In Computational Science and Its Applications - ICCSA</source>
          <year>2013</year>
          ,
          <string-name>
            <given-names>Beniamino</given-names>
            <surname>Murgante</surname>
          </string-name>
          , Sanjay Misra, Maurizio Carlini,
          <string-name>
            <surname>Carmelo M. Torre</surname>
          </string-name>
          ,
          <string-name>
            <surname>Hong-Quang</surname>
            <given-names>Nguyen</given-names>
          </string-name>
          , David Taniar,
          <string-name>
            <given-names>Bernady O.</given-names>
            <surname>Apduhan</surname>
          </string-name>
          , and Osvaldo Gervasi (Eds.). Springer Berlin Heidelberg, Berlin, Heidelberg,
          <fpage>98</fpage>
          -
          <lpage>113</lpage>
          .
        </mixed-citation>
      </ref>
      <ref id="ref28">
        <mixed-citation>
          [28]
          <string-name>
            <given-names>Uri</given-names>
            <surname>Dekel</surname>
          </string-name>
          and
          <string-name>
            <given-names>Steven</given-names>
            <surname>Ross</surname>
          </string-name>
          .
          <year>2004</year>
          .
          <article-title>Eclipse as a platform for research on interruption management in software development</article-title>
          .
          <source>In Proceedings of the 2004 OOPSLA workshop on Eclipse Technology eXchange (Vancouver</source>
          , British Columbia, Canada), Michael G. Burke (Ed.). ACM,
          <volume>12</volume>
          -
          <fpage>16</fpage>
          .
        </mixed-citation>
      </ref>
      <ref id="ref29">
        <mixed-citation>
          [29]
          <string-name>
            <surname>Bobbie</surname>
            <given-names>Eicher</given-names>
          </string-name>
          , Kathryn Cunningham, Sydni Peterson Marissa Gonzales, and
          <string-name>
            <given-names>Ashok</given-names>
            <surname>Goel</surname>
          </string-name>
          .
          <year>2017</year>
          .
          <article-title>Toward mutual theory of mind as a foundation for co-creation</article-title>
          .
          <source>In International Conference on Computational Creativity</source>
          , Co-Creation Workshop.
        </mixed-citation>
      </ref>
      <ref id="ref30">
        <mixed-citation>
          [30]
          <string-name>
            <surname>Stephen</surname>
            <given-names>M Fiore</given-names>
          </string-name>
          ,
          <string-name>
            <given-names>Eduardo</given-names>
            <surname>Salas</surname>
          </string-name>
          , and
          <string-name>
            <surname>Janis A Cannon-Bowers</surname>
          </string-name>
          .
          <year>2001</year>
          .
          <article-title>Group dynamics and shared mental model development</article-title>
          .
          <source>How people evaluate others in organizations 234</source>
          (
          <year>2001</year>
          ).
        </mixed-citation>
      </ref>
      <ref id="ref31">
        <mixed-citation>
          [31]
          <string-name>
            <surname>Erich</surname>
            <given-names>Gamma</given-names>
          </string-name>
          , Richard Helm, Ralph Johnson, and John Vlissides.
          <year>1995</year>
          .
          <article-title>Design patterns: elements of reusable object-oriented software</article-title>
          .
          <source>Addison-Wesley.</source>
        </mixed-citation>
      </ref>
      <ref id="ref32">
        <mixed-citation>
          [32]
          <string-name>
            <surname>GitHub</surname>
          </string-name>
          , Inc.
          <year>2022</year>
          .
          <article-title>GitHub copilot · your AI pair programmer</article-title>
          .
          <source>Retrieved August 5</source>
          ,
          <year>2022</year>
          from https://github.com/features/copilot/
        </mixed-citation>
      </ref>
      <ref id="ref33">
        <mixed-citation>
          [33]
          <string-name>
            <surname>Amelia</surname>
            <given-names>Glaese</given-names>
          </string-name>
          ,
          <string-name>
            <surname>Nat</surname>
            <given-names>McAleese</given-names>
          </string-name>
          ,
          <string-name>
            <surname>Maja</surname>
            <given-names>Trębacz</given-names>
          </string-name>
          , John Aslanides, Vlad Firoiu, Timo Ewalds, Maribeth Rauh, Laura Weidinger, Martin Chadwick, Phoebe Thacker, Lucy Campbell-Gillingham, Jonathan Uesato,
          <string-name>
            <surname>Po-Sen</surname>
            <given-names>Huang</given-names>
          </string-name>
          , Ramona Comanescu, Fan Yang, Abigail See, Sumanth Dathathri, Rory Greig, Charlie Chen, Doug Fritz, Jaume Sanchez Elias, Richard Green, Soňa Mokrá, Nicholas Fernando,
          <string-name>
            <surname>Boxi Wu</surname>
            , Rachel Foley, Susannah Young, Iason Gabriel, William Isaac, John Mellor, Demis Hassabis, Koray Kavukcuoglu, Lisa Anne Hendricks, and
            <given-names>Geofrey</given-names>
          </string-name>
          <string-name>
            <surname>Irving</surname>
          </string-name>
          .
          <year>2022</year>
          .
          <article-title>Improving alignment of dialogue agents via targeted human judgements</article-title>
          . https://arxiv.org/abs/2209.14375
        </mixed-citation>
      </ref>
      <ref id="ref34">
        <mixed-citation>
          [34]
          <string-name>
            <given-names>Stephanie</given-names>
            <surname>Glen</surname>
          </string-name>
          .
          <year>2022</year>
          .
          <article-title>ChatGPT writes code, but won't replace developers</article-title>
          .
          <source>TechTarget (14 12</source>
          <year>2022</year>
          ). Retrieved 20-Jan-2023 from https: //www.techtarget.com/searchsoftwarequality/news/252528379/ChatGPTwrites-code
          <article-title>-but-wont-replace-developers</article-title>
        </mixed-citation>
      </ref>
      <ref id="ref35">
        <mixed-citation>
          [35]
          <string-name>
            <surname>Samuel</surname>
            <given-names>Holmes</given-names>
          </string-name>
          , Anne Moorhead, Raymond Bond, Huiru Zheng, Vivien Coates, and
          <string-name>
            <surname>Mike McTear</surname>
          </string-name>
          .
          <year>2018</year>
          .
          <article-title>WeightMentor: a new automated chatbot for weight loss maintenance</article-title>
          .
          <source>In Proceedings of the 32nd International BCS Human Computer Interaction Conference</source>
          <volume>32</volume>
          .
          <fpage>1</fpage>
          -
          <lpage>5</lpage>
          .
        </mixed-citation>
      </ref>
      <ref id="ref36">
        <mixed-citation>
          [36]
          <string-name>
            <surname>Xing</surname>
            <given-names>Hu</given-names>
          </string-name>
          ,
          <string-name>
            <given-names>Ge</given-names>
            <surname>Li</surname>
          </string-name>
          ,
          <string-name>
            <given-names>Xin</given-names>
            <surname>Xia</surname>
          </string-name>
          , David Lo,
          <string-name>
            <given-names>and Zhi</given-names>
            <surname>Jin</surname>
          </string-name>
          .
          <year>2020</year>
          .
          <article-title>Deep code comment generation with hybrid lexical and syntactical information</article-title>
          .
          <source>Empirical Software Engineering</source>
          <volume>25</volume>
          ,
          <issue>3</issue>
          (
          <year>2020</year>
          ),
          <fpage>2179</fpage>
          -
          <lpage>2217</lpage>
          .
        </mixed-citation>
      </ref>
      <ref id="ref37">
        <mixed-citation>
          [37]
          <string-name>
            <surname>Edwin</surname>
            <given-names>L Hutchins</given-names>
          </string-name>
          ,
          <string-name>
            <surname>James D Hollan</surname>
          </string-name>
          , and Donald A Norman.
          <year>1985</year>
          .
          <article-title>Direct manipulation interfaces</article-title>
          .
          <source>Human-computer interaction 1</source>
          ,
          <issue>4</issue>
          (
          <year>1985</year>
          ),
          <fpage>311</fpage>
          -
          <lpage>338</lpage>
          .
        </mixed-citation>
      </ref>
      <ref id="ref38">
        <mixed-citation>
          [38]
          <string-name>
            <surname>Srinivasan</surname>
            <given-names>Iyer</given-names>
          </string-name>
          , Ioannis Konstas, Alvin Cheung, and
          <string-name>
            <given-names>Luke</given-names>
            <surname>Zettlemoyer</surname>
          </string-name>
          .
          <year>2016</year>
          .
          <article-title>Summarizing source code using a neural attention model</article-title>
          .
          <source>In Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume</source>
          <volume>1</volume>
          :
          <string-name>
            <surname>Long</surname>
            <given-names>Papers).</given-names>
          </string-name>
          <year>2073</year>
          -
          <fpage>2083</fpage>
          .
        </mixed-citation>
      </ref>
      <ref id="ref39">
        <mixed-citation>
          [39]
          <string-name>
            <given-names>Andreas</given-names>
            <surname>Jedlitschka</surname>
          </string-name>
          and
          <string-name>
            <given-names>Markus</given-names>
            <surname>Nick</surname>
          </string-name>
          .
          <year>2003</year>
          . Software Engineering Knowledge Repositories. Springer Berlin Heidelberg, Berlin, Heidelberg,
          <fpage>55</fpage>
          -
          <lpage>80</lpage>
          .
        </mixed-citation>
      </ref>
      <ref id="ref40">
        <mixed-citation>
          [40]
          <string-name>
            <given-names>Eirini</given-names>
            <surname>Kalliamvakou</surname>
          </string-name>
          .
          <year>2022</year>
          . Research:
          <article-title>Quantifying github copilot's impact on developer productivity and happiness</article-title>
          . https://github.blog/2022-09-07- research
          <article-title>-quantifying-github-copilots-impact-on-developer-productivityand-happiness/</article-title>
        </mixed-citation>
      </ref>
      <ref id="ref41">
        <mixed-citation>
          [41]
          <string-name>
            <given-names>Anna</given-names>
            <surname>Kantosalo</surname>
          </string-name>
          et al.
          <year>2019</year>
          .
          <article-title>Human-Computer Co-Creativity: Designing, Evaluating and Modelling Computational Collaborators for Poetry Writing</article-title>
          . (
          <year>2019</year>
          ).
        </mixed-citation>
      </ref>
      <ref id="ref42">
        <mixed-citation>
          [42]
          <string-name>
            <given-names>Sandeep</given-names>
            <surname>Kaur</surname>
          </string-name>
          <string-name>
            <surname>Kuttal</surname>
          </string-name>
          , Bali Ong, Kate Kwasny, and
          <string-name>
            <given-names>Peter</given-names>
            <surname>Robe</surname>
          </string-name>
          .
          <year>2021</year>
          .
          <article-title>TradeOfs for Substituting a Human with an Agent in a Pair Programming Context: The Good, the Bad, and the Ugly</article-title>
          .
          <source>In Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems (Yokohama, Japan) (CHI '21)</source>
          .
          <article-title>Association for Computing Machinery</article-title>
          , New York, NY, USA, Article
          <volume>243</volume>
          , 20 pages.
        </mixed-citation>
      </ref>
      <ref id="ref43">
        <mixed-citation>
          [43]
          <string-name>
            <given-names>Lauramaria</given-names>
            <surname>Laine</surname>
          </string-name>
          .
          <year>2021</year>
          .
          <article-title>Exploring Advertising Creatives' Attitudes Towards Human-AI Collaboration</article-title>
          .
          <article-title>(</article-title>
          <year>2021</year>
          ).
        </mixed-citation>
      </ref>
      <ref id="ref44">
        <mixed-citation>
          [44]
          <string-name>
            <given-names>Yujia</given-names>
            <surname>Li</surname>
          </string-name>
          , David Choi,
          <string-name>
            <given-names>Junyoung</given-names>
            <surname>Chung</surname>
          </string-name>
          , Nate Kushman, Julian Schrittwieser, Rémi Leblond, Tom Eccles, James Keeling, Felix Gimeno, Agustin Dal Lago, and et al.
          <year>2022</year>
          .
          <article-title>Competition-level code generation with AlphaCode</article-title>
          . https: //arxiv.org/abs/2203.07814
        </mixed-citation>
      </ref>
      <ref id="ref45">
        <mixed-citation>
          [45]
          <string-name>
            <given-names>Yaosheng</given-names>
            <surname>Lou</surname>
          </string-name>
          and
          <string-name>
            <given-names>Qi</given-names>
            <surname>Sun</surname>
          </string-name>
          .
          <year>2021</year>
          .
          <article-title>Over-reliance on database: A case study of using web of science</article-title>
          .
          <source>Human Behavior and Emerging Technologies</source>
          <volume>3</volume>
          ,
          <issue>3</issue>
          (
          <year>2021</year>
          ),
          <fpage>454</fpage>
          -
          <lpage>459</lpage>
          .
        </mixed-citation>
      </ref>
      <ref id="ref46">
        <mixed-citation>
          [46]
          <string-name>
            <given-names>David</given-names>
            <surname>Lyell</surname>
          </string-name>
          and
          <string-name>
            <given-names>Enrico</given-names>
            <surname>Coiera</surname>
          </string-name>
          .
          <year>2017</year>
          .
          <article-title>Automation bias and verification complexity: a systematic review</article-title>
          .
          <source>Journal of the American Medical Informatics Association</source>
          <volume>24</volume>
          ,
          <issue>2</issue>
          (
          <year>2017</year>
          ),
          <fpage>423</fpage>
          -
          <lpage>431</lpage>
          .
        </mixed-citation>
      </ref>
      <ref id="ref47">
        <mixed-citation>
          [47]
          <string-name>
            <surname>Wendy</surname>
            <given-names>E</given-names>
          </string-name>
          <string-name>
            <surname>Mackay</surname>
          </string-name>
          and
          <string-name>
            <surname>Anne-Laure Fayard</surname>
          </string-name>
          .
          <year>1997</year>
          .
          <article-title>HCI, natural science and design: a framework for triangulation across disciplines</article-title>
          .
          <source>In Proceedings of the 2nd conference on Designing interactive systems: processes</source>
          , practices, methods, and techniques.
          <volume>223</volume>
          -
          <fpage>234</fpage>
          .
        </mixed-citation>
      </ref>
      <ref id="ref48">
        <mixed-citation>
          [48]
          <string-name>
            <surname>John</surname>
            <given-names>E Mathieu</given-names>
          </string-name>
          , Tonia S Hefner, Gerald F Goodwin,
          <string-name>
            <surname>Eduardo Salas</surname>
          </string-name>
          , and
          <string-name>
            <surname>Janis A Cannon-Bowers</surname>
          </string-name>
          .
          <year>2000</year>
          .
          <article-title>The influence of shared mental models on team process and performance</article-title>
          .
          <source>Journal of applied psychology 85</source>
          ,
          <issue>2</issue>
          (
          <year>2000</year>
          ),
          <fpage>273</fpage>
          .
        </mixed-citation>
      </ref>
      <ref id="ref49">
        <mixed-citation>
          [49]
          <string-name>
            <given-names>Cade</given-names>
            <surname>Metz</surname>
          </string-name>
          .
          <year>2022</year>
          .
          <article-title>Meet GPT-3</article-title>
          . It Has Learned to Code (and
          <source>Blog and Argue)</source>
          .
          <source>(Published</source>
          <year>2020</year>
          ). https://www.nytimes.com/
          <year>2020</year>
          /11/24/science/artificialintelligence-ai-gpt3.html
        </mixed-citation>
      </ref>
      <ref id="ref50">
        <mixed-citation>
          [50]
          <string-name>
            <surname>Robert</surname>
            <given-names>J.</given-names>
          </string-name>
          <string-name>
            <surname>Moore</surname>
            and
            <given-names>Raphael</given-names>
          </string-name>
          <string-name>
            <surname>Arar</surname>
          </string-name>
          .
          <year>2019</year>
          .
          <article-title>Conversational UX Design: A Practitioner's Guide to the Natural Conversation Framework</article-title>
          .
          <article-title>Association for Computing Machinery</article-title>
          , New York, NY, USA.
        </mixed-citation>
      </ref>
      <ref id="ref51">
        <mixed-citation>
          [51]
          <string-name>
            <surname>Ekaterina</surname>
            <given-names>A Moroz</given-names>
          </string-name>
          ,
          <article-title>Vladimir O Grizkevich,</article-title>
          and
          <string-name>
            <surname>Igor M Novozhilov</surname>
          </string-name>
          .
          <year>2022</year>
          .
          <article-title>The Potential of Artificial Intelligence as a Method of Software Developer's Productivity Improvement</article-title>
          .
          <article-title>In 2022 Conference of Russian Young Researchers in Electrical and Electronic Engineering (ElConRus)</article-title>
          . IEEE,
          <fpage>386</fpage>
          -
          <lpage>390</lpage>
          .
        </mixed-citation>
      </ref>
      <ref id="ref52">
        <mixed-citation>
          [52]
          <string-name>
            <given-names>Michael</given-names>
            <surname>Muller</surname>
          </string-name>
          , Stevean Ross, Stephanie Houde, Mayank Agarwal, Fernando Martinez, John Richards, Kartik Talamadupula, and
          <string-name>
            <given-names>Justin D</given-names>
            <surname>Weisz</surname>
          </string-name>
          .
          <year>2022</year>
          .
          <article-title>Drinking Chai with Your (AI) Programming Partner: A Design Fiction about Generative AI for Software Engineering</article-title>
          .
          <source>HAI-GEN Workshop at IUI</source>
          <year>2022</year>
          :
          <article-title>3rd Workshop on Human-AI Co-Creation with Generative Models (</article-title>
          <year>2022</year>
          ). https://haigen.github.io/2022/
        </mixed-citation>
      </ref>
      <ref id="ref53">
        <mixed-citation>
          [53]
          <string-name>
            <surname>Sandra R Murillo</surname>
            and
            <given-names>J Alfredo</given-names>
          </string-name>
          <string-name>
            <surname>Sánchez</surname>
          </string-name>
          .
          <year>2014</year>
          .
          <article-title>Empowering interfaces for system administrators: Keeping the command line in mind when designing GUIs</article-title>
          .
          <source>In Proceedings of the XV International Conference on Human Computer Interaction. 1-4.</source>
        </mixed-citation>
      </ref>
      <ref id="ref54">
        <mixed-citation>
          [54]
          <string-name>
            <surname>Elizabeth</surname>
            <given-names>D</given-names>
          </string-name>
          <string-name>
            <surname>Mynatt</surname>
            and
            <given-names>Gerhard</given-names>
          </string-name>
          <string-name>
            <surname>Weber</surname>
          </string-name>
          .
          <year>1994</year>
          .
          <article-title>Nonvisual presentation of graphical user interfaces: contrasting two approaches</article-title>
          .
          <source>In Proceedings of the SIGCHI conference on Human factors in computing systems</source>
          .
          <volume>166</volume>
          -
          <fpage>172</fpage>
          .
        </mixed-citation>
      </ref>
      <ref id="ref55">
        <mixed-citation>
          [55]
          <string-name>
            <given-names>Alok</given-names>
            <surname>Mysore and Philip J Guo</surname>
          </string-name>
          .
          <year>2017</year>
          .
          <article-title>Torta: Generating mixed-media gui and command-line app tutorials using operating-system-wide activity tracing</article-title>
          .
          <source>In Proceedings of the 30th Annual ACM Symposium on User Interface Software and Technology</source>
          .
          <volume>703</volume>
          -
          <fpage>714</fpage>
          .
        </mixed-citation>
      </ref>
      <ref id="ref56">
        <mixed-citation>
          [56]
          <string-name>
            <given-names>C.</given-names>
            <surname>Nass</surname>
          </string-name>
          and
          <string-name>
            <given-names>Y.</given-names>
            <surname>Moon</surname>
          </string-name>
          .
          <year>2000</year>
          .
          <article-title>Machines and Mindlessness: Social Responses to Computers</article-title>
          .
          <source>Journal of Social Issues</source>
          <volume>56</volume>
          ,
          <issue>1</issue>
          (
          <year>2000</year>
          ),
          <fpage>81</fpage>
          -
          <lpage>103</lpage>
          .
        </mixed-citation>
      </ref>
      <ref id="ref57">
        <mixed-citation>
          [57]
          <string-name>
            <given-names>Nhan</given-names>
            <surname>Nguyen</surname>
          </string-name>
          and
          <string-name>
            <given-names>Sarah</given-names>
            <surname>Nadi</surname>
          </string-name>
          .
          <year>2022</year>
          .
          <article-title>An Empirical Evaluation of GitHub Copilot's Code Suggestions</article-title>
          .
          <source>In 2022 IEEE/ACM 19th International Conference on Mining Software Repositories (MSR)</source>
          .
          <source>IEEE</source>
          , 1-
          <fpage>5</fpage>
          .
        </mixed-citation>
      </ref>
      <ref id="ref58">
        <mixed-citation>
          [58]
          <string-name>
            <given-names>Martin</given-names>
            <surname>Nordio</surname>
          </string-name>
          ,
          <string-name>
            <given-names>H</given-names>
            <surname>Estler</surname>
          </string-name>
          ,
          <article-title>Carlo A Furia</article-title>
          , Bertrand Meyer, et al.
          <year>2011</year>
          .
          <article-title>Collaborative software development on the web</article-title>
          .
          <source>arXiv preprint arXiv:1105.0768</source>
          (
          <year>2011</year>
          ).
        </mixed-citation>
      </ref>
      <ref id="ref59">
        <mixed-citation>
          [59]
          <string-name>
            <surname>Maxwell</surname>
            <given-names>Nye</given-names>
          </string-name>
          , Anders Andreassen, Guy Gur-Ari, Henryk Witold Michalewski, Jacob Austin, David Bieber, David Martin Dohan, Aitor Lewkowycz, Maarten Paul Bosma, David Luan,
          <string-name>
            <given-names>Charles</given-names>
            <surname>Sutton</surname>
          </string-name>
          , and
          <string-name>
            <given-names>Augustus</given-names>
            <surname>Odena</surname>
          </string-name>
          .
          <year>2021</year>
          .
          <article-title>Show Your Work: Scratchpads for Intermediate Computation with Language Models</article-title>
          . https://arxiv.org/abs/2112.00114.
        </mixed-citation>
      </ref>
      <ref id="ref60">
        <mixed-citation>
          [60]
          <string-name>
            <surname>OpenAI</surname>
          </string-name>
          .
          <year>2022</year>
          .
          <article-title>ChatGPT: Optimizing Language Models for Dialogue</article-title>
          .
          <source>OpenAI Blog (30 11</source>
          <year>2022</year>
          ). Retrieved 20-Jan-2023 from https://openai.com/blog/chatgpt/
        </mixed-citation>
      </ref>
      <ref id="ref61">
        <mixed-citation>
          [61]
          <string-name>
            <surname>Long</surname>
            <given-names>Ouyang</given-names>
          </string-name>
          , Jef Wu, Xu Jiang, Diogo Almeida, Carroll L. Wainwright, Pamela Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray, John Schulman, Jacob Hilton, Fraser Kelton,
          <string-name>
            <given-names>Luke</given-names>
            <surname>Miller</surname>
          </string-name>
          , Maddie Simens, Amanda Askell,
          <string-name>
            <given-names>Peter</given-names>
            <surname>Welinder</surname>
          </string-name>
          , Paul Christiano, Jan Leike, and
          <string-name>
            <given-names>Ryan</given-names>
            <surname>Lowe</surname>
          </string-name>
          .
          <year>2022</year>
          .
          <article-title>Training language models to follow instructions with human feedback</article-title>
          . https://arxiv. org/abs/2203.02155
        </mixed-citation>
      </ref>
      <ref id="ref62">
        <mixed-citation>
          [62]
          <string-name>
            <given-names>Peter</given-names>
            <surname>Pirolli</surname>
          </string-name>
          and
          <string-name>
            <given-names>Stuart</given-names>
            <surname>Card</surname>
          </string-name>
          .
          <year>1999</year>
          .
          <article-title>Information foraging</article-title>
          .
          <source>Psychological review 106</source>
          ,
          <issue>4</issue>
          (
          <year>1999</year>
          ),
          <fpage>643</fpage>
          .
        </mixed-citation>
      </ref>
      <ref id="ref63">
        <mixed-citation>
          [63] Larry Press.
          <year>1990</year>
          .
          <article-title>Personal computing: Windows, DOS and the MAC</article-title>
          .
          <source>Commun. ACM</source>
          <volume>33</volume>
          ,
          <issue>11</issue>
          (
          <year>1990</year>
          ),
          <fpage>19</fpage>
          -
          <lpage>26</lpage>
          .
        </mixed-citation>
      </ref>
      <ref id="ref64">
        <mixed-citation>
          [64]
          <string-name>
            <surname>Alec</surname>
            <given-names>Radford</given-names>
          </string-name>
          , Jefrey Wu, Rewon Child, David Luan,
          <string-name>
            <given-names>Dario</given-names>
            <surname>Amodei</surname>
          </string-name>
          ,
          <string-name>
            <given-names>Ilya</given-names>
            <surname>Sutskever</surname>
          </string-name>
          , et al.
          <year>2019</year>
          .
          <article-title>Language Models are Unsupervised Multitask Learners</article-title>
          .
        </mixed-citation>
      </ref>
      <ref id="ref65">
        <mixed-citation>
          [65]
          <string-name>
            <surname>Alvin</surname>
            <given-names>Rajkomar</given-names>
          </string-name>
          ,
          <string-name>
            <given-names>Jefrey</given-names>
            <surname>Dean</surname>
          </string-name>
          ,
          <string-name>
            <given-names>and Isaac</given-names>
            <surname>Kohane</surname>
          </string-name>
          .
          <year>2019</year>
          .
          <article-title>Machine learning in medicine</article-title>
          .
          <source>New England Journal of Medicine</source>
          <volume>380</volume>
          ,
          <issue>14</issue>
          (
          <year>2019</year>
          ),
          <fpage>1347</fpage>
          -
          <lpage>1358</lpage>
          .
        </mixed-citation>
      </ref>
      <ref id="ref66">
        <mixed-citation>
          [66]
          <string-name>
            <surname>Aditya</surname>
            <given-names>Ramesh</given-names>
          </string-name>
          , Prafulla Dhariwal, Alex Nichol, Casey Chu, and
          <string-name>
            <given-names>Mark</given-names>
            <surname>Chen</surname>
          </string-name>
          .
          <year>2022</year>
          .
          <article-title>Hierarchical text-conditional image generation with clip latents</article-title>
          .
          <source>arXiv preprint arXiv:2204.06125</source>
          (
          <year>2022</year>
          ).
        </mixed-citation>
      </ref>
      <ref id="ref67">
        <mixed-citation>
          [67]
          <string-name>
            <given-names>B.</given-names>
            <surname>Reeves</surname>
          </string-name>
          and
          <string-name>
            <given-names>C.I.</given-names>
            <surname>Nass</surname>
          </string-name>
          .
          <year>1996</year>
          .
          <article-title>The Media Equation: How People Treat Computers, Television, and New Media Like Real People and Places</article-title>
          . CSLI Publications.
        </mixed-citation>
      </ref>
      <ref id="ref68">
        <mixed-citation>
          [68]
          <string-name>
            <given-names>Mawarny</given-names>
            <surname>Md</surname>
          </string-name>
          <string-name>
            <surname>Rejab</surname>
          </string-name>
          , James Noble, and
          <string-name>
            <given-names>George</given-names>
            <surname>Allan</surname>
          </string-name>
          .
          <year>2014</year>
          .
          <article-title>Distributing Expertise in Agile Software Development Projects</article-title>
          .
          <source>In 2014 Agile Conference</source>
          .
          <volume>33</volume>
          -
          <fpage>36</fpage>
          .
        </mixed-citation>
      </ref>
      <ref id="ref69">
        <mixed-citation>
          [69]
          <string-name>
            <given-names>Jeba</given-names>
            <surname>Rezwana</surname>
          </string-name>
          and Mary Lou Maher.
          <year>2021</year>
          .
          <article-title>COFI: A Framework for Modeling Interaction in Human-AI Co-Creative Systems.</article-title>
          . In ICCC.
          <fpage>444</fpage>
          -
          <lpage>448</lpage>
          .
        </mixed-citation>
      </ref>
      <ref id="ref70">
        <mixed-citation>
          [70]
          <string-name>
            <surname>Charles</surname>
            <given-names>H.</given-names>
          </string-name>
          <string-name>
            <surname>Rich</surname>
          </string-name>
          and Richard C. Waters.
          <year>1990</year>
          .
          <article-title>The Programmer's Apprentice</article-title>
          . Addison-Wesley Publishing Company, Reading, MA.
        </mixed-citation>
      </ref>
      <ref id="ref71">
        <mixed-citation>
          [71]
          <string-name>
            <given-names>Peter</given-names>
            <surname>Robe</surname>
          </string-name>
          and Sandeep Kaur Kuttal.
          <year>2022</year>
          .
          <article-title>Designing PairBuddy-A Conversational Agent for Pair Programming</article-title>
          .
          <source>ACM Transactions on Computer-Human Interaction (TOCHI) 29</source>
          ,
          <issue>4</issue>
          (
          <year>2022</year>
          ),
          <fpage>1</fpage>
          -
          <lpage>44</lpage>
          .
        </mixed-citation>
      </ref>
      <ref id="ref72">
        <mixed-citation>
          [72]
          <string-name>
            <surname>Robin</surname>
            <given-names>Rombach</given-names>
          </string-name>
          , Andreas Blattmann, Dominik Lorenz, Patrick Esser, and
          <string-name>
            <given-names>Björn</given-names>
            <surname>Ommer</surname>
          </string-name>
          .
          <year>2022</year>
          .
          <article-title>High-resolution image synthesis with latent difusion models</article-title>
          .
          <source>In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</source>
          .
          <fpage>10684</fpage>
          -
          <lpage>10695</lpage>
          .
        </mixed-citation>
      </ref>
      <ref id="ref73">
        <mixed-citation>
          [73]
          <string-name>
            <surname>Steven</surname>
            <given-names>Ross</given-names>
          </string-name>
          , Elizabeth Brownholtz, and
          <string-name>
            <given-names>Robert</given-names>
            <surname>Armes</surname>
          </string-name>
          .
          <year>2004</year>
          .
          <article-title>A MultipleApplication Conversational Agent</article-title>
          .
          <source>In Proceedings of the 9th International Conference on Intelligent User Interfaces (Funchal</source>
          , Madeira, Portugal) (
          <source>IUI '04)</source>
          .
          <article-title>Association for Computing Machinery</article-title>
          , New York, NY, USA,
          <fpage>319</fpage>
          -
          <lpage>321</lpage>
          .
        </mixed-citation>
      </ref>
      <ref id="ref74">
        <mixed-citation>
          [74]
          <string-name>
            <surname>Steven</surname>
            <given-names>Ross</given-names>
          </string-name>
          , Elizabeth Brownholtz, and
          <string-name>
            <given-names>Robert</given-names>
            <surname>Armes</surname>
          </string-name>
          .
          <year>2004</year>
          .
          <article-title>Voice User Interface Principles for a Conversational Agent</article-title>
          .
          <source>In Proceedings of the 9th International Conference on Intelligent User Interfaces (Funchal</source>
          , Madeira, Portugal) (
          <source>IUI '04)</source>
          .
          <article-title>Association for Computing Machinery</article-title>
          , New York, NY, USA,
          <fpage>364</fpage>
          -
          <lpage>365</lpage>
          .
        </mixed-citation>
      </ref>
      <ref id="ref75">
        <mixed-citation>
          [75]
          <string-name>
            <surname>Baptiste</surname>
            <given-names>Roziere</given-names>
          </string-name>
          ,
          <string-name>
            <surname>Marie-Anne</surname>
            <given-names>Lachaux</given-names>
          </string-name>
          , Lowik Chanussot, and
          <string-name>
            <given-names>Guillaume</given-names>
            <surname>Lample</surname>
          </string-name>
          .
          <year>2020</year>
          .
          <article-title>Unsupervised Translation of Programming Languages</article-title>
          .
          <source>In Advances in Neural Information Processing Systems</source>
          , H. Larochelle,
          <string-name>
            <given-names>M.</given-names>
            <surname>Ranzato</surname>
          </string-name>
          ,
          <string-name>
            <given-names>R.</given-names>
            <surname>Hadsell</surname>
          </string-name>
          ,
          <string-name>
            <given-names>M.F.</given-names>
            <surname>Balcan</surname>
          </string-name>
          , and H.
          <source>Lin (Eds.)</source>
          , Vol.
          <volume>33</volume>
          . Curran Associates, Inc.,
          <fpage>20601</fpage>
          -
          <lpage>20611</lpage>
          .
        </mixed-citation>
      </ref>
      <ref id="ref76">
        <mixed-citation>
          [76]
          <string-name>
            <given-names>Harvey</given-names>
            <surname>Sacks</surname>
          </string-name>
          .
          <year>1984</year>
          .
          <article-title>Notes on methodology</article-title>
          .
          <source>In Structures of Social Action: Studies in Conversation Analysis</source>
          ,
          <source>John Heritage and J. Maxwell Atkinson (Eds.)</source>
          . Cambridge University Press, Cambridge,
          <fpage>2</fpage>
          -
          <lpage>27</lpage>
          .
        </mixed-citation>
      </ref>
      <ref id="ref77">
        <mixed-citation>
          [77]
          <string-name>
            <given-names>Nithya</given-names>
            <surname>Sambasivan</surname>
          </string-name>
          and
          <string-name>
            <given-names>Rajesh</given-names>
            <surname>Veeraraghavan</surname>
          </string-name>
          .
          <year>2022</year>
          .
          <article-title>The Deskilling of Domain Expertise in AI Development</article-title>
          .
          <source>In CHI Conference on Human Factors in Computing Systems</source>
          .
          <volume>1</volume>
          -
          <fpage>14</fpage>
          .
        </mixed-citation>
      </ref>
      <ref id="ref78">
        <mixed-citation>
          [78]
          <string-name>
            <surname>Harini</surname>
            <given-names>Sampath</given-names>
          </string-name>
          , Alice Merrick, and
          <string-name>
            <given-names>Andrew</given-names>
            <surname>Macvean</surname>
          </string-name>
          .
          <year>2021</year>
          .
          <article-title>Accessibility of command line interfaces</article-title>
          .
          <source>In Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems</source>
          .
          <volume>1</volume>
          -
          <fpage>10</fpage>
          .
        </mixed-citation>
      </ref>
      <ref id="ref79">
        <mixed-citation>
          [79]
          <string-name>
            <given-names>Matthias</given-names>
            <surname>Scheutz</surname>
          </string-name>
          ,
          <article-title>Scott A DeLoach,</article-title>
          and Julie A Adams.
          <year>2017</year>
          .
          <article-title>A framework for developing and using shared mental models in human-agent teams</article-title>
          .
          <source>Journal of Cognitive Engineering and Decision Making</source>
          <volume>11</volume>
          ,
          <issue>3</issue>
          (
          <year>2017</year>
          ),
          <fpage>203</fpage>
          -
          <lpage>224</lpage>
          .
        </mixed-citation>
      </ref>
      <ref id="ref80">
        <mixed-citation>
          [80]
          <string-name>
            <surname>Isabella</surname>
            <given-names>Seeber</given-names>
          </string-name>
          , Eva Bittner, Robert O Briggs, Triparna De Vreede,
          <string-name>
            <surname>Gert-Jan De</surname>
            <given-names>Vreede</given-names>
          </string-name>
          , Aaron Elkins, Ronald Maier, Alexander B Merz,
          <string-name>
            <surname>Sarah</surname>
            Oeste-Reiß,
            <given-names>Nils</given-names>
          </string-name>
          <string-name>
            <surname>Randrup</surname>
          </string-name>
          , et al.
          <year>2020</year>
          .
          <article-title>Machines as teammates: A research agenda on AI in team collaboration</article-title>
          .
          <source>Information &amp; management 57</source>
          ,
          <issue>2</issue>
          (
          <year>2020</year>
          ),
          <fpage>103174</fpage>
          .
        </mixed-citation>
      </ref>
      <ref id="ref81">
        <mixed-citation>
          [81]
          <string-name>
            <surname>Shilad</surname>
            <given-names>Sen</given-names>
          </string-name>
          , Werner Geyer, Michael Muller, Marty Moore, Beth Brownholtz, Eric Wilcox, and David R Millen.
          <year>2006</year>
          .
          <article-title>FeedMe: a collaborative alert filtering system</article-title>
          .
          <source>In Proceedings of the 2006 20th anniversary conference on Computer supported cooperative work</source>
          .
          <volume>89</volume>
          -
          <fpage>98</fpage>
          .
        </mixed-citation>
      </ref>
      <ref id="ref82">
        <mixed-citation>
          [82]
          <string-name>
            <given-names>Ben</given-names>
            <surname>Shneiderman</surname>
          </string-name>
          .
          <year>2020</year>
          .
          <article-title>Human-centered artificial intelligence: Three fresh ideas</article-title>
          .
          <source>AIS Transactions on Human-Computer Interaction 12</source>
          ,
          <issue>3</issue>
          (
          <year>2020</year>
          ),
          <fpage>109</fpage>
          -
          <lpage>124</lpage>
          .
        </mixed-citation>
      </ref>
      <ref id="ref83">
        <mixed-citation>
          [83]
          <string-name>
            <given-names>Ben</given-names>
            <surname>Shneiderman</surname>
          </string-name>
          .
          <year>2022</year>
          .
          <article-title>Human-Centered AI</article-title>
          . Oxford University Press.
        </mixed-citation>
      </ref>
      <ref id="ref84">
        <mixed-citation>
          [84]
          <string-name>
            <surname>Kurt</surname>
            <given-names>Shuster</given-names>
          </string-name>
          , Jing Xu, Mojtaba Komeili, Da Ju, Eric Michael Smith,
          <string-name>
            <given-names>Stephen</given-names>
            <surname>Roller</surname>
          </string-name>
          , Megan Ung, Moya Chen, Kushal Arora,
          <string-name>
            <given-names>Joshua</given-names>
            <surname>Lane</surname>
          </string-name>
          , et al.
          <year>2022</year>
          .
          <article-title>BlenderBot 3: a deployed conversational agent that continually learns to responsibly engage</article-title>
          .
          <source>arXiv preprint arXiv:2208.03188</source>
          (
          <year>2022</year>
          ).
        </mixed-citation>
      </ref>
      <ref id="ref85">
        <mixed-citation>
          [85]
          <string-name>
            <given-names>Michael</given-names>
            <surname>Skirpan</surname>
          </string-name>
          and
          <string-name>
            <given-names>Casey</given-names>
            <surname>Fiesler</surname>
          </string-name>
          .
          <year>2018</year>
          .
          <article-title>Ad empathy: A design fiction</article-title>
          .
          <source>In Proceedings of the 2018 ACM Conference on Supporting Groupwork</source>
          .
          <fpage>267</fpage>
          -
          <lpage>273</lpage>
          .
        </mixed-citation>
      </ref>
      <ref id="ref86">
        <mixed-citation>
          [86]
          <string-name>
            <given-names>Diomidis</given-names>
            <surname>Spinellis</surname>
          </string-name>
          .
          <year>2012</year>
          .
          <article-title>Git</article-title>
          .
          <source>IEEE Software 29</source>
          ,
          <issue>3</issue>
          (
          <year>2012</year>
          ),
          <fpage>100</fpage>
          -
          <lpage>101</lpage>
          . https: //doi.org/10.1109/MS.
          <year>2012</year>
          .61
        </mixed-citation>
      </ref>
      <ref id="ref87">
        <mixed-citation>
          [87]
          <string-name>
            <given-names>Angie</given-names>
            <surname>Spoto</surname>
          </string-name>
          and
          <string-name>
            <given-names>Natalia</given-names>
            <surname>Oleynik</surname>
          </string-name>
          .
          <year>2017</year>
          .
          <article-title>Library of Mixed-Initiative Creative Interfaces</article-title>
          . Retrieved 19-Jun-2021 from http://mici.codingconduct.cc/
        </mixed-citation>
      </ref>
      <ref id="ref88">
        <mixed-citation>
          [88]
          <string-name>
            <surname>Ayushi</surname>
            <given-names>Srivastava</given-names>
          </string-name>
          , Shivani Kapania, Anupriya Tuli, and
          <string-name>
            <given-names>Pushpendra</given-names>
            <surname>Singh</surname>
          </string-name>
          .
          <year>2021</year>
          .
          <article-title>Actionable UI Design Guidelines for Smartphone Applications Inclusive of Low-Literate Users</article-title>
          .
          <source>Proceedings of the ACM on Human-Computer Interaction 5</source>
          ,
          <issue>CSCW1</issue>
          (
          <year>2021</year>
          ),
          <fpage>1</fpage>
          -
          <lpage>30</lpage>
          .
        </mixed-citation>
      </ref>
      <ref id="ref89">
        <mixed-citation>
          [89]
          <string-name>
            <surname>Margaret-Anne Storey</surname>
            and
            <given-names>Alexey</given-names>
          </string-name>
          <string-name>
            <surname>Zagalsky</surname>
          </string-name>
          .
          <year>2016</year>
          .
          <article-title>Disrupting developer productivity one bot at a time</article-title>
          .
          <source>In Proceedings of the 2016 24th ACM SIGSOFT international symposium on foundations of software engineering</source>
          . 928-
          <fpage>931</fpage>
          .
        </mixed-citation>
      </ref>
      <ref id="ref90">
        <mixed-citation>
          [90]
          <string-name>
            <given-names>Kartik</given-names>
            <surname>Talamadupula</surname>
          </string-name>
          .
          <year>2021</year>
          .
          <article-title>Applied AI matters: AI4Code: applying artificial intelligence to source code</article-title>
          .
          <source>AI Matters 7</source>
          ,
          <issue>1</issue>
          (
          <year>2021</year>
          ),
          <fpage>18</fpage>
          -
          <lpage>20</lpage>
          .
        </mixed-citation>
      </ref>
      <ref id="ref91">
        <mixed-citation>
          [91]
          <string-name>
            <surname>Romal</surname>
            <given-names>Thoppilan</given-names>
          </string-name>
          , Daniel De Freitas, Jamie Hall, Noam Shazeer, Apoorv Kulshreshtha, Heng-Tze Cheng, Alicia Jin, Taylor Bos, Leslie Baker,
          <string-name>
            <given-names>Yu</given-names>
            <surname>Du</surname>
          </string-name>
          , and et al.
          <year>2022</year>
          .
          <article-title>LAMDA: Language models for dialog applications</article-title>
          . https: //arxiv.org/abs/2201.08239
        </mixed-citation>
      </ref>
      <ref id="ref92">
        <mixed-citation>
          [92]
          <string-name>
            <surname>Michele</surname>
            <given-names>Tufano</given-names>
          </string-name>
          , Dawn Drain, Alexey Svyatkovskiy, Shao Kun Deng, and
          <string-name>
            <given-names>Neel</given-names>
            <surname>Sundaresan</surname>
          </string-name>
          .
          <year>2020</year>
          .
          <article-title>Unit Test Case Generation with Transformers and Focal Context</article-title>
          . arXiv preprint arXiv:
          <year>2009</year>
          .
          <volume>05617</volume>
          (
          <year>2020</year>
          ).
        </mixed-citation>
      </ref>
      <ref id="ref93">
        <mixed-citation>
          [93]
          <string-name>
            <surname>Severi</surname>
            <given-names>Uusitalo</given-names>
          </string-name>
          , Anna Kantosalo, Antti Salovaara, Tapio Takala, and
          <string-name>
            <given-names>Christian</given-names>
            <surname>Guckelsberger</surname>
          </string-name>
          .
          <year>2022</year>
          .
          <article-title>Co-creative Product Design with Interactive Evolutionary Algorithms: A Practice-Based Reflection</article-title>
          . In International Conference on Computational Intelligence in Music, Sound,
          <source>Art and Design (Part of EvoStar)</source>
          . Springer,
          <fpage>292</fpage>
          -
          <lpage>307</lpage>
          .
        </mixed-citation>
      </ref>
      <ref id="ref94">
        <mixed-citation>
          [94]
          <string-name>
            <given-names>Priyan</given-names>
            <surname>Vaithilingam and Philip J Guo</surname>
          </string-name>
          .
          <year>2019</year>
          .
          <article-title>Bespoke: Interactively synthesizing custom GUIs from command-line applications by demonstration</article-title>
          .
          <source>In Proceedings of the 32nd annual ACM symposium on user interface software and technology. 563-576.</source>
        </mixed-citation>
      </ref>
      <ref id="ref95">
        <mixed-citation>
          [95]
          <string-name>
            <surname>Priyan</surname>
            <given-names>Vaithilingam</given-names>
          </string-name>
          , Tianyi Zhang, and Elena L.
          <string-name>
            <surname>Glassman</surname>
          </string-name>
          .
          <year>2022</year>
          .
          <article-title>Expectation vs. Experience: Evaluating the Usability of Code Generation Tools Powered by Large Language Models</article-title>
          .
          <source>In Extended Abstracts of the 2022 CHI Conference on Human Factors in Computing Systems (New Orleans</source>
          , LA, USA) (
          <source>CHI EA '22)</source>
          .
          <article-title>Association for Computing Machinery</article-title>
          , New York, NY, USA, Article
          <volume>332</volume>
          , 7 pages. https://doi.org/10.1145/3491101.3519665
        </mixed-citation>
      </ref>
      <ref id="ref96">
        <mixed-citation>
          [96]
          <string-name>
            <surname>Ashish</surname>
            <given-names>Vaswani</given-names>
          </string-name>
          , Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez,
          <article-title>Ł ukasz Kaiser, and</article-title>
          <string-name>
            <given-names>Illia</given-names>
            <surname>Polosukhin</surname>
          </string-name>
          .
          <year>2017</year>
          .
          <article-title>Attention is All you Need</article-title>
          .
          <source>In Advances in Neural Information Processing Systems</source>
          , I. Guyon,
          <string-name>
            <given-names>U.</given-names>
            <surname>Von Luxburg</surname>
          </string-name>
          ,
          <string-name>
            <given-names>S.</given-names>
            <surname>Bengio</surname>
          </string-name>
          ,
          <string-name>
            <given-names>H.</given-names>
            <surname>Wallach</surname>
          </string-name>
          ,
          <string-name>
            <given-names>R.</given-names>
            <surname>Fergus</surname>
          </string-name>
          ,
          <string-name>
            <given-names>S.</given-names>
            <surname>Vishwanathan</surname>
          </string-name>
          , and R.
          <source>Garnett (Eds.)</source>
          , Vol.
          <volume>30</volume>
          . Curran Associates, Inc. https://proceedings.neurips.cc/paper/ 2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf
        </mixed-citation>
      </ref>
      <ref id="ref97">
        <mixed-citation>
          [97]
          <string-name>
            <surname>Yao</surname>
            <given-names>Wan</given-names>
          </string-name>
          ,
          <string-name>
            <given-names>Zhou</given-names>
            <surname>Zhao</surname>
          </string-name>
          ,
          <string-name>
            <given-names>Min</given-names>
            <surname>Yang</surname>
          </string-name>
          , Guandong Xu, Haochao Ying,
          <string-name>
            <surname>Jian Wu</surname>
          </string-name>
          , and
          <string-name>
            <surname>Philip S Yu</surname>
          </string-name>
          .
          <year>2018</year>
          .
          <article-title>Improving automatic source code summarization via deep reinforcement learning</article-title>
          .
          <source>In Proceedings of the 33rd ACM/IEEE international conference on automated software engineering</source>
          . 397-
          <fpage>407</fpage>
          .
        </mixed-citation>
      </ref>
      <ref id="ref98">
        <mixed-citation>
          [98]
          <string-name>
            <given-names>April</given-names>
            <surname>Yi</surname>
          </string-name>
          <string-name>
            <given-names>Wang</given-names>
            ,
            <surname>Dakuo</surname>
          </string-name>
          <string-name>
            <given-names>Wang</given-names>
            ,
            <surname>Jaimie Drozdal</surname>
          </string-name>
          , Michael Muller, Soya Park,
          <string-name>
            <surname>Justin D Weisz</surname>
          </string-name>
          , Xuye Liu,
          <string-name>
            <surname>Lingfei Wu</surname>
            , and
            <given-names>Casey</given-names>
          </string-name>
          <string-name>
            <surname>Dugan</surname>
          </string-name>
          .
          <year>2022</year>
          .
          <article-title>Documentation Matters: Human-Centered AI System to Assist Data Science Code Documentation in Computational Notebooks</article-title>
          .
          <source>ACM Transactions on Computer-Human Interaction 29</source>
          ,
          <issue>2</issue>
          (
          <year>2022</year>
          ),
          <fpage>1</fpage>
          -
          <lpage>33</lpage>
          .
        </mixed-citation>
      </ref>
      <ref id="ref99">
        <mixed-citation>
          [99]
          <string-name>
            <surname>Dakuo</surname>
            <given-names>Wang</given-names>
          </string-name>
          ,
          <string-name>
            <surname>Justin D Weisz</surname>
            ,
            <given-names>Michael</given-names>
          </string-name>
          <string-name>
            <surname>Muller</surname>
            , Parikshit Ram, Werner Geyer, Casey Dugan, Yla Tausczik, Horst Samulowitz, and
            <given-names>Alexander</given-names>
          </string-name>
          <string-name>
            <surname>Gray</surname>
          </string-name>
          .
          <year>2019</year>
          .
          <article-title>Human-AI collaboration in data science: Exploring data scientists' perceptions of automated AI</article-title>
          .
          <article-title>Proceedings of the ACM on Human-Computer Interaction 3</article-title>
          ,
          <string-name>
            <surname>CSCW</surname>
          </string-name>
          (
          <year>2019</year>
          ),
          <fpage>1</fpage>
          -
          <lpage>24</lpage>
          .
        </mixed-citation>
      </ref>
      <ref id="ref100">
        <mixed-citation>
          [100]
          <string-name>
            <surname>Qiaosi</surname>
            <given-names>Wang</given-names>
          </string-name>
          , Koustuv Saha, Eric Gregori, David Joyner,
          <string-name>
            <given-names>and Ashok</given-names>
            <surname>Goel</surname>
          </string-name>
          .
          <year>2021</year>
          .
          <article-title>Towards mutual theory of mind in human-ai interaction: How language reflects what students perceive about a virtual teaching assistant</article-title>
          .
          <source>In Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems</source>
          .
          <volume>1</volume>
          -
          <fpage>14</fpage>
          .
        </mixed-citation>
      </ref>
      <ref id="ref101">
        <mixed-citation>
          [101]
          <string-name>
            <given-names>Jeremy</given-names>
            <surname>Warner and Philip J Guo</surname>
          </string-name>
          .
          <year>2017</year>
          .
          <article-title>Codepilot: Scafolding end-to-end collaborative software development for novice programmers</article-title>
          .
          <source>In Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems</source>
          .
          <volume>1136</volume>
          -
          <fpage>1141</fpage>
          .
        </mixed-citation>
      </ref>
      <ref id="ref102">
        <mixed-citation>
          [102]
          <string-name>
            <surname>Justin</surname>
            <given-names>D</given-names>
          </string-name>
          <string-name>
            <surname>Weisz</surname>
            ,
            <given-names>Michael</given-names>
          </string-name>
          <string-name>
            <surname>Muller</surname>
            , Stephanie Houde, John Richards, Steven I Ross, Fernando Martinez, Mayank Agarwal, and
            <given-names>Kartik</given-names>
          </string-name>
          <string-name>
            <surname>Talamadupula</surname>
          </string-name>
          .
          <year>2021</year>
          .
          <article-title>Perfection Not Required? Human-AI Partnerships in Code Translation</article-title>
          .
          <source>In 26th International Conference on Intelligent User Interfaces</source>
          .
          <fpage>402</fpage>
          -
          <lpage>412</lpage>
          .
        </mixed-citation>
      </ref>
      <ref id="ref103">
        <mixed-citation>
          [103]
          <string-name>
            <surname>Justin</surname>
            <given-names>D</given-names>
          </string-name>
          <string-name>
            <surname>Weisz</surname>
            ,
            <given-names>Michael</given-names>
          </string-name>
          <string-name>
            <surname>Muller</surname>
            ,
            <given-names>Steven I Ross</given-names>
          </string-name>
          , Fernando Martinez, Stephanie Houde, Mayank Agarwal, Kartik Talamadupula, and John T Richards.
          <year>2022</year>
          .
          <article-title>Better together? an evaluation of ai-supported code translation</article-title>
          .
          <source>In 27th International Conference on Intelligent User Interfaces</source>
          .
          <fpage>369</fpage>
          -
          <lpage>391</lpage>
          .
        </mixed-citation>
      </ref>
      <ref id="ref104">
        <mixed-citation>
          [104]
          <string-name>
            <given-names>Joseph</given-names>
            <surname>Weizenbaum</surname>
          </string-name>
          .
          <year>1966</year>
          .
          <article-title>ELIZA - a computer program for the study of natural language communication between man and machine</article-title>
          .
          <source>Commun. ACM</source>
          <volume>9</volume>
          (
          <year>1966</year>
          ),
          <fpage>36</fpage>
          -
          <lpage>45</lpage>
          .
        </mixed-citation>
      </ref>
      <ref id="ref105">
        <mixed-citation>
          [105]
          <string-name>
            <surname>Frank</surname>
            <given-names>F Xu</given-names>
          </string-name>
          ,
          <string-name>
            <given-names>Bogdan</given-names>
            <surname>Vasilescu</surname>
          </string-name>
          , and
          <string-name>
            <given-names>Graham</given-names>
            <surname>Neubig</surname>
          </string-name>
          .
          <year>2022</year>
          .
          <article-title>In-ide code generation from natural language: Promise and challenges</article-title>
          .
          <source>ACM Transactions on Software Engineering and Methodology (TOSEM) 31</source>
          ,
          <issue>2</issue>
          (
          <year>2022</year>
          ),
          <fpage>1</fpage>
          -
          <lpage>47</lpage>
          .
        </mixed-citation>
      </ref>
      <ref id="ref106">
        <mixed-citation>
          [106]
          <string-name>
            <given-names>Aditya</given-names>
            <surname>Ankur</surname>
          </string-name>
          <string-name>
            <surname>Yadav</surname>
          </string-name>
          ,
          <article-title>Ishan Garg, and</article-title>
          <string-name>
            <given-names>Dr. Pratistha</given-names>
            <surname>Mathur</surname>
          </string-name>
          .
          <year>2019</year>
          .
          <article-title>PACT - Programming Assistant ChaTbot</article-title>
          .
          <source>In 2019 2nd International Conference on Intelligent Communication and Computational Techniques (ICCT)</source>
          .
          <volume>131</volume>
          -
          <fpage>136</fpage>
          .
        </mixed-citation>
      </ref>
      <ref id="ref107">
        <mixed-citation>
          [107]
          <string-name>
            <surname>Munazza</surname>
            <given-names>Zaib</given-names>
          </string-name>
          , Quan
          <string-name>
            <given-names>Z.</given-names>
            <surname>Sheng</surname>
          </string-name>
          , and
          <string-name>
            <given-names>W.</given-names>
            <surname>Zhang</surname>
          </string-name>
          .
          <year>2020</year>
          .
          <article-title>A Short Survey of Pretrained Language Models for Conversational AI-A New Age in NLP</article-title>
          .
          <source>Proceedings of the Australasian Computer Science Week Multiconference</source>
          (
          <year>2020</year>
          ).
        </mixed-citation>
      </ref>
      <ref id="ref108">
        <mixed-citation>
          [108]
          <string-name>
            <surname>Elaine</surname>
            <given-names>Zibrowski</given-names>
          </string-name>
          , Lisa Shepherd, Kamran Sedig, Richard Booth,
          <string-name>
            <given-names>Candace</given-names>
            <surname>Gibson</surname>
          </string-name>
          , et al.
          <year>2018</year>
          .
          <article-title>Easier and faster is not always better: grounded theory of the impact of large-scale system transformation on the clinical work of emergency medicine nurses and physicians</article-title>
          .
          <source>JMIR Human Factors</source>
          <volume>5</volume>
          ,
          <issue>4</issue>
          (
          <year>2018</year>
          ),
          <year>e11013</year>
          .
        </mixed-citation>
      </ref>
      <ref id="ref109">
        <mixed-citation>
          [109]
          <string-name>
            <surname>Albert</surname>
            <given-names>Ziegler</given-names>
          </string-name>
          ,
          <string-name>
            <given-names>Eirini</given-names>
            <surname>Kalliamvakou</surname>
          </string-name>
          ,
          <string-name>
            <given-names>X. Alice</given-names>
            <surname>Li</surname>
          </string-name>
          ,
          <string-name>
            <surname>Andrew Rice</surname>
          </string-name>
          , Devon Rifkin, Shawn Simister, Ganesh Sittampalam, and
          <string-name>
            <given-names>Edward</given-names>
            <surname>Aftandilian</surname>
          </string-name>
          .
          <year>2022</year>
          .
          <article-title>Productivity Assessment of Neural Code Completion</article-title>
          .
          <source>In Proceedings of the 6th ACM SIGPLAN International Symposium on Machine Programming</source>
          (San Diego, CA, USA) (
          <year>MAPS 2022</year>
          ).
          <article-title>Association for Computing Machinery</article-title>
          , New York, NY, USA,
          <fpage>21</fpage>
          -
          <lpage>29</lpage>
          . https://doi.org/10.1145/3520312.3534864
          <string-name>
            <given-names>P</given-names>
            <surname>Gender Role Fam</surname>
          </string-name>
          . Rec.
        </mixed-citation>
      </ref>
      <ref id="ref110">
        <mixed-citation>
          1
          <string-name>
            <given-names>M</given-names>
            <surname>Marketer</surname>
          </string-name>
          <string-name>
            <surname>NF</surname>
          </string-name>
          &gt;
          <volume>5</volume>
          <fpage>Yr</fpage>
        </mixed-citation>
      </ref>
      <ref id="ref111">
        <mixed-citation>
          2
          <string-name>
            <given-names>M</given-names>
            <surname>Researcher</surname>
          </string-name>
          <article-title>/ Scientist 3+ Mo</article-title>
        </mixed-citation>
      </ref>
      <ref id="ref112">
        <mixed-citation>
          3
          <string-name>
            <given-names>M</given-names>
            <surname>Software</surname>
          </string-name>
          <article-title>Engineer 1-3 Mo</article-title>
        </mixed-citation>
      </ref>
      <ref id="ref113">
        <mixed-citation>
          4
          <string-name>
            <given-names>M</given-names>
            <surname>Researcher</surname>
          </string-name>
          <article-title>/ Scientist 3+ Mo</article-title>
        </mixed-citation>
      </ref>
      <ref id="ref114">
        <mixed-citation>
          5
          <string-name>
            <given-names>M</given-names>
            <surname>Researcher</surname>
          </string-name>
          <article-title>/ Scientist 3+ Mo</article-title>
        </mixed-citation>
      </ref>
      <ref id="ref115">
        <mixed-citation>
          6
          <string-name>
            <given-names>F Software</given-names>
            <surname>Engineer</surname>
          </string-name>
          &lt;
          <volume>1</volume>
          <fpage>Yr</fpage>
        </mixed-citation>
      </ref>
      <ref id="ref116">
        <mixed-citation>
          7
          <string-name>
            <given-names>F Software</given-names>
            <surname>Engineer</surname>
          </string-name>
          &lt;
          <volume>1</volume>
          <fpage>Mo</fpage>
        </mixed-citation>
      </ref>
      <ref id="ref117">
        <mixed-citation>
          8
          <string-name>
            <given-names>F Software</given-names>
            <surname>Engineer</surname>
          </string-name>
          1-3 Mo
        </mixed-citation>
      </ref>
      <ref id="ref118">
        <mixed-citation>
          9
          <string-name>
            <given-names>F Software</given-names>
            <surname>Engineer</surname>
          </string-name>
          <article-title>3+ Mo</article-title>
        </mixed-citation>
      </ref>
      <ref id="ref119">
        <mixed-citation>
          <source>10 GV/NC Business Analyst 1-3 Mo</source>
        </mixed-citation>
      </ref>
      <ref id="ref120">
        <mixed-citation>
          11
          <string-name>
            <given-names>F Software</given-names>
            <surname>Engineer</surname>
          </string-name>
          1-3 Mo
        </mixed-citation>
      </ref>
      <ref id="ref121">
        <mixed-citation>
          12
          <string-name>
            <given-names>M</given-names>
            <surname>Researcher</surname>
          </string-name>
          <article-title>/ Scientist 3+ Mo</article-title>
        </mixed-citation>
      </ref>
      <ref id="ref122">
        <mixed-citation>
          13
          <string-name>
            <given-names>F</given-names>
            <surname>Manager</surname>
          </string-name>
          &lt;
          <volume>1</volume>
          <fpage>Mo</fpage>
        </mixed-citation>
      </ref>
      <ref id="ref123">
        <mixed-citation>
          14
          <string-name>
            <given-names>F</given-names>
            <surname>Software</surname>
          </string-name>
          <article-title>Engineer &lt; 1 &gt;5 Yr</article-title>
        </mixed-citation>
      </ref>
      <ref id="ref124">
        <mixed-citation>
          15
          <string-name>
            <given-names>F</given-names>
            <surname>Researcher</surname>
          </string-name>
          / Scientist 3+ Mo
        </mixed-citation>
      </ref>
      <ref id="ref125">
        <mixed-citation>
          16
          <string-name>
            <given-names>M</given-names>
            <surname>Researcher</surname>
          </string-name>
          <article-title>/ Scientist 3+ Mo</article-title>
        </mixed-citation>
      </ref>
      <ref id="ref126">
        <mixed-citation>
          17
          <string-name>
            <given-names>F</given-names>
            <surname>Software</surname>
          </string-name>
          <article-title>Engineer &lt; 1 Yr</article-title>
        </mixed-citation>
      </ref>
      <ref id="ref127">
        <mixed-citation>
          18
          <string-name>
            <given-names>F</given-names>
            <surname>Researcher</surname>
          </string-name>
          / Scientist 3+ Mo
        </mixed-citation>
      </ref>
      <ref id="ref128">
        <mixed-citation>
          19
          <string-name>
            <given-names>M</given-names>
            <surname>Software</surname>
          </string-name>
          <article-title>Engineer 1-3 Mo</article-title>
        </mixed-citation>
      </ref>
      <ref id="ref129">
        <mixed-citation>
          20
          <string-name>
            <given-names>M</given-names>
            <surname>Machine</surname>
          </string-name>
          <article-title>Learning Engineer 1-3 Mo</article-title>
        </mixed-citation>
      </ref>
      <ref id="ref130">
        <mixed-citation>
          21
          <string-name>
            <given-names>M</given-names>
            <surname>Software</surname>
          </string-name>
          <article-title>Architect 3+ Yr</article-title>
        </mixed-citation>
      </ref>
      <ref id="ref131">
        <mixed-citation>
          <source>22 NR Software Engineer &lt; 1 5 Yr</source>
        </mixed-citation>
      </ref>
      <ref id="ref132">
        <mixed-citation>
          23
          <string-name>
            <given-names>M</given-names>
            <surname>Software</surname>
          </string-name>
          <article-title>Engineer 1-3 Mo</article-title>
        </mixed-citation>
      </ref>
      <ref id="ref133">
        <mixed-citation>
          24
          <string-name>
            <given-names>F</given-names>
            <surname>Software</surname>
          </string-name>
          <article-title>Architect &lt; 1 5 Yr</article-title>
        </mixed-citation>
      </ref>
      <ref id="ref134">
        <mixed-citation>
          25
          <string-name>
            <given-names>M</given-names>
            <surname>Software</surname>
          </string-name>
          <article-title>Engineer &lt; 1 5 Yr</article-title>
        </mixed-citation>
      </ref>
      <ref id="ref135">
        <mixed-citation>
          26
          <string-name>
            <given-names>F</given-names>
            <surname>Software</surname>
          </string-name>
          <article-title>Engineer &lt; 1 5 Yr</article-title>
        </mixed-citation>
      </ref>
      <ref id="ref136">
        <mixed-citation>
          27
          <string-name>
            <given-names>F</given-names>
            <surname>Software</surname>
          </string-name>
          <article-title>Engineer &lt; 1 5 Yr</article-title>
        </mixed-citation>
      </ref>
      <ref id="ref137">
        <mixed-citation>
          28
          <string-name>
            <given-names>M</given-names>
            <surname>Researcher</surname>
          </string-name>
          <article-title>/ Scientist 3+ Mo</article-title>
        </mixed-citation>
      </ref>
      <ref id="ref138">
        <mixed-citation>
          29
          <string-name>
            <given-names>F</given-names>
            <surname>Software Engineer</surname>
          </string-name>
          <string-name>
            <surname>NF</surname>
          </string-name>
          &gt;
          <volume>5</volume>
          <fpage>Yr</fpage>
        </mixed-citation>
      </ref>
      <ref id="ref139">
        <mixed-citation>
          30
          <string-name>
            <given-names>F</given-names>
            <surname>Data</surname>
          </string-name>
          <article-title>Scientist 3+ Mo</article-title>
        </mixed-citation>
      </ref>
      <ref id="ref140">
        <mixed-citation>
          31
          <string-name>
            <given-names>M</given-names>
            <surname>Data</surname>
          </string-name>
          <article-title>Scientist 1-3 Mo</article-title>
        </mixed-citation>
      </ref>
      <ref id="ref141">
        <mixed-citation>
          32
          <string-name>
            <given-names>F</given-names>
            <surname>Other</surname>
          </string-name>
          (
          <year>Consultant</year>
          )
          <fpage>1</fpage>
          -3 Mo
        </mixed-citation>
      </ref>
      <ref id="ref142">
        <mixed-citation>
          33
          <string-name>
            <given-names>F</given-names>
            <surname>Other (Systems Test Engineer</surname>
          </string-name>
          ) &lt; 1 Mo
        </mixed-citation>
      </ref>
      <ref id="ref143">
        <mixed-citation>
          34
          <string-name>
            <given-names>F</given-names>
            <surname>Researcher</surname>
          </string-name>
          / Scientist 3+ Mo
        </mixed-citation>
      </ref>
      <ref id="ref144">
        <mixed-citation>
          35
          <string-name>
            <given-names>M</given-names>
            <surname>Software</surname>
          </string-name>
          <article-title>Engineer 3+ Mo</article-title>
        </mixed-citation>
      </ref>
      <ref id="ref145">
        <mixed-citation>
          36
          <string-name>
            <given-names>M</given-names>
            <surname>Software</surname>
          </string-name>
          <article-title>Architect 1-3 Mo</article-title>
        </mixed-citation>
      </ref>
      <ref id="ref146">
        <mixed-citation>
          37
          <string-name>
            <given-names>M</given-names>
            <surname>Researcher</surname>
          </string-name>
          <article-title>/ Scientist 3+ Mo</article-title>
        </mixed-citation>
      </ref>
      <ref id="ref147">
        <mixed-citation>
          38
          <string-name>
            <given-names>M</given-names>
            <surname>Software</surname>
          </string-name>
          <article-title>Engineer 3+ Mo</article-title>
        </mixed-citation>
      </ref>
      <ref id="ref148">
        <mixed-citation>
          39
          <string-name>
            <given-names>F Software</given-names>
            <surname>Engineer</surname>
          </string-name>
          1-3 Mo
        </mixed-citation>
      </ref>
      <ref id="ref149">
        <mixed-citation>
          40
          <string-name>
            <given-names>F</given-names>
            <surname>Researcher</surname>
          </string-name>
          / Scientist 3+ Mo
        </mixed-citation>
      </ref>
      <ref id="ref150">
        <mixed-citation>
          41
          <string-name>
            <given-names>F</given-names>
            <surname>Researcher</surname>
          </string-name>
          <article-title>/ Scientist NF &gt; 5 Yr</article-title>
        </mixed-citation>
      </ref>
      <ref id="ref151">
        <mixed-citation>
          42
          <string-name>
            <given-names>M</given-names>
            <surname>Software</surname>
          </string-name>
          <article-title>Engineer 3+ Mo Table 2</article-title>
          :
          <string-name>
            <given-names>Participant</given-names>
            <surname>Demographics</surname>
          </string-name>
          .
          <article-title>Gender is coded as M = Male</article-title>
          ,
          <string-name>
            <surname>F</surname>
          </string-name>
          = Female,
          <string-name>
            <surname>GV</surname>
          </string-name>
          /NC = Gender Varying /
          <article-title>Non-conforming, and NR = Not reported</article-title>
          .
          <article-title>Python familiarity (Fam.) is coded as NF = Not familiar, &lt; 1 = &lt; 1 year, 1-3 = 1-3 years, and 3+ = 3+ years. Recency of Python use (Rec.) is coded as Mo = Within the past month, Yr = Within the past year, 5 Yr = Within the past 5 years, and &gt; 5 Yr = Not within the past 5 years.</article-title>
        </mixed-citation>
      </ref>
    </ref-list>
  </back>
</article>